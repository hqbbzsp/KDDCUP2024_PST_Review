<p> dynamic branch prediction with perceptrons </p><p> the perceptron: a model for brain functioning </p><p> [pos is Related Work] "How Perceptrons WorkThe perceptron was introduced in 1962 [19] as a way to study brain function. We consider the simplest of many types of perceptrons [#b1][2], a singlelayer perceptron consisting of one artificial neuron connecting several input units by weighted edges to one output unit. A perceptron learns a target </p>
<p> dynamic branch prediction with perceptrons </p><p> the bi-mode branch predictor </p><p> [pos is Related Work] he penalty for a misprediction increases. Recent efforts to improve branch prediction focus primarily on eliminating aliasing in twolevel adaptive predictors [[#b15]], which occurs when two unrelated branches destructively interfere by using the sa. [pos is Related Work] evel predictors is aliasing [20], and many of the recently proposed branch predictors seek to reduce the aliasing problem [[#b15]] but do not change the basic prediction mechanism. Given a generous hardware budge. [pos is Related Work] iv MethodologyPredictors simulated. We compare our new predictor against gshare [17] and bimode [#b15][16], two of the best purely dynamic global predictors from the branch prediction literature. We also evaluate a hybrid gshareperceptron predictor that uses a 2K. [pos is Related Work] on can yield greater accuracy [], but our restriction to global information is typical of recent work in branch prediction [#b15][].Gathering traces. Our simulations use the instrumented assembly output of the gcc 2.95.1 compiler with optimizati. [pos is Related Work] ingly, the SPEC 2000 integer benchmarks are, as a whole, easier for branch predictors than the SPEC95 benchmarks, explaining the smaller separation between gshare and bimode than observed previously [#b15][16]. Figures 4 and 5 show the misprediction rates on the SPEC 2000 benchmarks for hardware budgets of 4K and 16K bytes, respectively. The </p>
<p> dynamic branch prediction with perceptrons </p><p> dynamically weighted ensemble neural networks for classification </p><p> [pos is Related Work] s have been used for a variety of applications, including pattern recognition, classification [8], and image understanding [[#b11]].Static branch prediction with neural networks. Neural networks have been used to perform static branch prediction [3]ref. [pos is Related Work] number that we interpret as taken if  . The value of  provides important information about the branch since the distance of  from 0 is proportional to the certainty that the branch will be taken [#b11][12]. This confidence can be used, for example, to allow a microarchitecture to speculatively execute both branch paths when confidence is low, and to execute only </p>
<p> dynamic branch prediction with perceptrons </p><p> understanding neural networks via rule extraction </p><p> [pos is Related Work] m of many neural networks is that it is difficult or impossible to determine exactly how the neural network is making its decision. Techniques have been proposed to extract rules from neural networks [#b20][21], but these rules are not always accurate. Perceptrons do not suffer from this opaqueness the perceptron's decisionmaking process is easy to understand as th </p>
<p> dynamic branch prediction with perceptrons </p><p> using hybrid branch predictors to improve branch prediction accuracy in the presence of context switches </p><p> [pos is Related Work] either perbranch nor path information is used. Thus, we have not yet compared our hybrid against existing globalperbranch hybrid schemes. Perbranch and path information can yield greater accuracy [#b5][], but our restriction to global information is typical of recent work in branch prediction ref type"bibr" target"b15". [pos is Related Work] httpwww.teic.orgns1.0"Effects of Context SwitchingBranch predictors can suffer a loss in performance after a context switch, having to warm up while relearning patterns [#b5][6]. We simulate the effects of context switching by interleaving branch traces from each of the SPEC 2000 integer benchmarks, switching to the next program after 6. [pos is Related Work] tors at hardware budgets of 4K bytes or more. The hybrid gshareperceptron predictor performs better in the presence of context switching this benefit of hybrid predictors has been noticed by others [#b5][6].  ImplementationWe now suggest ways to implement our predictor efficiently.Compu. [pos is Related Work] target"b21"[22]. We can also employ perceptrons in a hybrid predictor that uses both global and local histories, since hybrid predictors have proven to work better than purely global schemes [#b5][6]. We have preliminary experimental evidence that such hybrid schemes can be improved by using perceptrons, and we intend to continue this study in more detail. </p>
<p> dynamic branch prediction with perceptrons </p><p> the yags branch prediction scheme </p><p> [pos is Related Work] ction focus primarily on eliminating aliasing in twolevel adaptive predictors [[#b3]], which occurs when two unrelated branches destructively interfere by using the same prediction resources. We take a different approachone that is largely orthog. [pos is Related Work] of the recently proposed branch predictors seek to reduce the aliasing problem [[#b3]] but do not change the basic prediction mechanism. Given a generous hardware budget, many of these twolevel schemes perform about the same as one another ref ty. [pos is Related Work] ,[#b3]4] but do not change the basic prediction mechanism. Given a generous hardware budget, many of these twolevel schemes perform about the same as one another [#b3][4].Most twolevel predictors cannot consider long history lengths, which becomes a problem when the distance between correlated branches is longer than the. [pos is Related Work] bibr" target"b5"[], but our restriction to global information is typical of recent work in branch prediction [[#b3]].Gathering traces. Our simulations use the instrumented assembly output of the gcc 2.95.1 compiler with optimization flags O3 fomitframepointer running. [pos is Related Work] workload represents an unrealistically heavy amount of context switching, but it serves as a good indicator of performance in extreme conditions, and it uses the same methodology as other recent work [#b3][4]. Note that previous studies have used the 8 SPEC 95 integer benchmarks, so our use of the 12 SPEC 2000 benchmarks will likely lead to higher misprediction rates </p>
<p> dynamic branch prediction with perceptrons </p><p> understanding neural networks via rule extraction </p><p> [pos is Related Work] m of many neural networks is that it is difficult or impossible to determine exactly how the neural network is making its decision. Techniques have been proposed to extract rules from neural networks [#b20][21], but these rules are not always accurate. Perceptrons do not suffer from this opaqueness the perceptron's decisionmaking process is easy to understand as th </p>
<p> dynamic branch prediction with perceptrons </p><p> two-level adaptive branch prediction </p><p> [pos is Related Work] c.orgns1.0"Dynamic Branch PredictionDynamic branch prediction has a rich history in the literature. Recent research focuses on refining the twolevel scheme of Yeh and Patt [#b25][26]. In this scheme, a pattern history table (PHT) of twobit saturating counters is indexed by a combination of branch address and global or perbranch history. </p>
<p> dynamic branch prediction with perceptrons </p><p> adaptive switching circuits </p><p> [pos is Related Work] forms of machine learning, such as decision trees, are less attractive because of excessive implementation costs. For this work, we also considered other simple neural architectures, such as ADALINE [#b24][25] and Hebb learning [8], but we found that these were less effective than perceptrons (lower hardware efficiency for ADALINE. [pos is Related Work] there are more linearly inseparable branches, gshare performs better. Note that although the perceptron predictor performs best on linearly separable branches, it still has good performance overall. [#b24]25  Some branches require longer histories than others for accurate prediction, and the perceptron predictor often has an advantage for these branches. Figure ref </p>
<p> dynamic branch prediction with perceptrons </p><p> variable length path branch prediction </p><p> [pos is Related Work] story lengths, it would not help because longer history lengths require longer training times for these methods [18].Variable length path branch prediction [#b22][23] is one scheme for considering longer paths. It avoids the PHT capacity problem by computing a hash function of the addresses along the path to the branch. It. [pos is Related Work] rovide feedback for other branch prediction schemes. For example, our methodology in Section 5.6 could be used with a profiler to provide path length information to the variable length path predictor [#b22][23]. Effects of Context SwitchingBranch predictors can suffer a loss in performance aft. [pos is Related Work] than two clock cycles to make a prediction. For smaller hardware budgets, one cycle operation is feasible. Two cycles is also the amount of time claimed for the variable length path branch predictor [#b22][23]. That work proposes pipelining the predictor to reduce delay.Jimnez et al study a number of techniques for reducing the impact of delay on branch pred. [pos is Related Work] ger benchmarks.We have shown that there is benefit to considering history lengths longer than those previously considered. Variable length path prediction considers history lengths of up to 23 [#b22][23], and a study of the effects of long branch histories on branch prediction only considers lengths up to 32 [7]. We have fou </p>
<p> dynamic branch prediction with perceptrons </p><p> assigning confidence to conditional branch predictions </p><p> [pos is Related Work] y execute both branch paths when confidence is low, and to execute only the predicted path when confidence is high. Some branch prediction schemes explicitly compute a confidence in their predictions [#b10][11], but in our predictor this information comes for free. We have observed experimentally that the probability that a branch will be taken can be accurately esti </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> one-shot relational learning for knowledge graphs </p><p> r by only observing K triples about r, usually K is small. Figure 1 depicts an example of 3shot link prediction in KGs.To do fewshot link prediction, [#b22]Xiong et al. (2018) made the first trial and proposed GMatching, learning a matching metric by considering both learned embeddings and onehop graph structures, wh. Gradient meta is the loss gradient of relation meta which will be used to make a rapid update before transferring relation meta to incomplete triples during prediction.Compared with GMatching [#b22](Xiong et al., 2018) which relies on a background knowledge graph, our MetaR is independent with them, thus is more robust as background knowledge graphs might not. mmarize the current popular knowledge graph embedding methods.Traditional embedding models are heavily rely on rich training instances (Zhang et al., 2019b[#b22]Xiong et al., 2018), thus are limited to do fewshot link prediction. Our MetaR is designed to fill this vulnerability of existing embedding models. div. (1) Metricbased metalearning (Koch et al., 2015Vinyals et al., 2016Snell et al., 2017[#b22]Xiong et al., 2018), which tries to learn a matching metric between query and support set generalized to all tasks, where the idea of matching is similar to some n. t neighbors algorithms. Siamese Neural Network (Koch et al., 2015) is a typical method using symmetric twin networks to compute the metric of two inputs. GMatching [#b22](Xiong et al., 2018), the first trial on oneshot link prediction in knowledge graphs, learns a matching metric based on entity embeddings and local graph structur. ecific learner, and metaoptimization across tasks is performed over parameters by using above updated parameters, it's like "a gradient through a gradient".As far as we know, work proposed by [#b22]Xiong et al. (2018) is the first research on fewshot learning for knowledge graphs. It's a metricbased model which consists of a neighbor encoder and a matching. arget"foot_0"1 . Datasets and Evaluation MetricsWe use two datasets, NELLOne and WikiOne which are constructed by [#b22]Xiong et al. (2018). NELLOne and WikiOne are derived from NELL (Carlson et al., 2010) and Wikidata ref type"bibr" target". of two fewshot link prediction tasks, including 1shot and 5shot, on NELLOne and WikiOne are shown in Table 4. The baseline in our experiment is GMatching [#b22](Xiong et al., 2018), which made the first trial on fewshot link prediction task and is the only method that we can find as baseline. In this table, results of GM. denoted as g. The third one is removing the relation meta further which makes the model rebase to a simple TransE embedding model, denoted as g r. The result under the third setting is copied from [#b22]Xiong et al. (2018). It uses the triples from background graph, training tasks and oneshot training triples from validationtest set, so it's neither BGPreTrain </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> modeling relation paths for representation learning of knowledge bases </p><p> al., 2018) using convolutional structure to score triples and models using additional information such as entity types (Xie et al., 2016) and relation paths [#b9](Lin et al., 2015a). Wang et al. (2017) comprehensively summarize the current popular knowledge graph embedding methods. </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> toward an architecture for never-ending language learning </p><p> ort), encoding knowledge and facts in the world. Many KGs have been proposed (Vrandei and Krtzsch, 2014Bollacker et al., 2008[#b3]Carlson et al., 2010) and applied to various applications (Bordes et al., 2014Zhang et al., 2016. d Evaluation MetricsWe use two datasets, NELLOne and WikiOne which are constructed by Xiong et al. (2018). NELLOne and WikiOne are derived from NELL [#b3](Carlson et al., 2010) and Wikidata (Vrandei and Krtzsch, 2014)   graph originally, we can make use of such background graph by </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> representation learning of knowledge graphs with hierarchical types </p><p> are also some others like ConvE (Dettmers et al., 2018) using convolutional structure to score triples and models using additional information such as entity types [#b21](Xie et al., 2016) and relation paths (Lin et al., 2015a). Wang et al. (2017) comprehensiv </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> matching networks for one shot learning </p><p> talearning models have been proposed recently. Generally, there are three kinds of metalearning methods so far (1) Metricbased metalearning (Koch et al., 2015[#b17]Vinyals et al., 2016Snell et al., 2017Xiong et al., 2018), which tries to learn a match </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> convolutional 2d knowledge graph embeddings </p><p> uillon et al., 2016) are derived from RESCAL (Nickel et al., 2011), trying to mine latent semantics in different ways. There are also some others like ConvE [#b4](Dettmers et al., 2018) using convolutional structure to score triples and models using additional information such as entity types ( </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> convolutional 2d knowledge graph embeddings </p><p> uillon et al., 2016) are derived from RESCAL (Nickel et al., 2011), trying to mine latent semantics in different ways. There are also some others like ConvE [#b4](Dettmers et al., 2018) using convolutional structure to score triples and models using additional information such as entity types ( </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> a simple neural attentive metalearner </p><p> res which also can be regarded as a metricbased method. (2) Modelbased method (Santoro et al., 2016Munkhdalai and Yu, 2017[#b11]Mishra et al., 2018), which uses a specially designed part like memory to achieve the ability of learning rapidly by only a few training instances.MetaNet  </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> freebase: a collaboratively created graph database for structuring human knowledge </p><p> rm of (head entity, relation, tail entity) ((h, r, t) in short), encoding knowledge and facts in the world. Many KGs have been proposed (Vrandei and Krtzsch, 2014[#b0]Bollacker et al., 2008Carlson et al., 2010) and applied to various applications (Bordes et al., 2 </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> iteratively learning embeddings and rules for knowledge graph reasoning </p><p> target"b19"Wang et al. (2017) comprehensively summarize the current popular knowledge graph embedding methods.Traditional embedding models are heavily rely on rich training instances [#b26](Zhang et al., 2019bXiong et al., 2018), thus are limited to do fewshot link prediction. Our MetaR is designed to fill this </p>
<p> meta relational learning for few-shot link prediction in knowledge graphs </p><p> convolutional 2d knowledge graph embeddings </p><p> uillon et al., 2016) are derived from RESCAL (Nickel et al., 2011), trying to mine latent semantics in different ways. There are also some others like ConvE [#b4](Dettmers et al., 2018) using convolutional structure to score triples and models using additional information such as entity types ( </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> texram: a smart memory for texturing </p><p> s. This is an incentive for integrating the SRAM cache onto the same chip as the fragment generator.Finally, a recent trend in computer graphics has been the use of rendered images as textures [#b2][3]. As a result, it has become desirable to unify the framebuffer and texture memories to avoid copying data between the two. A fragment generator connected to an. rather than a cache line. A conflictfree address distribution which allows up to four texels to be accessed in parallel is possible if the texels are stored in a morton order within the cache lines [#b2][3]. Morton order implies that the texels are stored in 2x2 blocks. The texels within each 2x2 block are interleaved across the four banks and the same interleaving </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> the truth about texture mapping </p><p> are within a square region (block) of a twodimensional image are ordered consecutively in memory. The idea of texture blocking is previously discussed in [4] and [#b9][10]. There are several issues that are raised by this representation. First, what is the addressing overhead associated with blocking? Second, how do we select the </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> high-bandwidth data memory systems for superscalar processors </p><p> o be able to access more than one texel from the cache in the same cycle. A common way of designing a multiported cache is to interleave the cache lines across multiple independently addressed banks [#b7][8]. Since a trilinear interpolation involves accessing neighboring texels, the interleaving across banks in a texture cache must be at the granularity of a texel r </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> rendering antialiased shadows with depth maps </p><p> nt [21], bumps [9], transparency [7], and shadows [[#b24]].One characteristic of texture mapping is that texture images often require large amounts of memory (typically in the range of a few megabytes to tens of </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> rendering antialiased shadows with depth maps </p><p> nt [21], bumps [9], transparency [7], and shadows [[#b24]].One characteristic of texture mapping is that texture images often require large amounts of memory (typically in the range of a few megabytes to tens of </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> applications of world projections </p><p> ddition to the mapping of surface color [5], texture mapping has been used for mapping a myriad of other surface parameters including reflection of the environment [#b20][21], bumps [9], transparency [7], and shadows [20,re </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> the truth about texture mapping </p><p> are within a square region (block) of a twodimensional image are ordered consecutively in memory. The idea of texture blocking is previously discussed in [4] and [#b9][10]. There are several issues that are raised by this representation. First, what is the addressing overhead associated with blocking? Second, how do we select the </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> applications of world projections </p><p> ddition to the mapping of surface color [5], texture mapping has been used for mapping a myriad of other surface parameters including reflection of the environment [#b20][21], bumps [9], transparency [7], and shadows [20,re </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> pyramidal parametrics </p><p> and texture mapping calculations. Before we can describe how the fragments are texture mapped, we must first discuss the concept of Mip Mapping.The goal of Mip Mapping, introduced by Williams [#b14][15], is to efficiently avoid aliasing artifacts by quickly filtering the texture image. It involves representing a texture as an image pyramid as illustrated in F. ache organization. We examine two representations a Nonblocked representation and a Blocked representation. Previous WorkIn [#b14][15], Williams also described a clever memory organization and addressing scheme for twodimensional textures which is illustrated in Figure 5 </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> talisman: commodity realtime 3d graphics for the pc </p><p> ] and Accelerated Graphics Port (AGP) [1] from Intel Corporation, Magic Carpet [12] from MIPS Technologies, and Talisman [#b12][13] from Microsoft Corporation. In this paper, we focus on one challenging aspect of graphics architecture, the design of a memory system for texture mapping.p. conditions. A texturing system can sustain the maximum rate if the memory latency is completely hidden and the memory bandwidth is met.One solution for hiding the memory latency is proposed in [#b12][13]. The basic idea is to compute the texel addresses far in advance of the cache accesses by rasterizing the triangles twice the first time to compute the texel. ly, caches have not been used in computer graphics systems where the philosophy has been to provide guaranteed performance under worstcase conditions, although this philosophy is beginning to change [#b12][13]. By using techniques such as (i) blockbased representation of MipMapped textures, (ii) tiled rendering in the screen space itself, and (iii) padded or sixd </p>
<p> the design and analysis of a cache architecture for texture mapping </p><p> rendering from compressed textures </p><p> e performance can be made robust regardless of the scenes that are being texture mapped.A promising approach for rendering directly from compressed textures has been proposed in the literature [#b1][2]. In future work, it would be interesting to study the interaction between compressed representations of textures and cache architectures. Another area which we </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> a short introduction to probabilistic soft logic </p><p>  </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> go for a walk and arrive at the answer: reasoning over paths in knowledge bases using reinforcement learning </p><p> he embedding space. Hence, they have been the crucial feature models that benefit numerous knowledgedriven tasks (Bordes, Weston, and Usunier 2014 He et al. 2017[#b5]Das et al. 2018). Recently, extensive efforts have been devoted into embedding deterministic KGs. Translational models, e.g., TransE ( </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> on2vec: embedding-based relation prediction for ontology population </p><p> t al. 2016), relation extraction (Weston, Bordes, and others 2013), relational learning (Nickel, Rosasco, and Poggio 2016), and ontology population [#b4](Chen et al. 2018).While current embedding models focus on capturing deterministic knowledge, it is critical to incorporate uncertainty information into know </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> adaptive subgradient methods for online learning and stochastic optimization </p><p>  </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> on embedding uncertain graphs </p><p> ven applications. For example, Wang and Wang (2016) utilize Probase to help understand short texts.One recent work has proposed a matrixfactorizationbased approach to embed uncertain networks [#b9](Hu et al. 2017). However, it cannot be generalized to embed uncertain KGs because this model only considers the node proximity in the networks with no explicit rel. l. 2013), DistMult (Yang et al. 2015) and ComplEx (Trouillon et al. 2016), (ii) an uncertain graph embedding model URGE [#b9](Hu et al. 2017) Here linear stands for linear gain, and exp. stands for exponential gain. have a KGspecific confidence score threshold  to distinguish the highc </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> connecting language and knowledge bases with embedding models for relation extraction </p><p> r" target"b1"(Bordes et al. 2013) andTransH (Wang et al. 2014)), and bilinear models, e.g. DistMult (Yang et al. 2015) and ComplEx [#b20](Trouillon et al. 2016), have achieved promising performance in many tasks, such as link prediction (Yang et al. 2015ref typ. ComplEx [#b20](Trouillon et al. 2016), have achieved promising performance in many tasks, such as link prediction (Yang et al. 2015[#b20]Trouillon et al. 2016), relation extraction (Weston, Bordes, and others 2013), relational learning (Nickel, Rosasco, and Po. e"bibr" target"b21"(Wu et al. 2012) provides a prior probability distribution of concepts behind a term that has critically supported short text understanding tasks involving disambiguation [#b20](Wang et al. 2015Wang and Wang 2016). Furthermore, uncertain knowledge representations have largely benefited various applications, such as. of nodes with FB15k (Bordes et al. 2013) the widely used benchmark dataset for deterministic KG embeddings (Bordes et al. 2013[#b20]Wang et al. 2014Yang et al. 2015), while NL27k is a larger dataset. PPI5k is a denser graph with fewer entities but more rela. ison, which include (i) deterministic KG embedding models TransE (Bordes et al. 2013), DistMult (Yang et al. 2015) and ComplEx [#b20](Trouillon et al. 2016), (ii) an uncertain graph embedding model URGE (Hu et al. 2017) Here linear stands for linear gain, and. ds to them only on the ranking and the classification tasks. For the same reason, the early stopping is based on mean reciprocal rank (MRR) on the validation set. We adopt the implementation given by [#b20](Trouillon et al. 2016) and choose the best hyperparameters following the same grid search procedure. This implementation uses (Duchi, Hazan, and. models need to distinguish relation facts in the KG from negative links and highconfidence relation facts from lowconfidence ones.Evaluation protocol We follow a procedure that is similar to [#b20](Wang et al. 2014). Our test set consists of relation facts from the KG and randomly sampled negative links equally. We divide the test cases into two groups, stro </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> question answering using enhanced lexical semantic models </p><p> get"b20"(Wang et al. 2015Wang and Wang 2016). Furthermore, uncertain knowledge representations have largely benefited various applications, such as question answering [#b23](Yih et al. 2013) and named entity recognition (Ratinov and Roth 2009).Capturing the uncertainty information with KG embeddings remai </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> knowledge base completion: baselines strike back </p><p>  </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> on2vec: embedding-based relation prediction for ontology population </p><p> t al. 2016), relation extraction (Weston, Bordes, and others 2013), relational learning (Nickel, Rosasco, and Poggio 2016), and ontology population [#b4](Chen et al. 2018).While current embedding models focus on capturing deterministic knowledge, it is critical to incorporate uncertainty information into know </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> question answering using enhanced lexical semantic models </p><p> get"b20"(Wang et al. 2015Wang and Wang 2016). Furthermore, uncertain knowledge representations have largely benefited various applications, such as question answering [#b23](Yih et al. 2013) and named entity recognition (Ratinov and Roth 2009).Capturing the uncertainty information with KG embeddings remai </p>
<p> Embedding Uncertain Knowledge Graphs </p><p> knowledge base completion: baselines strike back </p><p>  </p>
<p> Learning Language Representations for Typology Prediction </p><p> uriel and lang2vec: representing languages as typological, geographical, and phylogenetic vectors </p><p> abases, from known entries (Daum III and Campbell, 2007Daum III, 2009Coke et al., 2016[#b22]Littell et al., 2017).In this study, we examine whether we can tackle the problem of inferring linguistic typology from parallel corpora, specifically by tr. rained on 1017 languages, and use them for typlogy prediction both on their own and in composite with feature vectors from previous work based on the genetic and geographic distance between languages [#b22](Littell et al., 2017). Results show that the extracted representations do in fact allow us to learn about the typology of languages, with particular gains for syn. markers. Dataset and Experimental SetupTypology Database To perform our analysis, we use the URIEL language typology database [#b22](Littell et al., 2017), which is a collection of binary features extracted from multiple typological, phylogenetic, and geographical databases such as WALS (World. al., 2016Coke et al., 2016). As an alternative that does not necessarily require preexisting knowledge of the typological features in the language at hand, [#b22]Littell et al. (2017) have proposed a method for inferring typological features directly from the language's k nearest neighbors (kNN) according to geodesic dista </p>
<p> Learning Language Representations for Typology Prediction </p><p> universal reordering via linguistic typology </p><p> l language modeling and loanword prediction (Tsvetkov et al., 2016), POStagging (Zhang et al., 2012), and machine translation [#b8](Daiber et al., 2016).However, the needs of NLP tasks differ in many ways from the needs of scientific typology, and typological databases are often only spa </p>
<p> Learning Language Representations for Typology Prediction </p><p> recurrent neural network based language model </p><p>  </p>
<p> Learning Language Representations for Typology Prediction </p><p> universal reordering via linguistic typology </p><p> l language modeling and loanword prediction (Tsvetkov et al., 2016), POStagging (Zhang et al., 2012), and machine translation [#b8](Daiber et al., 2016).However, the needs of NLP tasks differ in many ways from the needs of scientific typology, and typological databases are often only spa </p>
<p> Learning Language Representations for Typology Prediction </p><p> automatically identifying computationally relevant typological features </p><p> eflect the syntactic, phonetic, or semantic consistencies of various languages. This has been demonstrated to some extent in previous work that has used specifically engineered alignmentbased models [#b21](Lewis and Xia, 2008stling, 2015Coke et al., 2016), and we examine whether these result. eatures (Lewis and  Table 2 Top 5 improvements from "NONE Aux" to "MTBOTH Aux" in the syntax ("S "), phonology ("P "), and inventory ("I ") classes.  [#b21]2008stling, 2015Coke et al., 2016), our proposed method is also able to infer informati </p>
<p> Learning Language Representations for Typology Prediction </p><p> the velar nasal </p><p>  </p>
<p> Learning Language Representations for Typology Prediction </p><p> long short-term memory </p><p> "b31"stling and Tiedemann, 2017). Specifically, these models train a recurrent neural network LM (RNNLM Mikolov et al. ( 2010)) using long shortterm memory (LSTM [#b16]Hochreiter and Schmidhuber (1997)) with an additional vector representing the current language as an input. The expectation is that this vector will be able to cap </p>
<p> Learning Language Representations for Typology Prediction </p><p> survey on the use of typological information in natural language processing </p><p> nguages. Typological information from sources like the World Atlas of Language Structures (WALS) (Dryer and Haspelmath, 2013), has proven useful in many NLP tasks [#b29](O'Horan et al., 2016), such as multilingual dependency parsing (Ammar et al., 2016), generative parsing in lowresource settin </p>
<p> Learning Language Representations for Typology Prediction </p><p> reconstructing native language typology from foreign language usage </p><p> between translation studies and tools for contrastive linguistic analysis, work in inferring typology from bilingual data ( stling, 2015) and English as Second Language texts [#b3](Berzak et al., 2014), as well as work in NLP (Shi et al., 2016Kuncoro et al., 2017ref </p>
<p> Learning Language Representations for Typology Prediction </p><p> learning to map into a universal pos tagset </p><p> 012Tckstrm et al., 2013), phonological language modeling and loanword prediction (Tsvetkov et al., 2016), POStagging [#b38](Zhang et al., 2012), and machine translation (Daiber et al., 2016).However, the needs of NLP tasks differ in many ways </p>
<p> Learning Language Representations for Typology Prediction </p><p> discriminative analysis of linguistic features for typological study </p><p> ical traits correlate strongly with others, to use known features of a language to help infer other unknown features of the language (Daum III and Campbell, 2007[#b36]Takamura et al., 2016Coke et al., 2016). As an alternative that does not necessarily require preexisting knowledge of the typ </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> learning a deep convolutional network for image super-resolution </p><p> "bibr" target"b2"3], do not bring additional information to solve the illposed reconstruction problem.Learning upscaling filters was briefly suggested in the footnote of Dong et.al. [#b5][6]. However, the importance of integrating it into the CNN as part of the SR operation was not fully recognised and the option not explored. Additionally, as noted. target"b5"[6]. However, the importance of integrating it into the CNN as part of the SR operation was not fully recognised and the option not explored. Additionally, as noted by Dong et al. [#b5][6], there are no efficient implementations of a convolution layer whose output size is larger than the input size and welloptimized implementations such as convne. positive effect of the subpixel convolution layer as well as tanh activation function. We first evaluate the power of the subpixel convolution layer by comparing against SRCNN's standard 915 model [#b5][6]. Here, we follow the approach in [#b5][6], using relu as the activation function for our models in this experiment, and training. ion function. We first evaluate the power of the subpixel convolution layer by comparing against SRCNN's standard 915 model [#b5][6]. Here, we follow the approach in [#b5][6], using relu as the activation function for our models in this experiment, and training a set of models with 91 images and another set with images from ImageNet.. s. However, the use of Set14 on a single CPU core is selected here in order to allow a straightforward comparison with results from previous published results[[#b5]].         SuperResolution from </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> anchored neighborhood regression for fast example-based super-resolution </p><p> on Set143 with an upscale factor of 3. We evaluate the run time of other methods [[#b38]] from the Matlab codes provided by [40] and [31]. For methods which use convolutions i </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> imagenet large scale visual recognition challenge </p><p> 34] have recently also shown promise for SISR. These methods, employ the backpropagation algorithm [22] to train on large image databases such as ImageNet [#b29][30] in order to learn nonlinear mappings of LR and HR image patches. Stacked collaborative local autoencoders are used in [4]. images for testing and the super texture dataset [5] which provides 136 texture images. For our final models, we use 50,000 randomly selected images from ImageNet [#b29][30] for the training. Following previous works, we only consider the luminance channel in YCbCr colour space in this section because humans are more sensitive to. eshold . The final layer learns 10 times slower as in [7]. The training takes roughly three hours on a K2 GPU on 91 images, and seven days on images from ImageNet [#b29][30] for upscaling factor of 3. We use the PSNR as the performance metric to evaluate our models. PSNR of SRCNN and Chen's models on our extended benchmark set are </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> super-resolution through neighbor embedding </p><p> , image statisticsbased [] and patchbased [#b1][2,43,52,13,54,. e evaluationsIn this section, we evaluated our best model's run time on Set143 with an upscale factor of 3. We evaluate the run time of other methods [#b1][] from the Matlab codes provided by [40] and </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> complex wavelets for shift invariant analysis and filtering of signals </p><p> get"fig_4"4. The weights of our first and last layer filters have a strong similarity to designed features including the logGabor filters [48], wavelets [#b19][20] and Haar features [42]. It is noticeable that despite each filter is independent in LR space, our independent filters is </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> complex wavelets for shift invariant analysis and filtering of signals </p><p> get"fig_4"4. The weights of our first and last layer filters have a strong similarity to designed features including the logGabor filters [48], wavelets [#b19][20] and Haar features [42]. It is noticeable that despite each filter is independent in LR space, our independent filters is </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> eigenface-domain super-resolution for face recognition </p><p> get"b14"[15], medical imaging [], satellite imaging [38], face recognition [#b16][17] and surveillance [53]. The global SR problem assumes LR data to be a lowpass filtered (blurred), downsampled and noisy v </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> image deblurring and superresolution by adaptive sparse domain selection and adaptive regularization </p><p> is able to embed the prior knowledge necessary to constrain the illposed problem of superresolving unseen data. This approach is proposed in the methods of [[#b7]]. A drawback of sparsitybased techniques is that introducing the sparsity constraint through a nonlinear reconstruction is generally computationally expensive. </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> rapid object detection using a boosted cascade of simple features </p><p> r filters have a strong similarity to designed features including the logGabor filters [48], wavelets [20] and Haar features [#b41][42]. It is noticeable that despite each filter is independent in LR space, our independent filters is actually smooth in the HR space after PS. Compared to SRCNN' </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> iris recognition algorithm using modified log-gabor filters </p><p> get"fig_2"3 and Fig. 4. The weights of our first and last layer filters have a strong similarity to designed features including the logGabor filters [#b47][48], wavelets [20] and Haar features [42]. It is noticeable that despite each filter is </p>
<p> real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. </p><p> image super-resolution via sparse representation </p><p> etween LR and HR patches. This dictionary is able to embed the prior knowledge necessary to constrain the illposed problem of superresolving unseen data. This approach is proposed in the methods of [#b46][]. A drawback of sparsitybased techniques is that introducing the sparsity constraint through a nonlinear reconstruction </p>
<p> fast thread migration via cache working set prediction </p><p> the shared-thread multiprocessor </p><p> cality due to frequent thread spawning in a speculative multithreading architecture. Background and Related WorkPrevious work [#b2][] describes support mechanisms for migrating register state in order to decrease the latency of thread activation and deac. apply to systems with scalable interconnects and more cores.The cores of our CMP feature hardware support for thread activation and deactivation, as found in prior studies of thread scheduling [#b2][]. While those works used hardware support to implement scheduling and timesharing policies, we use it simply for adding </p>
<p> fast thread migration via cache working set prediction </p><p> simultaneous subordinate microthreading (ssmt) </p><p> "b26"27,34] breaks serial execution into potentially parallel threads, each thread inheriting the execution context of the previous thread. Helper threads [#b6][] also utilize parallel hardware for speedup, without actually offloading computat </p>
<p> fast thread migration via cache working set prediction </p><p> understanding the backward slices of performance degrading instructions </p><p> ds, migration cost is extreme. Note that several speculative multithreading proposals routinely execute threads under 100 instructions [21], as do helperthreads [#b38][39] several transactional memory programs (for Transactional Coherency and Consistency) showed average transaction lengths in the low hundreds ref type"bibr" t </p>
<p> fast thread migration via cache working set prediction </p><p> improving direct-mapped cache performance by the addition of a small fully-associative cache and prefetch buffers </p><p> s which limit the gains of those techniques. Choi, et al., explore the complementary problem of branch prediction for shortlived threads [8].Stream buffers [#b15][] introduce small associative structures which track data access patterns. Additional work ref type"bibr" target"b30 </p>
<p> fast thread migration via cache working set prediction </p><p> evaluating stream buffers as a secondary cache replacement </p><p> es. Choi, et al., explore the complementary problem of branch prediction for shortlived threads [8].Stream buffers [[#b23]] introduce small associative structures which track data access patterns. Additional work [31] extends this idea, allowing </p>
<p> fast thread migration via cache working set prediction </p><p> quantifying load stream behavior </p><p> get"b30"[31], omitting the shared Markov predictor, as part of our baseline. We also add the ability to transfer streambuffer state as a candidate working set prefetcher.Sair, et al. [#b28][29] survey several prefetchers, and introduce a method for classifying memory access behaviors in hardware the memory access stream is matched against behaviors. ts a specific type of access pattern we next describe each type we consider. (We are not proposing these tables as novel prefetching schemes several of the underlying ideas are discussed in 2, and [#b28][29] surveys several more.)NextblockInst,Data These detect sequential block accesses entries are advanced by one cache block on a hit. We maintain sep </p>
<p> fast thread migration via cache working set prediction </p><p> speculative precomputation on chip multiprocessors </p><p> br" target"b39"[] targets memory instructions which degrade performance due to poor cache behavior, using alternate contexts on multithreaded or CMP [#b3][4] architectures. Focusing on misses, these schemes target the subset of the future working set which is not currently cached. Dependencefollowing schemes ref ty </p>
<p> fast thread migration via cache working set prediction </p><p> cmp memory modeling: how much does accuracy matter? </p><p> eues, banking, and porting for each cache, with perbank and port latency and bandwidth accounting. We model latency and bandwidth for each DRAM channel with a simple queue, "QILM" in the parlance of [#b32][33], without detailed memory controller modeling. In this study, virtually all postmigration misses are serviced coretocore rather than offchip consequently,. those critical prefetches are delayed by the extra traffic generated by DataMRU prefetching.As mentioned in 6.1, postmigrate performance is dominated by cachetocache transfers. Prior work [#b32][33] shows that memory simulation models such as ours can underestimate latency by up to 25. Since main memory access patterns are largely unaffected by WSM, the </p>
<p> fast thread migration via cache working set prediction </p><p> predictor-directed stream buffers </p><p> .Stream buffers [] introduce small associative structures which track data access patterns. Additional work [#b30][31] extends this idea, allowing an advanced predictor to be shared among many streams. We model a discrete hardware predictordirected stream buffer in the style. f type"bibr" target"b30"[31] extends this idea, allowing an advanced predictor to be shared among many streams. We model a discrete hardware predictordirected stream buffer in the style of [#b30][31], omitting the shared Markov predictor, as part of our baseline. We also add the ability to transfer streambuffer state as a candidate working set prefetcher. </p>
<p> fast thread migration via cache working set prediction </p><p> automatically characterizing large scale program behavior </p><p> impact the readwrite sets of transactions.We evaluate the full SPEC 2000 benchmark suite with reference inputs. Each benchmark is executed using 100Minstruction simulations based on SimPoint [#b29][30]. We model dualcore execution using architectural parameters similar to [26] these parameters include a shared L2 cache, </p>
<p> fast thread migration via cache working set prediction </p><p> data marshaling for multi-core architectures </p><p> to prefetch likely misses, and use the freed L1 storage as a prefetch buffer. Their work motivates ours we also find that caches often hold data irrelevant to future accesses.Data Marshaling [#b35][36] mitigates intercore data misses in Staged Execution models. In contrast to our approach, DM targets scheduled stage transitions using compiletime flagging o </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> end-to-end neural ad-hoc ranking with kernel pooling </p><p> A recent success of neural methods in information retrieval (neural IR) is the development of interaction based models [[#b39]]. Interaction based models thrive with encoding wordword translations using word embeddings, and utilizing new pooling methods to be er summarize the word tran. using word embeddings, and utilizing new pooling methods to be er summarize the word translations into ranking signals [[#b39]]. Learned endtoend from user feedbacks [[#b39]], the word embeddings can encode so ma. f type"bibr" target"b20"[[#b39]]. Learned endtoend from user feedbacks [[#b39]], the word embeddings can encode so matches tailored for relevance ranking, which has signi cant advantages over traditional featurebased methods ref type"bi. 3"[[#b39]], the word embeddings can encode so matches tailored for relevance ranking, which has signi cant advantages over traditional featurebased methods [#b39][]. ese initial successes of neural IR were mainly from so matching individual words. On the other hand, the query and do. calculating the similarity of two ngrams' embeddings. e current stateoftheart kernel pooling and learningtorank techniques are then used to combine the ngram somatches to the nal ranking score [#b39][29].e CNN is the key to modeling ngrams. Typical IR approaches treat ngrams as discrete terms and use them the same as unigrams. For example, a document. embeddings are then also found to be more e ective in ad hoc ranking [30].KNRM uni ed the progress of IR customized embeddings and interaction based model [#b39][29]. It rst embeds words and builds the translation matrix using the similarities between query and document words' embeddings. en it uses kernelpooling to summa. beddings and ranking parameters can be learned together. When trained with user feedback in a search log, KNRM outperforms both neural IR methods and featurebased learningtorank by a large margin [#b39][29].ough the so matching of ngrams in information retrieval remains an open topic, there has been a large amount of research that utilizes ngram exact ma. Ranking with Ngram TranslationsConvKNRM uses the kernelpooling technique and a learningtorank layer to calculate the ranking score using the ngram translations M. is part extends KNRM [#b39][29] to ngrams. Kernelpooling is a pooling technique that uses K Gaussian kernels to count the so matches of word or ngram pairs at K di erent strength levels.. ector  (M)  K 1 (M), ..., K K (M). Such countingbased pooling methods have shown be er performance than scorebased ones like meanpooling or maxpooling [[#b39]].Kernelpooling is applied to each M h q ,h d matrix in M to generate the so TF feature vector  M h q ,h d , which describes the distribution of match. d featurebased ranking. SummaryConvKNRM adds the ability of so matching ngrams to the recent stateoftheart KNRM model [#b39][29] with convolutional neural networks (CNNs). Without CNNs, ConvKNRM withdraws to KNRM.Matching ngrams is a wellestablished idea in information retrie.  DOMAIN ADAPTATIONEndtoend training ConvKNRM requires largescale training data, for example, user clicks in a commercial search log [#b39][29] or industryscale annotations [21]. However, for many search domains such as TREC benchmarks, such data are not available.. nd convolution layers are learned in the source domain to absorb the rich relevance signals in the training data. ey are then used in the target domain to generate so TF features (M). Xiong, et al. [#b39][29] showed that kernelpooled so TF features reveal di erent types of so match. For example, one kernel may count synonyms (e.g., 'oppor9' and 'OPPOR') another. use the importances of each type of so matches can change over domains. For instance, the synonym kernel is of low importance in search logs as all candidate documents already contain the query words [#b39][29] however, synonyms can be a strong signal in a recalloriented domain.Retraining the ranking layer in the target domain is a standard feature based le. two search logs in di erent languages (Sogou, Bing), and a TREC dataset (ClueWeb09B).SogouLog Sogou.com is a major Chinese commercial search engine.e same se ings as KNRM were used [#b39][29]. e same sample of Sogou log and trainingtesting splits are used (Table 1).e testing queries were sampled from. in document body text. Testing document's body texts were crawled, and were used by the traditional IR baselines for stronger baseline performance. Body texts of training documents were not available [#b39][29]. e Chinese text was segmented by ICTCLASS [31] then Chinese words were treated like English words.BingLog We us.  InDomain Training and TestingTraining and testing labels on SogouLog and BingLog were generated following prior research [#b39][29]. Technical PresentationWSDM'18, February 59, 2018, Marina Del Rey, CA, USA  ref type"bib. t. Neural IR baselines included CDSSM [26], MatchPyramid (MP) [23], DRMM [13], and KNRM [#b39][29].CDSSM [26] is uses CNNs to build query and document representations on their words' le ertrigrams (or Chinese ch. t"b39"[29].CDSSM [26] is uses CNNs to build query and document representations on their words' le ertrigrams (or Chinese characters in SogouLog [#b39][29]). e ranking scores are calculated by the similarity between the representations.MP [23] and DRMM ref type"bibr". re, while DRMM uses histogram pooling to count multiple levels of so TF, and use learningtorank a erwards.KNRM is a stateoftheart neural model previously tested on the SogouLog dataset [#b39][29]. It uses kernelpooling instead of DRMM's histogram pooling, and learns the word embeddings and the ranking layers endtoend. It is the main baseline in our. vised traditional IR models were trained and tested using crossvalidation on the testing data. On search logs, 5fold cross validation were used to be consistent with the previous study on SogouLog [#b39][29]. On ClueWeb09B, the 10fold cross validation splits from the provided baselines were used. All RankSVM's used the linear kernel with the hyperparameter C se. g, then used RankSVM with crossvalidation to retrain the learningtorank layer. Document Fields On SogouLog, traditional IR methods used both title and body, and neural IR methods only used title [#b39][29], as discussed in section 5.1. On BingLog, all methods used the title and snippets. On ClueWeb09B, all methods used title and body, except KNRM and ConvKNR. e candidate documents in the search log, or the ClueWeb corpus. MP, KNRM, and ConvKNRM embeddings were all learned endtoend using the query logs. For Sogoulog, we set embedding dimension L  300 [#b39][29] . For BingLog, we set L  100 because our pilot study showed that L  100 has similar performance with L  300 but the training is 3 times faster.Hype. 3 , or bin [ ]. e other 10 kernelsbins equally split the cosine range [ ] the  or bin centers were  1  0.9,  2  0.7, ...,  10  0.9.e  of the so match bins were set to be 0.1 [#b39][29]. Model Implementation and E ciency e model was implemented with Tensor ow.e optimization used the Adam optimizer, with batch size 16, learning rate 0.. g rate 0.001, and early stopping with the patience of 5 epochs.e training of ConvKNRM took about 12 hours on an AWS GPU machine. e training time is similar with prior work using only unigrams [#b39][29]. Most computation time was spent on the embedding layer the convolutional layer was very e cient. head n. ods are harder to beat endtoend learned embeddings and matchbased techniques are necessary for current neural IR methods to provide additional improvements [[#b39]] Comparing the two strong neural IR baselines, KNRM outperforms MP by a large margin. Both methods use endtoend learn. eddings. Our experiments and prior studies show that counting the frequencies of multilevel so matches are more e ective than weightsumming the similarities [[#b39]]"similarity does not necessarily mean relevance" [6].Recall that ConvKNRM is a richer model than KNRM only becaus </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> e pyramid match kernel: discriminative classi cation with sets of image features </p><p> 29]. Interaction based models thrive with encoding wordword translations using word embeddings, and utilizing new pooling methods to be er summarize the word translations into ranking signals [#b20][]. Learned endtoend from user feedbacks [23,r. ignals in the translation matrix at various levels and are suboptimal for ad hoc search [22].e DRMM model introduces the histogram pooling (pyramid pooling [#b20][11]) technique to summarize the translation matrix it demonstrated that it is more e ective to 'count' the wordlevel translation scores at di erent so match lev </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> a deep relevance matching model for ad-hoc retrieval </p><p> body INTRODUCTIONA recent success of neural methods in information retrieval (neural IR) is the development of interaction based models [#b22][]. Interaction based models thrive with encoding wordword translations using wo. ve with encoding wordword translations using word embeddings, and utilizing new pooling methods to be er summarize the word translations into ranking signals [[#b22]]. Learned endtoend from user feedbacks []re. ion 7. RELATED WORKe current neural IR methods can be categorized into two classes representation based and interaction based [#b22][13]. e earlier a empts of neural IR research were mainly about how to learn good representation of the query and document, and the ranking was simply done by thei. ) technique to summarize the translation matrix it demonstrated that it is more e ective to 'count' the wordlevel translation scores at di erent so match levels, instead of to weightsum them [#b22][13]. e interaction based model and the representation based model can also be combined in a duet architecture [21].Ano. and document words' embeddings. en it uses kernelpooling to summarize the word embeddings and provide so match signals for learning to rank. e kernelpooling shares the advantage of pyramid pooling [#b22][13] that it 'counts' the so matches at multiple levels, while also being di erentiable so that word embeddings and ranking parameters can be learned together. Whe. ooled to a Kdimensional so TF feature vector  (M)  K 1 (M), ..., K K (M). Such countingbased pooling methods have shown be er performance than scorebased ones like meanpooling or maxpooling [#b22][].Kernelpooling is applied to each M h q ,h d matrix in M to generate the so TF feature vector  M h q ,h d , w. , and learningtorank models RankSVM and CoorAscent. Neural IR baselines included CDSSM [26], MatchPyramid (MP) [23], DRMM [#b22][13], and KNRM [29].CDSSM [26] is uses CNNs to build query and document represent. ers in SogouLog [29]). e ranking scores are calculated by the similarity between the representations.MP [23] and DRMM [#b22][13] are both interaction based models built upon the embedding translation matrix. MP uses CNNs to directly combine the translation scores to the ranking score, w. k layers, and can be trained with limited training data. KNRM was tested the same as ConvKNRM in the domain adaption fashion. MP and CDSSM performed worse than DRMM on TREC data in previous studies [#b22][].It is unfair for unsupervised [30] or pseudosupervised ref type"bibr" t. djacent document words, but not their embeddings. Our experiments and prior studies show that counting the frequencies of multilevel so matches are more e ective than weightsumming the similarities [#b22][]"similarity does not necessarily mean relevance" [6].Recall that ConvKNRM </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> e pyramid match kernel: discriminative classi cation with sets of image features </p><p> 29]. Interaction based models thrive with encoding wordword translations using word embeddings, and utilizing new pooling methods to be er summarize the word translations into ranking signals [#b20][]. Learned endtoend from user feedbacks [23,r. ignals in the translation matrix at various levels and are suboptimal for ad hoc search [22].e DRMM model introduces the histogram pooling (pyramid pooling [#b20][11]) technique to summarize the translation matrix it demonstrated that it is more e ective to 'count' the wordlevel translation scores at di erent so match lev </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> neural ranking models with weak supervision </p><p> re recent example is the weakly supervised ranking model in which all word embeddings of a query or document are combined into one vector, and the match of two vectors is done by deep neural networks [#b18][9].e interaction based methods, on the other hand, directly model querydocument matches at the word level.ey are rooted in statistical translation. previous studies [].It is unfair for unsupervised [30] or pseudosupervised [#b18][9] neural IR methods to compete with ConvKNRM, which is trained endtoend with large amount of supervisions.  </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> adapting boosting for information retrieval measures </p><p> imitation on which learning to rank model to use in the target domain. One can leverage the power of any learningtorank model such as RankSVM [16] or LambdaMART [#b37][27].  EXPERIMENTAL METHODOLOGYis section describes our datasets, how training and testing </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> learning semantic representations using convolutional neural networks for web search </p><p> tation of the query and document, and the ranking was simply done by their representations' similarities, for example, DSSM [15] and its convolution version CDSSM [#b36][26]. A more recent example is the weakly supervised ranking model in which all word embeddings of a query or document are combined into one vector, and the match. aselines include Indri's language model (Indri), Galago with sequential dependency model queries (GalagoSDM), and learningtorank models RankSVM and CoorAscent. Neural IR baselines included CDSSM [#b36][26], MatchPyramid (MP) [23], DRMM [13], and KNRM [29]r. target"b36"[26], MatchPyramid (MP) [23], DRMM [13], and KNRM [29].CDSSM [#b36][26] is uses CNNs to build query and document representations on their words' le ertrigrams (or Chinese characters in SogouLog [2 </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> e pyramid match kernel: discriminative classi cation with sets of image features </p><p> 29]. Interaction based models thrive with encoding wordword translations using word embeddings, and utilizing new pooling methods to be er summarize the word translations into ranking signals [#b20][]. Learned endtoend from user feedbacks [23,r. ignals in the translation matrix at various levels and are suboptimal for ad hoc search [22].e DRMM model introduces the histogram pooling (pyramid pooling [#b20][11]) technique to summarize the translation matrix it demonstrated that it is more e ective to 'count' the wordlevel translation scores at di erent so match lev </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> glove: global vectors for word representation </p><p> end of neural IR research is to learn customized word embeddings by and for adhoc ranking. e surrounding text based word embeddings, e.g. word2vec [20] and GloVe [#b34][24], have been questioned about their suitability for ad hoc search []. Diaz et al. train word emb </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> relevance-based word embedding </p><p> 9"29], the word embeddings can encode so matches tailored for relevance ranking, which has signi cant advantages over traditional featurebased methods [[#b40]]. ese initial successes of neural IR were mainly from so matching individual words. On the other hand, the query and document o en match at ngrams, such as phr. pendicesWSDM2018ConvKNRM word2vec in query expansion [10]. e relevance feedback based word embeddings are then also found to be more e ective in ad hoc ranking [#b40][30].KNRM uni ed the progress of IR customized embeddings and interaction based model [29]. It rst embeds words and bu. fashion. MP and CDSSM performed worse than DRMM on TREC data in previous studies [].It is unfair for unsupervised [#b40][30] or pseudosupervised [9] neural IR methods to compete with ConvKNRM, which is trained endtoend with large amount of sup. ed embeddings and matchbased techniques are necessary for current neural IR methods to provide additional improvements [[#b40]] Comparing the two strong neural IR baselines, KNRM outperforms MP by a large margin. Both methods use endtoend learned word embeddings to build the translat </p>
<p> Convolutional Neural Networks for Soft-Matching N-Grams in Ad-hoc Search. </p><p> distributed representations of words and phrases and their compositionality </p><p> a ranking score [4]. e main challenge of translation models is that the wordpair translations are too sparse to learn. To overcome this problem, word embeddings [#b30][20] are introduced to calculate the translation scores [12]. How to combine the wordlevel translation scores to generate que. pe"bibr" target"b31"[21].Another trend of neural IR research is to learn customized word embeddings by and for adhoc ranking. e surrounding text based word embeddings, e.g. word2vec [#b30][20] and GloVe [24], have been questioned about their suitability for ad hoc search [1,ref type"bibr" </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> towards end-to-end speech recognition with recurrent neural networks </p><p> tart DNNs and thus get ride of GMM models. However, this GMMfree approach still requires iterative procedures such as generating forced alignments and decision trees. Meanwhile, another line of work [#b6][6,7,8,9,10,ref ty. br" target"b13"[13] introduce the connectionist temporal classification (CTC) objective function to infer speechlabel alignments automatically. This CTC technique is further investigated in [#b6][] on largescale acoustic modeling tasks. Alth. romising results, research on endtoend ASR faces two major obstacles. First, it is challenging to incorporate lexicons and language models into decoding. When decoding CTCtrained models, past work [#b6][] has successfully constrained search paths with lexicons. However, how to integrate. red experimental platform for the purpose of benchmarking. Endtoend systems described in the literature differ not only in their model architectures but also in their decoding methods. For example, [#b6][6] and [8] adopt two distinct versions of beam search for decoding CTC models. These setup variations hamper rigorous compariso. label and enabling beam search during decoding. Our experiments with the Wall Street Journal (WSJ) benchmark show that Eesen results in superior performance than the existing endtoend ASR pipelines [#b6][]. The WERs of Eesen are on a par with strong hybrid HMMDNN baselines. Moreover, the application of CI modeling targets all. lassificationUnlike in the hybrid approach, the RNN model in our Eesen framework is not trained using framelevel labels with respect to the crossentropy (CE) criterion. Instead, following [#b6][], we adopt the CTC objective [13] to automatic. ns1.0"THE EESEN FRAMEWORK DECODING Decoding with WFSTsPrevious work has introduced a variety of methods [#b6][] to decode CTCtrained models. These methods, however, either fail to integrate wor. methods, however, either fail to integrate wordlevel language models [10] or achieve the integration under constrained conditions (e.g., nbest list rescoring in [#b6][6]). In this work, we propose a generalized decoding approach based on WFSTs []. A W. optimal value is decided empirically. We apply the WSJ standard pruned trigram language model in the ARPA format (which we will consistently refer to as standard). To be consistent with previous work [#b6][], we report our results on the eval92 set. Our experimental setup has been released together with Eesen, which enables the. endtoend system finally achieves the WER of 7.87, with both the lexicon and the language model used in decoding. When only the lexicon is used, our decoding behaves similarly as the beam search in [#b6][6]. In this case, the WER rises quickly to 26.92. This obvious degradation reveals the effectiveness of our decoding approach in integrating language models.. ng letters, digits, punctuation marks, etc. Table 3 shows that with the standard language model, the characterbased system gets the WER of 9.07. CTC experiments in past work [#b6][6] have adopted an expanded vocabulary, and retrained the language model using text data released together with the WSJ corpus. For fair comparison, we follow the. setup, the WER of the Eesen characterbased system is reduced to 7.34.Table 3 lists the results of endtoend ASR systems that have been reported in the previous work [#b6][] and on the same dataset. Our Eesen framework outperforms both [#b6][6] and ref type"bibr". nd ASR systems that have been reported in the previous work [#b6][] and on the same dataset. Our Eesen framework outperforms both [#b6][6] and [8] in terms of WERs on the testing set. It is worth pointing out that the 8.7 WER reported in ref type"bibr" target. mework outperforms both [#b6][6] and [8] in terms of WERs on the testing set. It is worth pointing out that the 8.7 WER reported in [#b6][6] is obtained not in a purely endtoend manner. Instead, the authors of [#b6][6] generate a nbest list of hypotheses from a hybrid. terms of WERs on the testing set. It is worth pointing out that the 8.7 WER reported in [#b6][6] is obtained not in a purely endtoend manner. Instead, the authors of [#b6][6] generate a nbest list of hypotheses from a hybrid DNN model, and apply the CTC model to rescore the hypotheses candidates. Our Eesen numbers, in contrast, come. ark platform for research on endtoend ASR.In our future work, we plan to further improve the WERs of Eesen systems via more advanced learning techniques (e.g., expected transcription loss in [#b6][6]) and alternative decoding approach (e.g., dynamic decoders [31]). Also, we are interested to apply Eesen to various languag </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> speech recognition with deep recurrent neural networks </p><p> hese issues by presenting and publicly releasing our Eesen framework. Acoustic modeling in Eesen is viewed as a sequencetosequence learning problem. We exploit deep recurrent neural networks (RNNs) [#b16][] as the acoustic models, and the Long ShortTerm Memory (LSTM) units [17,ref type </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> phoneme recognition using time-delay neural networks </p><p> e backward LSTM layer can be represented similarly. In this work, we use a purely LSTMbased architecture as the acoustic model. However, combing LSTMs with other network structures, e.g., timedelay [#b24][] or convolutional neural networks [], is </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> context-dependent pre-trained deep neural networks for large-vocabulary speech recognition </p><p> eas GMMs compute the emission probabilities of HMM states. In recent years, the performance of ASR has been improved dramatically by the introduction of deep neural networks (DNNs) as acoustic models [#b0][]. In the hybrid HMMDNN approach, DNNs are used to classify speech frames into cluste </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> weighted finite-state transducers in speech recognition </p><p> r achieve the integration under constrained conditions (e.g., nbest list rescoring in [6]). In this work, we propose a generalized decoding approach based on WFSTs [#b28][]. A WFST is a finitestate acceptor (FSA) in which each transition has an input symbol, an output symbol and a weight. </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> asynchronous, online, gmm-free training of a context dependent acoustic model for speech recognition </p><p> rameters, for instance, the number of senones and Gaussians in the GMM models.Previous work has made various attempts to reduce the complexity of ASR. In [[#b5]], researchers propose to flatstart DNNs and thus get ride of GMM models. However, this GMMfree approach still requires iterative procedures such as generating fo </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> weighted finite-state transducers in speech recognition </p><p> r achieve the integration under constrained conditions (e.g., nbest list rescoring in [6]). In this work, we propose a generalized decoding approach based on WFSTs [#b28][]. A WFST is a finitestate acceptor (FSA) in which each transition has an input symbol, an output symbol and a weight. </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> towards speaker adaptive training of deep neural network acoustic models </p><p> eling in Eesen cannot leverage speaker adapted frontends. We will study new speaker adaptation [] and adaptive training [#b38][] techniques for the CTC models. ACKNOWLEDGEMENTS </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> convolutional, long short-term memory, fully connected deep neural networks </p><p> [] as the acoustic models, and the Long ShortTerm Memory (LSTM) units [[#b20]] as the RNN building blocks. Using the CTC objective function, Eesen simplifies acoustic modeling into learning a single. other network structures, e.g., timedelay [] or convolutional neural networks [[#b20]], is straightforward to achieve. Training with Connectionist Temporal Classification </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> learning precise timing with lstm recurrent networks </p><p> tive gates are added to control the flow of information. Fig. 1 depicts the structure of the LSTM units we use. The blue curves represent peephole connections [#b23][22] that link the memory cells to the gates to learn precise timing of the outputs. The computation at the time step t can be formally written as follows. We omit </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> asynchronous, online, gmm-free training of a context dependent acoustic model for speech recognition </p><p> rameters, for instance, the number of senones and Gaussians in the GMM models.Previous work has made various attempts to reduce the complexity of ASR. In [[#b5]], researchers propose to flatstart DNNs and thus get ride of GMM models. However, this GMMfree approach still requires iterative procedures such as generating fo </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> speaker adaptation of context dependent deep neural networks </p><p> e how endtoend ASR performs under these conditions. Moreover, due to the removal of GMMs, acoustic modeling in Eesen cannot leverage speaker adapted frontends. We will study new speaker adaptation [#b36][] and adaptive training [] techniques for </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> the kaldi speech recognition toolkit </p><p> ed conditions (e.g., nbest list rescoring in [6]). In this work, we propose a generalized decoding approach based on WFSTs [[#b29]]. A WFST is a finitestate acceptor (FSA) in which each transition has an input symbol, an output symbol and a weight. A path Fig. 2. A. e the language model probabilities. With this WFST representation, CTC decoding in principle can leverage any language models that can be converted into WFSTs. Following conventions in the literature [#b29][28], the language model WFST is denoted as G.Lexicon. A lexicon WFST encodes the mapping from sequences of lexicon units to words. Depending on what labels. odels.Table 1 shows a comparison between Eesen and a hybrid HMMDNN system. The hybrid system is constructed by following the standard Kaldi recipe "s5" [#b29][28]. Inputs of the DNN model are 11 neighboring frames of filterbank features. The DNN has 6 hidden layers and 1024 units at each layer. This DNN model contains s </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p>  </p><p>  </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p>  </p><p>  </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> a novel objective function for improved phoneme recognition using time-delay neural networks </p><p> similarly. In this work, we use a purely LSTMbased architecture as the acoustic model. However, combing LSTMs with other network structures, e.g., timedelay [[#b25]] or convolutional neural networks [], is straightforward to achieve. d </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> long shortterm memory </p><p> We exploit deep recurrent neural networks (RNNs) [] as the acoustic models, and the Long ShortTerm Memory (LSTM) units [#b18][] as the RNN building blocks. Using the. training RNNs to learn longterm temporal dependency can be difficult due to the vanishing gradients problem [21]. To overcome this issue, we apply the LSTM units [#b18][17] as the building blocks of RNNs. LSTM contains memory cells with selfconnections to store the temporal states of the network. Also, multiplicative gates are a </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks </p><p> f has focused on endtoend ASR, i.e., modeling the mapping between speech and labels (words, phonemes, etc.) directly without any intermediate components (e.g., GMMs). On this aspect, Graves et al. [#b13][13] introduce the connectionist temporal classification (CTC) objective function to infer speechlabel alignments automatically. This CTC technique is further inv.  THE EESEN FRAMEWORK MODEL TRAININGAcoustic models in Eesen are deep bidirectional RNNs trained with the CTC objective function [#b13][13]. We describe the model structure in Section 2.1, and restate key points of CTC training in Section 2.2. Section 2.3 presents some practical considerations eme. the crossentropy (CE) criterion. Instead, following [], we adopt the CTC objective [#b13][13] to automatically learn the alignments between speech frames and their label sequences (e.g., phonemes or characters). Assume that the label sequences in the t. ed to the frames, it is difficult to evaluate the likelihood of z given the RNN outputs. To bridge the RNN outputs with label sequences, an intermediate representation, the CTC path, is introduced in [#b13][13]. A CTC path p  (p 1 , ..., p T ) is a sequence of labels at the frame level. It differs from z in that the CTC path allows occurrences of the blank label and. labels are estimated. However, this method does not perform well in our experiments. Part of the reason is that the softmaxlayer outputs from a CTCtrained model display a highly peaky distribution [#b13][]. That is, a majority of the frames have the blank as their labels. The activation of the nonblank labels only appears </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> the kaldi speech recognition toolkit </p><p> ed conditions (e.g., nbest list rescoring in [6]). In this work, we propose a generalized decoding approach based on WFSTs [[#b29]]. A WFST is a finitestate acceptor (FSA) in which each transition has an input symbol, an output symbol and a weight. A path Fig. 2. A. e the language model probabilities. With this WFST representation, CTC decoding in principle can leverage any language models that can be converted into WFSTs. Following conventions in the literature [#b29][28], the language model WFST is denoted as G.Lexicon. A lexicon WFST encodes the mapping from sequences of lexicon units to words. Depending on what labels. odels.Table 1 shows a comparison between Eesen and a hybrid HMMDNN system. The hybrid system is constructed by following the standard Kaldi recipe "s5" [#b29][28]. Inputs of the DNN model are 11 neighboring frames of filterbank features. The DNN has 6 hidden layers and 1024 units at each layer. This DNN model contains s </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> towards speaker adaptive training of deep neural network acoustic models </p><p> eling in Eesen cannot leverage speaker adapted frontends. We will study new speaker adaptation [] and adaptive training [#b38][] techniques for the CTC models. ACKNOWLEDGEMENTS </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p> phoneme recognition using time-delay neural networks </p><p> e backward LSTM layer can be represented similarly. In this work, we use a purely LSTMbased architecture as the acoustic model. However, combing LSTMs with other network structures, e.g., timedelay [#b24][] or convolutional neural networks [], is </p>
<p> eesen: end-to-end speech recognition using deep rnn models and wfst-based decoding </p><p>  </p><p>  </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> neural machine translation with reconstruction </p><p> xiliary data are beneficial only to a limited extent, and that direct multitask models are still heavily dependent on the endtoend data.As our second contribution, we apply a twostage model [#b23](Tu et al., 2017Kano et al., 2017) as an alternative solution to our problem, hoping that such models may overcome the data e. as that guides the complex transformation between source speech and target text through a reasonable intermediate representation closely tied to the source text. The architecture has been proposed by [#b23]Tu et al. (2017) to realize a reconstruction objective, and a similar model was also applied to speech translation (Kano et al., 201. Our main motivation for using this model is the potentially improved data efficiency when adding auxiliary ASR and MT training data ( 3). This model is similar to the architecture first described by [#b23]Tu et al. (2017). It combines two encoderdecoder models in a cascadelike fashion, with the decoder of the first stage and the encoder of the second stage being s. www.teic.orgns1.0" place"foot" n"8" xmlid"foot_7"For twostage and attentionpassing models, we apply beam search only for the second stage decoder. We do not use the twophase beam search of[#b23]Tu et al. (2017) because of its prohibitive memory requirements. Note that </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> neural machine translation by jointly learning to align and translate </p><p> types of endtoend trainable models for speech translation, along with a cascaded approach, which will serve as our baselines. All models are based on the attentional encoderdecoder architecture of [#b3]Bahdanau et al. (2015) with characterlevel outputs, and use the architecture described in 2.1 as audio encoders. The endtoend trainable models include a direct </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> many languages, one parser </p><p>  </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> multitask learning with low-level auxiliary tasks for encoder-decoder based speech recognition </p><p>  </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> tied multitask learning for neural speech translation </p><p> uencetosequence model instead (Duong et al., 2016Weiss et al., 2017Brard et al., 2018[#b2]Anastasopoulos and Chiang, 2018). An appealing property of such direct models is that we no longer suffer from propagation of errors, where the speech recognizer pa. ef type"bibr" target"b10"(Kano et al., 2017Brard et al., 2018), and one work in favor of direct models for two out of the three examined language pairs [#b2](Anastasopoulos and Chiang, 2018). (2) Cascaded and direct models have been compared under identical data situations, but this is an unrealistic assumption In prac. as been investigated previously (Weiss et al., 2017Kano et al., 2017Brard et al., 2018[#b2]Anastasopoulos and Chiang, 2018), but with contradictory findings. We hypothesize that the increased complexity of the direct mapping from speech to translation inc. tly simplifies training and may not lead to generalizable conclusions, as indicated by the fact that they were actually able to outperform a translation model that used the gold transcripts as input. [#b2]Anastasopoulos and Chiang (2018) conducted experiments on lowresource speech translation and used a triangle model that can be seen as a combination of a direct mo </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> local monotonic attention mechanism for end-to-end speech recognition </p><p> e impact is still more significant than perhaps expected, suggesting that improved attention models that are more robust to decoding errors (Chorowski et al., 2015[#b21]Tjandra et al., 2017) may serve to further improve our model in the future. Note that the APM benefits poorly from gold ASR labels, which is expected because gold </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> improved speech-totext translation with the fisher and callhome spanish-english speech translation corpus </p><p> y the audio encoder as and MT corpora exist and for which it is more realistic to obtain good speech translation accuracy.2 As a case in point, the largest available speech translation corpora [#b18](Post et al., 2013Kocabiyikoglu et al., 2018) are an order of magnitude smaller than the largest speech recognition corpora ref type"bibr. oss in our experiments. ExperimentsWe conduct experiments on the Fisher and Callhome SpanishEnglish Speech Translation Corpus [#b18](Post et al., 2013), a corpus of Spanish telephone conversations that includes audio, transcriptions, and translations into English. We use the Fisher portion that </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> attention-based models for speech recognition </p><p> .1"Audio EncoderSequencetosequence models can be adopted for audio inputs by directly feeding speech features (here, Mel filterbank features) instead of word embeddings as encoder inputs [#b7](Chorowski et al., 2015Chan et al., 2016). Such an encoder transforms M feature vectors x 1M into L encoded vectors e 1L , pe. he translation submodel, is much less impacted. However, the impact is still more significant than perhaps expected, suggesting that improved attention models that are more robust to decoding errors [#b7](Chorowski et al., 2015Tjandra et al., 2017) may serve to further improve our model in the future. Note that the APM benefits </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> many languages, one parser </p><p>  </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> very deep convolutional networks for end-to-end speech recognition </p><p> ch an encoder transforms M feature vectors x 1M into L encoded vectors e 1L , performing downsampling such that LltM . We use an encoder architecture that follows one of the variants described by [#b26]Zhang et al. (2017) We stack two blocks, each consisting of a bidirectional long shortterm memory (LSTM), a networkinnetwork (NiN) projection that downsamples. d at every time step, performing downsampling by concatenating pairs of adjacent projection inputs. Because of space constraints, we do not present detailed equations, but refer interested readers to [#b26]Zhang et al. (2017) as well as to our provided code for details. Direct ModelThe sequenc </p>
<p> attention-passing models for robust and data-efficient end-to-end speech translation </p><p> local monotonic attention mechanism for end-to-end speech recognition </p><p> e impact is still more significant than perhaps expected, suggesting that improved attention models that are more robust to decoding errors (Chorowski et al., 2015[#b21]Tjandra et al., 2017) may serve to further improve our model in the future. Note that the APM benefits poorly from gold ASR labels, which is expected because gold </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> end-to-end automatic speech translation of audiobooks </p><p> end systems. Recently explored techniques to mitigate this issue include multitask learning [] and pretrained components [#b10][11] in order to utilize weakly supervised data, i.e. speechtotranscript or texttotranslation pairs, in contrast to fully supervised speechtotranslation pair.  use multitask learning to train the ST model jointly with the ASR andor the MT model. By doing so, both of them achieved better performance with the endtoend model than the cascaded model. [#b10][11] conducts experiments on a larger 236 hour EnglishtoFrench dataset and pretrains the encoder and decoder prior to multitask learning, which further improve. r decoder directly on the 1M ST set. We then adopt pretraining and multitask learning as proposed in previous literature [[#b10]] in order to improve its performance. We pretrain the encoder on the ASR task, and the decoder on the MT task as descri </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> tied multitask learning for neural speech translation </p><p> This is often a limiting factor for the performance of such endtoend systems. Recently explored techniques to mitigate this issue include multitask learning [[#b9]] and pretrained components [11] in order to utilize weakly supervised data, i.e. speechtotranscript or texttotranslatio. type"bibr" target"b7"[].In order to utilize both fully supervised data and also weakly supervised data, [[#b9]] use multitask learning to train the ST model jointly with the ASR andor the MT model. By doing so, both of them achieved better performance with the endtoen. el with a 5layer encoder and an 8layer decoder directly on the 1M ST set. We then adopt pretraining and multitask learning as proposed in previous literature [[#b9]] in order to improve its performance. We pretrain the encoder on the ASR task, a </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> the best of both worlds: combining recent advances in neural machine translation </p><p> idirectional LSTM with cell size 1024. The attention is 4head additive attention. The model takes 80channel log mel spectrogram features as input. MT model Our MT model follows the architecture of [#b22][23]. We use a 6 layer bidirectional LSTM encoder, with cell size of 1024. The decoder is an 8 layer unidirectional LSTM with cell size 1024, with residual connect </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> on the properties of neural machine translation: encoder-decoder approaches </p><p> ly in sequencetosequence modeling have led to dramatic improvements in ASR [] and MT [[#b3]] tasks. These successes naturally led to attempt </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> multi-modal data augmentation for end-to-end asr </p><p> ormance. [17] builds a cycle chain between TTS and ASR models, in which the output from one model is used to help the training of the other. Instead of using TTS, [#b17][18]  The MT synthetic data in this work helps the system in a manner similar to knowledge distillation [20], since the networ </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> speech translation: coupling of recognition and translation </p><p> toend ST performance. RELATED WORKEarly work on speech translation typically used a cascade of an ASR model and an MT model [#b11][], giving the MT model access to the predicted probabilities and uncertainties f </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> sequence-to-sequence models can directly translate foreign speech </p><p> br" target"b6"7] tasks. These successes naturally led to attempts to construct endtoend speechtotext translation systems as a single neural network [[#b8]]. Such endtoend systems have advantages over a traditional cascaded system that performs ASR and MT consecutively in that they 1) naturally avoid compounding er. an acquiring data for ASR and MT tasks. This is often a limiting factor for the performance of such endtoend systems. Recently explored techniques to mitigate this issue include multitask learning [#b8][] and pretrained components [11] in order to utilize weakly supervised data, i.e. spe. , giving the MT model access to the predicted probabilities and uncertainties from the ASR. Recent work has focused on training endtoend ST in a single model [[#b8]].In order to utilize both fully supervised data and also weakly supervised data, [#b8][]. ng endtoend ST in a single model [[#b8]].In order to utilize both fully supervised data and also weakly supervised data, [#b8][] use multitask learning to train the ST model jointly with the ASR andor the MT model. By doing so, both of them achieve. ng speech inputs using TTS is more similar to MT backtranslation [21]. MODELSSimilar to [#b8][9], we make use of three sequencetosequence models. Each one is composed of an encoder, a decoder, and an attention module. Besides the endtoend ST model which. We train a vanilla endtoend ST model with a 5layer encoder and an 8layer decoder directly on the 1M ST set. We then adopt pretraining and multitask learning as proposed in previous literature [#b8][] in order to improve its performance. We p </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> sequence to sequence learning with neural networks </p><p> es in deep learning and more specifically in sequencetosequence modeling have led to dramatic improvements in ASR [] and MT [#b2][] tasks. T </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> state-of-the-art speech recognition with sequence-to-sequence models </p><p> ead n"1."INTRODUCTIONRecent advances in deep learning and more specifically in sequencetosequence modeling have led to dramatic improvements in ASR [[#b1]] and MT [3,4,5,6,. represent text using the same shared EnglishSpanish Word Piece Model (WPM) [22] containing 16K tokens.ASR model Our ASR model follows the architecture of [#b1][2]. We use a 5 layer bidirectional LSTM encoder, with cell size 1024. The decoder is a 2 layer unidirectional LSTM with cell size 1024. The attention is 4head add. al dataset can be directly used to train the endtoend ST model. We use data augmentation on both speech corpora by adding varying degrees of background noise and reverberation in the same manner as [#b1][2]. The WPM shared among all models is trained with the 70M MT set.We use two datasets for evaluation a held out subset of 10.8K examples from the 1M ST se </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> sequence to sequence learning with neural networks </p><p> es in deep learning and more specifically in sequencetosequence modeling have led to dramatic improvements in ASR [] and MT [#b2][] tasks. T </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> the best of both worlds: combining recent advances in neural machine translation </p><p> idirectional LSTM with cell size 1024. The attention is 4head additive attention. The model takes 80channel log mel spectrogram features as input. MT model Our MT model follows the architecture of [#b22][23]. We use a 6 layer bidirectional LSTM encoder, with cell size of 1024. The decoder is an 8 layer unidirectional LSTM with cell size 1024, with residual connect </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> improved speech-to-text translation with the fisher and callhome spanish-english speech translation corpus </p><p> n"2."RELATED WORKEarly work on speech translation typically used a cascade of an ASR model and an MT model [[#b13]], giving the MT model access to the predicted probabilities and uncertainties from the ASR. Recent work has focused on training endtoend ST in a single model </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> on the properties of neural machine translation: encoder-decoder approaches </p><p> ly in sequencetosequence modeling have led to dramatic improvements in ASR [] and MT [[#b3]] tasks. These successes naturally led to attempt </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> deep voice 3: 2000-speaker neural text-to-speech </p><p> Synthesis with TTS modelRecent TTS systems are able to synthesize speech with close to human naturalness [24], in varied speakers' voices [#b24][25], create novel voices by sampling from a continuous speaker embedding space [26].In this work, we use the TTS model </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> improving neural machine translation models with monolingual data </p><p> e"bibr" target"b19"[20], since the network is trained to predict outputs from a pretrained MT model. In contrast, synthesizing speech inputs using TTS is more similar to MT backtranslation [#b20][21]. MODELSSimilar to [9], we make use of three sequ </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> signal estimation from modified shorttime fourier transform </p><p> [26].In this work, we use the TTS model trained on LibriSpeech [27] from [26], except that we use a GriffinLim [#b27][28] vocoder as in [29] which has significantly lower cost, but results in reduced audio quality ref type"foot" target"foo </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> japanese and korean voice search </p><p> baseline cascaded ST model, as well as for multitask learning and encoder  decoder pretraining for ST. All three models represent text using the same shared EnglishSpanish Word Piece Model (WPM) [#b21][22] containing 16K tokens.ASR model Our ASR model follows the architecture of [2]. We use a 5 layer bidirectional LSTM </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> natural tts synthesis by conditioning wavenet on mel spectrogram predictions </p><p> R training corpus. Synthesis with TTS modelRecent TTS systems are able to synthesize speech with close to human naturalness [#b23][24], in varied speakers' voices [25], create novel voices by sampling from a continuous speaker embedding space ref type"bi. e the importance of using a high quality multispeaker TTS system to synthesize training data with wide speaker variation, we train models using data synthesized with the single speaker TTS model from [#b23][24]. This model generates more natural speech than the multispeaker model used in Sec. 5.4 [26]. To ensure a fair comparison </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> distilling the knowledge in a neural network </p><p> d to help the training of the other. Instead of using TTS, [18]  The MT synthetic data in this work helps the system in a manner similar to knowledge distillation [#b19][20], since the network is trained to predict outputs from a pretrained MT model. In contrast, synthesizing speech inputs using TTS is more similar to MT backtran. ate the transcripts in an ASR training set into the target language. In this work, we use the Google Translate service to obtain such translations. This procedure is similar to knowledge distillation [#b19][20], except that it uses the final predictions as training targets rather than the predicted probability distributions. div xmlns"httpwww.teic.org </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> listen and translate: a proof of concept for end-to-end speech-to-text translation </p><p> ibr" target"b5"6,7] tasks. These successes naturally led to attempts to construct endtoend speechtotext translation systems as a single neural network [#b7][]. Such endtoend systems have advantages over a traditional cascaded system that performs ASR and MT consecutively in that. 14], giving the MT model access to the predicted probabilities and uncertainties from the ASR. Recent work has focused on training endtoend ST in a single model [#b7][].In order to utilize both fully supervised data and also weakly supervised data, [9,. can improve ST quality on a different source language.Using TTS synthetic data for training speech translation was a requirement when no direct parallel training data is available, such as in [#b7][]. In contrast, we show that even when a large fully supervised training set is available, using synthetic training data f </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> on the properties of neural machine translation: encoder-decoder approaches </p><p> ly in sequencetosequence modeling have led to dramatic improvements in ASR [] and MT [[#b3]] tasks. These successes naturally led to attempt </p>
<p> leveraging weakly supervised data to improve end-to-end speech-to-text translation </p><p> listen, attend and spell: a neural network for large vocabulary conversational speech recognition </p><p> xmlns"httpwww.teic.orgns1.0"INTRODUCTIONRecent advances in deep learning and more specifically in sequencetosequence modeling have led to dramatic improvements in ASR [#b0][] and MT [3,4,5, </p>
<p> motifs in temporal networks </p><p> higher-order organization of complex networks </p><p> based on generalizing the notion of network motifs to temporal networks. In static networks, network motifs or graphlets are defined as small induced subgraphs occurring in a bigger network structure [#b4][]. We extend static motifs to temporal networks and define ?temporal motifs, whe. b25"[]. Furthermore, motifs are critical for understanding the higherorder organizational patterns in networks [[#b4]]. On the algorithmic side, a large amount of research has been devoted simply to counting triangles in undirected static graphs [14 </p>
<p> motifs in temporal networks </p><p> graph evolution: densification and shrinking diameters </p><p> ting methods either model the networks as strictly growing where a pair of nodes connect once and stay connected forever [[#b17]] or aggregate temporal information into a sequence of snapshots [1,6,ref type"bibr" ta. pe"table" target"tab_3"1. The time resolution of the edges in all datasets is one second. EMAILEU. This dataset is a collection of emails between members of a European research institution [#b17][17]. An edge (u, v, t) signifies that person u sent person v an email at time t. PHONECALLEU. This dataset was constructed from telephone call records for a majo </p>
<p> motifs in temporal networks </p><p> patterns and dynamics of users' behavior and interaction: network analysis of an online community </p><p> age to person v at time t [28]. COLLEGEMSG. This dataset is comprised of private messages sent on an online social network at the University of California, Irvine [#b21][21]. Users could search the network for others and then initiate conversation based on profile information. An edge (u, v, t) means that user u sent a private mes </p>
<p> motifs in temporal networks </p><p> revealing the hidden language of complex networks </p><p> tic networks, network motifs or graphlets are defined as small induced subgraphs occurring in a bigger network structure [[#b29]]. We extend static motifs to temporal networks and define ?temporal motifs, where all the edges in a given motif M have to occur inside the time period of ? t. ed crucial to understanding the mechanisms driving complex systems [19] and to characterizing classes of static networks [[#b29]]. Furthermore, motifs are critical for understanding the higherorder organizational patterns in networks [3,ref type"bibr. the same domain have similar counts. Static graphs from similar domains tend to have similar motif count distributions [[#b29]]. Here, we find similar results in temporal networks. We formed two collections of datasets from similar domains. First, we took subsets of the EMAILEU dataset </p>
<p> motifs in temporal networks </p><p> a framework for community identification in dynamic social networks </p><p> et"b10"10,17] or aggregate temporal information into a sequence of snapshots [[#b23]]. These techniques fail to fully capture the richness of the temporal information in the data.Characterizing temporal networks also brings a number of in </p>
<p> motifs in temporal networks </p><p> temporal motifs in time-dependent networks </p><p> edge ordering [30], only have heuristic counting algorithms [7], or assume temporal edges in a motif must be consecutive events for a node [#b13][13]. In the last case, the restrictive definition permits fast counting algorithms but misses important structures. For example, many related edges occurring in a. thmic design challenge. There is also a host of theoretical questions in this area for lower bounds on temporal motif counting. Finally, motif counts can also be measured with respect to a null model [#b13][]. Such analysis may yield additional discoveries. Importantly, our algorithms will speed up such computations, which us </p>
<p> motifs in temporal networks </p><p> main-memory triangle computations for very large (sparse (power-law)) graphs </p><p> type"bibr" target"b3"[]. On the algorithmic side, a large amount of research has been devoted simply to counting triangles in undirected static graphs [#b14][14].Prior definitions of temporal network motifs either do not account for edge ordering [30], only have heuristic cou </p>
<p> motifs in temporal networks </p><p> the structure and function of complex networks </p><p> INTRODUCTIONNetworks provide an abstraction for studying complex systems in a broad set of disciplines, ranging from social and communication networks to molecular biology and neuroscience [#b20][20]. Typically, these systems are modeled as static graphs that describe relationships between objects (nodes) and links between the objects (edges). However, man </p>
<p> motifs in temporal networks </p><p> the topological relationship between the large-scale attributes and local interaction patterns of complex networks </p><p> atic graphs, where these models have proved crucial to understanding the mechanisms driving complex systems [19] and to characterizing classes of static networks [#b25][]. Furthermore, motifs are critical for understanding the higherorder organizational patterns in networks ref type"bi. d expect cyclic behavior. Datasets from the same domain have similar counts. Static graphs from similar domains tend to have similar motif count distributions [[#b25]]. Here, we find similar results in temporal networks. We formed two collections of datasets from similar domains. First, </p>
<p> motifs in temporal networks </p><p> commit: a scalable approach to mining communication motifs from dynamic networks </p><p>  </p>
<p> motifs in temporal networks </p><p> a framework for community identification in dynamic social networks </p><p> et"b10"10,17] or aggregate temporal information into a sequence of snapshots [[#b23]]. These techniques fail to fully capture the richness of the temporal information in the data.Characterizing temporal networks also brings a number of in </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> you are who you know: inferring user profiles in online social networks </p><p> ion of communities or the identification of key individuals within a network. For all their benefits, the widespread use of such tools raises legitimate privacy concerns. For instance, Mislove et al. [#b22][24] demonstrated how, by analysing Facebook's social network structure, as well as the attributes of some users, it is possible to infer otherwiseprivate informa </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> reverse-engineering censorship in china: randomized experimentation and participant observation </p><p> o1 arXiv1608.00375v1 [cs.SI] 1 Aug 2016 cial networking sites and other internet content is policed, and antigovernmental blogs and activities are censored [[#b16]].Against this background, we ask the question can individuals or communities proactively manage their social connections so that their privacy is less e </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> mapping networks of terrorist cells </p><p> ition of this link cannot Figure 1 Executing the ROAM heuristic twice on the 911 terrorist network to hide Mohamed Attaone of the ringleaders of the attack [#b17][19]. The red link is the one to be to removed by the algorithm, and the dashed links are the ones to be added. increase the betweenness centrality of v  beyond i. c.orgns1.0"Data setsWe experiment with two types of reallife networks (a). Covert organizations we consider three terrorist network, responsible for the WTC 911 attacks [#b17][19] the 2002 Bali attack [13] and the 2004 Madrid train bombings [13](b). Soci </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> an improved index of centrality </p><p> entrality measure [11] is a function c  G  V  R. The degree centrality [32] is denoted by c degr , the closeness centrality [#b3][5] is denoted by c clos , and the betweeness centrality [] is denoted by c betw . Speci </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> computing communities in large networks using random walks </p><p> hms implemented in the igraph package of the R language (version 1.0.1), namely Eigenvector [25], Betweenness [26], Walktrap [#b27][29], Louvain [6], Greedy [7], Infomap [31] and Spingl </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> a set of measures of centrality based on betweenness </p><p> t"b30"[32] is denoted by c degr , the closeness centrality [5] is denoted by c clos , and the betweeness centrality [[#b8]] is denoted by c betw . Specifically, given a node v i  V and an undirected network, we havec degr (G, v i )  N G (v i ) n </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> a comparison of community detection algorithms on artificial networks </p><p> Viewed from a different perspective, our work can be seen as an extension of the sensitivity analyses of centrality measures [8] and community detection algorithms [#b26][28] while such analyses typically consider the effects of small network alterations, we consider changes that are much wider in scope, and strategic in nature. </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> visual reasoning about social networks using centrality sensitivity. visualization and computer graphics </p><p> using simple heuristics that are readilyimplementable even by lay people. Viewed from a different perspective, our work can be seen as an extension of the sensitivity analyses of centrality measures [#b6][8] and community detection algorithms [28] while such analyses typically consider the effects of small network alterations, w </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> visual reasoning about social networks using centrality sensitivity. visualization and computer graphics </p><p> using simple heuristics that are readilyimplementable even by lay people. Viewed from a different perspective, our work can be seen as an extension of the sensitivity analyses of centrality measures [#b6][8] and community detection algorithms [28] while such analyses typically consider the effects of small network alterations, w </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> group structure and the behavior of individuals in small groups </p><p> CS C i  V , and  Ci,Cj CS C i  C j  .Centrality Measures Formally, a centrality measure [11] is a function c  G  V  R. The degree centrality [#b30][32] is denoted by c degr , the closeness centrality [5] is denoted by c clos , and the betweeness centrality ref type"bibr" </p>
<p> Hiding Individuals and Communities in a Social Network </p><p> on random graphs i </p><p> "b31"[33]. We write SmallWorld (x, y, z) where x is the number of nodes y is the average degree z is the rewiring probability(c). Random graphs generated using the ErdosRenyi model [#b7][9]. We write RandomGraph(x, y) where x is the number of nodes y is the expected average degree.For each type of randomlygenerated networks, we report the </p>
<p>  Deep high-resolution representation learning for  </p><p> deep high-resolution representation learning for human pose estimation </p><p> liable highresolution representations through repeatedly fusing the representations from multiresolution streams. This paper represents a very substantial extension of our previous conference paper [#b105][105] with an additional material added from our unpublished technical report [106] as well as more object detection results. "b106"[106] as well as more object detection results under recentlydeveloped startoftheart object detection and instance segmentation frameworks. The main technical novelties compared with [#b105][105] lie in threefold. (1) We extend the network (named as HRNetV1) proposed in [#b105][105],. . The main technical novelties compared with [#b105][105] lie in threefold. (1) We extend the network (named as HRNetV1) proposed in [#b105][105], to two versions HRNetV2 and HRNetV2p, which explore all the fourresolution representations. (2) We build the connecti </p>
<p>  Deep high-resolution representation learning for  </p><p> convolutional neural fabrics </p><p> [110].Maintaining highresolution representations. Our work is closely related to several works that can also generate highresolution representations, e.g., convolutional neural fabrics [#b98][98], interlinked CNNs [150], GridNet [29], and multiscale DenseNet ref type"bibr" tar. rget"b150"[150], GridNet [29], and multiscale DenseNet [43].The two early works, convolutional neural fabrics [#b98][98] and interlinked CNNs [150], lack careful design on when to start lowresolution parallel streams, and how and where to e. " target"b19"[19], [29], [43], [50], [97], [#b98][98], [127], [130], [144], ref type"bibr" targe </p>
<p>  Deep high-resolution representation learning for  </p><p> semantic correlation promoted shape-variant context for segmentation </p><p>  </p>
<p>  Deep high-resolution representation learning for  </p><p> nu-net: deep residual wide field of view convolutional neural network for semantic segmentation </p><p> " target"b15"[15], [19], [29], [43], [50], [#b97][97], [98], [127], [130], ref type"bibr" target </p>
<p>  Deep high-resolution representation learning for  </p><p> interleaved group convolutions </p><p> ules are repeated several times which is inspired by deep fusion [104], [117], [126], [#b141][141], [147].Our approach. Our network connects hightolow convolution streams in parallel. It maintains highresolu. multibranch fullconnection form of the regular convolution, illustrated in Figure 5 (c). A regular convolution can be divided as multiple small convolutions as explained in [#b141][141]. The input channels are divided into several subsets, and the output channels are also divided into several subsets. The input and output subsets are connec </p>
<p>  Deep high-resolution representation learning for  </p><p> path aggregation network for instance segmentation </p><p> our network to stateoftheart singlemodel object detectors on COCO testdev without using multiscale training and multi  scale testing that are done in [65], [#b77][77], [88], [93], [102], ref type"bibr" target" </p>
<p>  Deep high-resolution representation learning for  </p><p> look at boundary: a boundary-aware face alignment algorithm </p><p> yramid representations [18], [125] stacking multiple DeconvNetsUNetsHourglass [31], [#b122][122] with dense connections [110].Maintaining highresolution representations. Our work is closely related to severa </p>
<p>  Deep high-resolution representation learning for  </p><p> multiposenet: fast multiperson pose estimation using pose residual network </p><p>  </p>
<p>  Deep high-resolution representation learning for  </p><p> deepercut: a deeper, stronger, and faster multi-person pose estimation model </p><p> "[5], [19], [72], [124], possibly with dilated convolutions used in the backbone [#b47][47], [69], [91] light downsample and heavy upsample processes ref type"bibr" target" </p>
<p>  Deep high-resolution representation learning for  </p><p> full-resolution residual networks for semantic segmentation in street scenes </p><p> target"b131"[131], [132], encoderdecoder [90], and so on. An extension of UNet, fullresolution residual network [#b92][92], introduces an extra fullresolution stream that carries information at the full image resolution, to replace the skip connections, and each unit in the downs </p>
<p>  Deep high-resolution representation learning for  </p><p> interleaved group convolutions </p><p> ules are repeated several times which is inspired by deep fusion [104], [117], [126], [#b141][141], [147].Our approach. Our network connects hightolow convolution streams in parallel. It maintains highresolu. multibranch fullconnection form of the regular convolution, illustrated in Figure 5 (c). A regular convolution can be divided as multiple small convolutions as explained in [#b141][141]. The input channels are divided into several subsets, and the output channels are also divided into several subsets. The input and output subsets are connec </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> execution cache-based microarchitecture power-efficient superscalar processors </p><p> s time scheduling the same small subset of the static program, and moreover tends to create the same cyclebycycle schedule repeatedly. Caching these schedules is the motivation for Execution Caching [#b46][47], to allow the scheduler to be shut down (which they argue produces power savings) some of the time.Our work extends this intuition in several ways. Fir. research efforts to capturereuse these schedules or to allow a compilerruntime to indicate when dynamic schedules should be generated. The major motivation in this regard has been energy savings, [#b46][], generally at the cost of performance degradation though offthecriticalpath HW rescheduling of ROB traces in ref ty. st be noted that these approaches invariably execute a significant percentage of their instructions via the dynamic scheduler (upwards of 70, 45 and 20 for [[#b46]] respectively) rather than executing the captured OOO traces on the inorder HW . Our own experiments suggest that even </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> performance characterization of a hardware framework for dynamic optimization </p><p> circuit limitations on OOO cycle times as well as concerns over object compatibility with the proposed simpler hardware.Industry RampD [12] and academia [#b12][13] were exploring this middleground between statically and dynamically scheduled hardware, ("quasidynamic scheduling" in the parlance of rePLay ref type"bibr </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> itanium processor microarchitecture </p><p> cally scheduled hardware, ("quasidynamic scheduling" in the parlance of rePLay [35]) while contemporaneous commercial processors at two extremes were the Itanium [#b39][40] and Transmeta processors [27]. Both the Itanium and Transmeta designs provide extensive hardware support for software spe </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> synergistic processing in cell's multicore architecture </p><p> "[29] have been proposed that separate the computation of a branch outcome from the branch's role as a basic block boundary IBM's Cell processor is a recent example employing such a mechanism [#b18][19] Branch MispredictionOne of the fundamental advantages of dynamic scheduling over static schedules is that ability of the dynamic scheduler to "ramp up </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> limits of instruction-level parallelism </p><p> re [[#b49]]. While insightful and prescient in many respects especially regarding the scalability of dynamically scheduled hardware, the small memory footprints and low br </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> itanium 2 processor microarchitecture </p><p> t"b8"[9] while Itanium exposes explicit rollback and recovery to software. Subsequently, Itanium designs have refinedexpanded their HW structures to permit more control and data speculation [#b30][31] and the most recently announced version has greater HW support for dynamism [48] in a manner explored by ref type"bibr" </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> replay: a hardware framework for dynamic optimization </p><p>  and academia [13] were exploring this middleground between statically and dynamically scheduled hardware, ("quasidynamic scheduling" in the parlance of rePLay [#b34][35]) while contemporaneous commercial processors at two extremes were the Itanium [40] and Transmeta processors ref type"bi </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> static placement, dynamic issue (spdi) scheduling for edge architectures </p><p> ctions to latencyspecific queues based on latency information encoded into the instructions at compile time [18] to more dataflow oriented ISAs and associated HW [#b31][32] though all come at the cost of significantly higher HW complexity and instruction encoding bloat.Solutions for handling variable latency loads in gener </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> increasing the size of atomic instruction blocks using control flow assertions </p><p> f are all well known, often profiledriven global scheduling techniques employed by static compilers. Incremental CommitNonAtomic Traces [51] and Atomic Frames [#b35][36] are techniques employed by runtimes to dynamically optimize binaries the first three techniques require modest amounts of HW support the last two require fa </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> ibm power6 microarchitecture </p><p> determinism of the memory hierarchy, the MLP advantage seems to be what is motivating the trend towards OOO designs. Recent inorder processors have explicitly incorporated HW features to "buy back" [#b27][28] this loss of MLP relative to the OOO including runahead execution (Power6) and Subordinate scout threading (Rock) [22]. </p>
<p> discerning the dominant out-of-order performance  advantage: is it speculation or dynamism? </p><p> replay: a hardware framework for dynamic optimization </p><p>  and academia [13] were exploring this middleground between statically and dynamically scheduled hardware, ("quasidynamic scheduling" in the parlance of rePLay [#b34][35]) while contemporaneous commercial processors at two extremes were the Itanium [40] and Transmeta processors ref type"bi </p>
<p> Deep Variational Information Bottleneck. </p><p> the information bottleneck method </p><p>       We present a variational approximation to the information bottleneck of [#b33]Tishby et al. (1999). This variational approach allows us to parameterize the information bottleneck model using a neural network and leverage the reparameterizati. being maximally compressive about X, where   0 controls the tradeoff. 3 This approach is known as the information bottleneck (IB), and was first proposed in [#b33]Tishby et al. (1999). Intuitively, the first term in R IB encourages Z to be predictive of Y  the second term encourages Z to "forget" X. Essentially it forces Z. n drawback of the IB principle is that computing mutual information is, in general, computationally challenging. There are two notable exceptions the first is when X, Y and Z are all discrete, as in [#b33]Tishby et al. (1999) this can be used to cluster discrete data, such as words. The second case is when X, Y and Z are all jointly Gaussian ref type"bibr" target </p>
<p> Deep Variational Information Bottleneck. </p><p> explaining and harnessing adversarial examples </p><p>  </p>
<p> Deep Variational Information Bottleneck. </p><p> predictive information in a sensory population </p><p> Y the future, while Z is the current representation of the network. This form of the information bottleneck is known as predictive information(Bialek et al., 2001[#b24]Palmer et al., 2015). The attacks still often cause the VIB model to miscla </p>
<p> Deep Variational Information Bottleneck. </p><p> variational information maximisation for intrinsically motivated reinforcement learning </p><p> blem. Variational bounds on mutual information have previously been explored in Agakov (2004), though not in conjunction with the information bottleneck objective. [#b20]Mohamed amp Rezende (2015) also explore variational bounds on mutual information, and apply them to deep neural networks, but in the context of reinforcement lea </p>
<p> Deep Variational Information Bottleneck. </p><p> predictive information in a sensory population </p><p> Y the future, while Z is the current representation of the network. This form of the information bottleneck is known as predictive information(Bialek et al., 2001[#b24]Palmer et al., 2015). The attacks still often cause the VIB model to miscla </p>
<p> Deep Variational Information Bottleneck. </p><p> universal adversarial perturbations </p><p>  </p>
<p> Deep Variational Information Bottleneck. </p><p> beta-vae: learning basic visual concepts with a constrained variational framework </p><p>  </p>
<p> Deep Variational Information Bottleneck. </p><p> multivariate sharp quadratic bounds via -strong convexity and the fenchel connection </p><p> ers have greater capacity for adversarial robustness than linear functions.We now derive an approximate bound using second order Taylor series expansion (TSE). The bound can be made proper via [#b6]Browne amp McNicholas (2015). However, using the TSE is sufficient to sketch the derivation.Jensen's inequality implies that the negative loglikelihood so. x ) exp  1 2 S(W  x ) T W  x W T S(W  x )  1 2 S(W  x ) T W  x W T S(W  x ) .As indicated, rather than approximate the lse via TSE, we can make a sharp, quadratic upper bound via [#b6]Browne amp McNicholas (2015). However this merely changes the S(W  x ) scaling in the exponential the result is still logquadratic.figure xmlns"htt </p>
<p> Deep Variational Information Bottleneck. </p><p> regularizing neural networks by penalizing confident output predictions </p><p>  </p>
<p> Deep Variational Information Bottleneck. </p><p> differential privacy as a mutual information constraint </p><p> g richer parametric marginal approximations, rather than assuming r(z)  N (0, I) exploring the connections to differential privacy (see e.g.,Wang et al. (2016a)[#b9]Cuff amp Yu (2016)) and investigating open universe classification problems (see e.g.,Bendale amp Boult (2015)). In additio </p>
<p> Deep Variational Information Bottleneck. </p><p> multivariate sharp quadratic bounds via -strong convexity and the fenchel connection </p><p> ers have greater capacity for adversarial robustness than linear functions.We now derive an approximate bound using second order Taylor series expansion (TSE). The bound can be made proper via [#b6]Browne amp McNicholas (2015). However, using the TSE is sufficient to sketch the derivation.Jensen's inequality implies that the negative loglikelihood so. x ) exp  1 2 S(W  x ) T W  x W T S(W  x )  1 2 S(W  x ) T W  x W T S(W  x ) .As indicated, rather than approximate the lse via TSE, we can make a sharp, quadratic upper bound via [#b6]Browne amp McNicholas (2015). However this merely changes the S(W  x ) scaling in the exponential the result is still logquadratic.figure xmlns"htt </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> adaptive multi-compositionality for recursive neural models with applications to sentiment analysis </p><p> the sentiments of words towards the target depending on context and syntactic structure. We employ a novel adaptive multicompositionality layer in recursive neural network, which is named as AdaRNN [#b1](Dong et al., 2014). It consists of more than one composition functions, and we model the adaptive sentiment propagations as learning distributions over these compo </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> parsing natural scenes and natural language with recursive neural networks </p><p> ed dataset, and conduct extensive experiments on it. The experimental results suggest that our approach yields better performances than the baseline methods.2 RNN Recursive Neural Network RNN [#b13](Socher et al., 2011) represents the phrases and words as Ddimensional vectors. It performs compositions based on the binary trees, and obtain the vector represen </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> accurate unlexicalized parsing </p><p> 2008) is used for baselines. A tweetspecific tokenizer (Gimpel et al., 2011) is employed, and the dependency parsing results are computed by Stanford Parser [#b9](Klein and Manning, 2003). The hyperparameters are chosen by crossvalidation on the training split, and the test accuracy and macroaverage F1score score are rep </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> learning distributed representations of concepts </p><p> In this paper, we mainly focus on integrating target information with Recursive Neural Network (RNN) to leverage the ability of deep learning models. The neural models use distributed representation [#b6](Hinton, 1986Rumelhart et al., 1986Bengio et al., 2003) to automatically learn features f </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> accurate unlexicalized parsing </p><p> 2008) is used for baselines. A tweetspecific tokenizer (Gimpel et al., 2011) is employed, and the dependency parsing results are computed by Stanford Parser [#b9](Klein and Manning, 2003). The hyperparameters are chosen by crossvalidation on the training split, and the test accuracy and macroaverage F1score score are rep </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> a neural probabilistic language model </p><p> age the ability of deep learning models. The neural models use distributed representation (Hinton, 1986Rumelhart et al., 1986[#b0]Bengio et al., 2003) to automatically learn features for targetdependent sentiment classification. RNN utilizes the recursive structure of text, and it has achieve </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> part-of-speech tagging for twitter: annotation, features, and experiments </p><p> ocess the tweets by replacing the targets with T and setting their POS tags to NN. Liblinear (Fan et al., 2008) is used for baselines. A tweetspecific tokenizer [#b5](Gimpel et al., 2011) is employed, and the dependency parsing results are computed by Stanford Parser (Klein and Manning, 2003). </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> part-of-speech tagging for twitter: annotation, features, and experiments </p><p> ocess the tweets by replacing the targets with T and setting their POS tags to NN. Liblinear (Fan et al., 2008) is used for baselines. A tweetspecific tokenizer [#b5](Gimpel et al., 2011) is employed, and the dependency parsing results are computed by Stanford Parser (Klein and Manning, 2003). </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> learning distributed representations of concepts </p><p> In this paper, we mainly focus on integrating target information with Recursive Neural Network (RNN) to leverage the ability of deep learning models. The neural models use distributed representation [#b6](Hinton, 1986Rumelhart et al., 1986Bengio et al., 2003) to automatically learn features f </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> semantic compositionality through recursive matrix-vector spaces </p><p> ly learn features for targetdependent sentiment classification. RNN utilizes the recursive structure of text, and it has achieved stateoftheart sentiment analysis results for movie review dataset [#b14](Socher et al., 2012Socher et al., 2013). The recursive neural models employ the semantic composition functions, which enable </p>
<p> Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification </p><p> learning representations by back-propagating errors </p><p> get information with Recursive Neural Network (RNN) to leverage the ability of deep learning models. The neural models use distributed representation (Hinton, 1986[#b12]Rumelhart et al., 1986Bengio et al., 2003) to automatically learn features for targetdependent sentiment classification. RNN.   j t j log y j      2 2 (4)where  represents the parameters, and the L 2regularization penalty is used.Based on the converted tree, we employ backpropagation algorithm [#b12](Rumelhart et al., 1986) to propagate the errors from root node to the leaf nodes. We calculate the derivatives to update the parameters. The AdaGrad ref type"bi </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> fast global alignment kernels </p><p> ear in space complexity with respect to the sequences' lengths.Because softDTW can be used with kernel machines, one typically observes an increase in performance when using softDTW over DTW [#b6](Cuturi, 2011) for classification.Our contributions. We explore in this paper another important benefit of smoothing DTW unlike the original DTW discrepancy </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> diagnosis of multiple cancer types by shrunken centroids of gene expression </p><p> ted with all training time series, leading to high computational cost. Both of these drawbacks can be addressed by the nearest centroid classifier (Hastie et al., 2001, p.670), [#b26](Tibshirani et al., 2002). This method chooses the class whose barycenter (centroid) is closest to the time series to classify. Although very simple, this method w </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> a global averaging method for dynamic time warping, with applications to clustering </p><p> ty). We show that this regularization is particularly well suited to average and cluster time series under the DTW geometry, a task for which our proposal significantly outperforms existing baselines [#b17](Petitjean et al., 2011). Next, we propose to tune the parameters of a machine that outputs time series by minimizing its fit with groundtruth labels in a softDT. amework (with a kNN or SVM classifier) to predict a real or a class label output, and engineered to run faster in that context (Yi et al., 1998). Recent works by [#b17]Petitjean et al. (2011) Petitjean amp Ganc arski (2012) have, however, shown that DTW can be used for more innovative task. t of the computation of the discrepancy itself, with an added quadratic storage cost. We use this fact to propose an alternative approach to the DBA (DTW Barycenter Averaging) clustering algorithm of [#b17](Petitjean et al., 2011), and observe that our smoothed approach significantly outperforms known baselines for that task. More generally, we propose to use softDT. n do 5r i,j  (x i , y j )  min  r i1,j1 , r i1,j , r i,j1  6end for 7 end for 8 Output (r n,m , R) average time series under the DTW metric [#b17](Petitjean et al., 2011Schultz amp Jain, 2017). To recover the gradient of dtw 0 (x, y) w.r.t. x, we only need to apply the. ation landscape. We believe this is why our approach recovers better results, even when measured in the original dtw 0 discrepancy, than subgradient or alternating minimization approaches such as DBA [#b17](Petitjean et al., 2011), which can, on the contrary, get more easily stuck in local minima. Evidence for this statement is presented in the experimental section.. erested readers. Averaging experimentsIn this section, we compare the softDTW barycenter approach presented in 3.1 to DBA [#b17](Petitjean et al., 2011) and a simple batch subgradient method.Experimental setup. For each dataset, we choose a class at random, pick 10 time series in tha </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> a kernel for time series based on global alignments </p><p> ces (Bahl amp Jelinek, 1975Ristad amp Yianilos, 1998) or kernels (Saigo et al., 2004[#b8]Cuturi et al., 2007). When applied to the DTW discrepancy, that regularization results in a softDTW score, which considers the softminimum of the distribution of. nctionsWe propose in this section a unified formulation for the original DTW discrepancy (Sakoe amp Chiba, 1978) and the Global Alignment kernel (GAK) [#b8](Cuturi et al., 2007), which can be both used to compare two time series x  (x 1 , . . . , x n )  R pn and y  (y 1 , . . . , y m )  R pm . div xmln </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> learning with a wasserstein loss </p><p> or instance, a regularized Wasserstein distance was used to compute barycenters (Cuturi amp Doucet, 2014), and later to fit discriminators that output histograms [#b28](Zhang et al., 2015Rolet et al., 2016). When paired with a flexible learning architecture such as a neural network, softDTW </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> metric learning for temporal sequence alignment </p><p> oe amp Chiba, 19711978). DTW computes the best possible alignment between two time series (the optimal alignment itself can also be of interest, see e.g. [#b10]Garreau et al. 2014) of respective length n and m by computing first the n  m pairwise distance matrix between these points to solve then a dynamic program (DP) u </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> summarizing a set of time series by averaging: from steiner sequence to compact multiple alignment </p><p> class label output, and engineered to run faster in that context (Yi et al., 1998). Recent works by Petitjean et al. (2011) [#b16]Petitjean amp Ganc arski (2012) have, however, shown that DTW can be used for more innovative tasks, such as time series averaging using the DTW discrepancy (se </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> on the theory of dynamic programming </p><p>  </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> fast dictionary learning with a smoothed wasserstein loss </p><p> to compute barycenters (Cuturi amp Doucet, 2014), and later to fit discriminators that output histograms (Zhang et al., 2015[#b20]Rolet et al., 2016). When paired with a flexible learning architecture such as a neural network, softDTW allows for a differentiable endtoend approach to design </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> least squares quantization in pcm </p><p>  </p>
<p> Soft-DTW: a Differentiable Loss Function for Time-Series </p><p> a dynamic programming approach to continuous speech recognition </p><p> 18). A simpler approach, motivated by geometry, lies in the direct definition of a discrepancy between time series that encodes these invariances, such as the Dynamic Time Warping (DTW) score [#b23](Sakoe amp Chiba, 19711978). DTW computes the best possible alignment between two time series (the optimal alignment itself </p>
<p> Mask R-CNN </p><p> faster r-cnn: towards real-time object detection with region proposal networks </p><p> ic segmentation results over a short period of time. In large part, these advances have been driven by powerful baseline systems, such as the FastFaster RCNN [[#b34]] and Fully Convolutional Network (FCN) [24] frameworks for object detection and semantic segmentation, respectively. These. d results. However, we show that a surprisingly simple, flexible, and fast system can surpass prior stateoftheart instance segmentation results. Our method, called Mask RCNN, extends Faster RCNN [#b34][29] by adding a branch for predicting segmentation masks on each Region of Interest (RoI), in parallel with the existing branch for classification and bounding bo. nded [] to allow attending to RoIs on feature maps using RoIPool, leading to fast speed and better accuracy. Faster RCNN [#b34][29] advanced this stream by learning the attention mechanism with a Region Proposal Network (RPN). Faster RCNN is flexible and robust to many followup improveme. e the key elements of Mask RCNN, including pixeltopixel alignment, which is the main missing piece of FastFaster RCNN.Faster RCNN We begin by briefly reviewing the Faster RCNN detector [#b34][29]. Faster RCNN consists of two stages. The first stage, called a Region Proposal Network (RPN), proposes candidate object bounding boxes. The second stage, whi. div Implementation DetailsWe set hyperparameters following existing FastFaster RCNN work [[#b34]]. Although these decisions were made for object detection in original papers [9,re. ef[#b34]29,22]. Although these decisions were made for object detection in original papers [[#b34]], we found our instance segmentation system is robust to them.Training As in Fast RCNN, an RoI is considered po. target"b20"[15]). Right '4' denotes a stack of four consecutive convs. [9]. N is 64 for the C4 backbone (as in [[#b34]]) and 512 for FPN (as in [22]). We train on 8 GPUs (so effective minibatch size is 16) for 160k iterations, with a learning. ss specified. For every entry in this paper, RPN and Mask RCNN have the same backbones and so they are shareable.Inference At test time, the proposal number is 300 for the C4 backbone (as in [#b34][29]) and 1000 for FPN (as in [22]). We run the box prediction branch on these proposals, followed by nonmaximum suppression. w.teic.orgns1.0"TimingInference We train a ResNet101FPN model that shares features between the RPN and Mask RCNN stages, following the 4step training of Faster RCNN [#b34][29]. This model runs at 195ms per image on an Nvidia Tesla M40 GPU (plus 15ms CPU time resizing the outputs to the original resolution), and achieves statisticall </p>
<p> Mask R-CNN </p><p> instance-sensitive fully convolutional networks </p><p> gments []. DeepMask [27] and following works [[#b10]] learn to propose segment candidates, which are then classified by Fast RCNN. In these methods, segmentation precedes recognition, which is slow and less accura. based on parallel prediction of masks and class labels, which is simpler and more flexible. Most recently, Li et al. [21] combined the segment proposal system in [#b10][5] and object detection system in [8] for "fully convolutional instance segmentation" (FCIS). The common idea in ref type"b. l system in [#b10][5] and object detection system in [8] for "fully convolutional instance segmentation" (FCIS). The common idea in [#b10][] is to predict a set of positionsensitive output channels fully convolutionally. </p>
<p> Mask R-CNN </p><p> instance-sensitive fully convolutional networks </p><p> gments []. DeepMask [27] and following works [[#b10]] learn to propose segment candidates, which are then classified by Fast RCNN. In these methods, segmentation precedes recognition, which is slow and less accura. based on parallel prediction of masks and class labels, which is simpler and more flexible. Most recently, Li et al. [21] combined the segment proposal system in [#b10][5] and object detection system in [8] for "fully convolutional instance segmentation" (FCIS). The common idea in ref type"b. l system in [#b10][5] and object detection system in [8] for "fully convolutional instance segmentation" (FCIS). The common idea in [#b10][] is to predict a set of positionsensitive output channels fully convolutionally. </p>
<p> Mask R-CNN </p><p> realtime multiperson 2d pose estimation using part affinity fields </p><p> nowledge for human pose is exploited by our system, as the experiments are mainly to demonstrate the generality of the Mask RCNN framework. We expect that domain knowledge (e.g., modeling structures [#b9][4]) will be complementary to our simple approach, but it is beyond the scope of this paper.Implementation Details We make minor modifications to the segmen. it from more training data, but this dataset is relatively small. Table 4 shows that our result (62.7 AP kp ) is 0.9 points higher than the COCO 2016 keypoint detection winner [#b9][4] that uses a multistage processing pipeline (see caption of Table 4). Our method is considerably simpler and faster.More importan </p>
<p> Mask R-CNN </p><p> fully convolutional instance-aware semantic segmentation </p><p> ls from boundingbox proposals, followed by classification. Instead, our method is based on parallel prediction of masks and class labels, which is simpler and more flexible. Most recently, Li et al. [#b26][21] combined the segment proposal system in [5] and object detection system in [8] for ". m in [8] for "fully convolutional instance segmentation" (FCIS). The common idea in [[#b26]] is to predict a set of positionsensitive output channels fully convolutionally. These channels simultaneously address object classes, boxes, and masks, making. y mask for each RoI. This is in contrast to most recent systems, where classification depends on mask predictions (e.g. [[#b26]]). Our approach follows the spirit of Fast RCNN [9] that applies boundingbox classification and regression in parallel (w. different scales). Unless otherwise noted, AP   Table 1. Instance segmentation mask AP on COCO testdev. MNC [7] and FCIS [#b26][21] are the winners of the COCO 2015 and 2016 segmentation challenges, respectively. Without bells and whistles, Mask RCNN outperforms the more complex FCIS,. "table" target"tab_2"1. All instantiations of our model outperform baseline variants of previous stateoftheart models. This includes MNC [7] and FCIS [#b26][21], the winners of the COCO 2015 and 2016 segmentation challenges, respectively. Without bells and whistles, Mask RCNN with ResNet101FPN backbone outperforms. e"bibr" target"b26"[21], the winners of the COCO 2015 and 2016 segmentation challenges, respectively. Without bells and whistles, Mask RCNN with ResNet101FPN backbone outperforms FCIS [#b26][21], which includes multiscale traintest, horizontal flip test, and online hard example mining (OHEM) [30]. While outside t. target"fig_3"2 and 4. Mask RCNN achieves good results even under challenging conditions. In Figure 5 we compare our Mask RCNN baseline and FCIS [#b26][21]. FCIS exhibits systematic artifacts on overlapping instances, suggesting that it is challenged by the fundamental difficulty of instance segmentation. Mask </p>
<p> Mask R-CNN </p><p> feature pyramid networks for object detection </p><p> his stream by learning the attention mechanism with a Region Proposal Network (RPN). Faster RCNN is flexible and robust to many followup improvements (e.g., [[#b27]]), and is the current leading framework in several benchmarks.Instance Segmentation Driven by the effectiveness. pe"bibr" target"b12"7,17,31].We also explore another more effective backbone recently proposed by Lin et al. [#b27][22], called a Feature Pyramid Network (FPN). FPN uses a topdown architecture with lateral connections to build an innetwork feature pyramid from a singlescale. oach is similar to vanilla ResNet. Using a ResNetFPN backbone for feature extraction with Mask RCNN gives excellent gains in both accuracy and speed. For further details on FPN, we refer readers to [#b27][22].For the network head we closely follow architectures presented in previous work to which we add a fully convolutional mask prediction branch. Specifica. ted in previous work to which we add a fully convolutional mask prediction branch. Specifically, we extend the Faster RCNN box heads from the ResNet [15] and FPN [#b27][22] papers. Details are shown in Figure 3. The head on the ResNetC4 backbone includes the 5th stage of ResNet (namely, the 9layer 'res. s1.0"Implementation DetailsWe set hyperparameters following existing FastFaster RCNN work [[#b27]]. Although these decisions were made for object detection in original papers [9,29,re. ef[#b27]22]. Although these decisions were made for object detection in original papers [[#b27]], we found our instance segmentation system is robust to them.Training As in Fast RCNN, an RoI is considered positive if it has IoU with a groundtruth. ween an RoI and its associated groundtruth mask.We adopt imagecentric training [9]. Images are resized such that their scale (shorter edge) is 800 pixels [#b27][22]. Each minibatch has 2 images per GPU and each image has N sampled RoIs, with a ratio of 13 of positive to negatives Faster RCNN w FPN ref type"bibr" tar. edge) is 800 pixels [#b27][22]. Each minibatch has 2 images per GPU and each image has N sampled RoIs, with a ratio of 13 of positive to negatives Faster RCNN w FPN [#b27][22] Figure 3. Head Architecture We extend two existing Faster RCNN heads [15,ref type"bibr" targ. Faster RCNN w FPN [#b27][22] Figure 3. Head Architecture We extend two existing Faster RCNN heads [[#b27]]. LeftRight panels show the heads for the ResNet C4 and FPN backbones, from [15] and [#b27][22]. type"bibr" target"b20"[[#b27]]. LeftRight panels show the heads for the ResNet C4 and FPN backbones, from [15] and [#b27][22], respectively, to which a mask branch is added. Numbers denote spatial resolution and channels. Arrows denote either conv, deconv, or fc layers as can be infe. onsecutive convs. [9]. N is 64 for the C4 backbone (as in []) and 512 for FPN (as in [#b27][22]). We train on 8 GPUs (so effective minibatch size is 16) for 160k iterations, with a learning rate of 0.02 which is decreased by 10 at the 120k iteration. We. tions, with a learning rate of 0.02 which is decreased by 10 at the 120k iteration. We use a weight decay of 0.0001 and a momentum of 0.9. The RPN anchors span 5 scales and 3 aspect ratios, following [#b27][22]. For convenient ablation, RPN is trained separately and does not share features with Mask RCNN, unless specified. For every entry in this paper, RPN and Mask. e the same backbones and so they are shareable.Inference At test time, the proposal number is 300 for the C4 backbone (as in [29]) and 1000 for FPN (as in [#b27][22]). We run the box prediction branch on these proposals, followed by nonmaximum suppression [11]. The mask branch is then. tal flip test, and OHEM [30]. All entries are singlemodel results.is evaluating using mask IoU. As in previous work [[#b27]], we train using the union of 80k train images and a 35k subset of val images (trainval35k), and report ablations on the remaining 5k subset of val images (mini. ned a version of Mask RCNN but without the mask branch, denoted by "Faster RCNN, RoIAlign" in Table 3. This model performs better than the model presented in [#b27][22] due to RoIAlign. On the other hand, it is 0.9 points box AP lower than Mask RCNN. This gap of Mask RCNN on box detection is therefore due solely to the bene. eart on testdev. Mask RCNN using ResNet101FPN outperforms the base variants of all previous stateoftheart models (the mask output is ignored in these experiments). The gains of Mask RCNN over[#b27][22] come from using RoIAlign (1.1 AP bb ), multitask training (0.9 AP bb ), and ResNeXt101 (1.6 AP bb ).backboneAP bb </p>
<p> Mask R-CNN </p><p> simultaneous detection and segmentation </p><p> s.Instance Segmentation Driven by the effectiveness of RCNN, many approaches to instance segmentation are based on segment proposals. Earlier methods [[#b17]] resorted to bottomup segments [33,ref typ </p>
<p> Mask R-CNN </p><p> inception-v4, inception-resnet and the impact of residual connections on learning </p><p>  </p>
<p> Mask R-CNN </p><p> towards accurate multiperson pose estimation in the wild </p><p>  </p>
<p> Mask R-CNN </p><p> aggregated residual transformations for deep neural networks </p><p> at is applied separately to each RoI.We denote the backbone architecture using the nomenclature networkdepthfeatures. We evaluate ResNet [15] and ResNeXt [#b40][35] networks of depth 50 or 101 layers. The original implementation of Faster RCNN with ResNets [15] extracted features from. more than four locations per bin, which we found to give diminishing returns. We use the 644d variant of ResNeXt[#b40][35].    a relatively high resolution output (compared to masks) is requir </p>
<p> Mask R-CNN </p><p> insideoutside net: detecting objects in context with skip pooling and recurrent neural networks </p><p> ncludes multiscale traintest, horizontal flip test, and OHEM [30]. All entries are singlemodel results.is evaluating using mask IoU. As in previous work [#b8][], we train using the union of 80k train images and a 35k subset of val images (trainval35k), and report ablations on the </p>
<p> Gated Graph Sequence Neural Networks </p><p> the graph neural network model </p><p> language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graphstructured inputs. Our starting point is previous work on Graph Neural Networks [#b24](Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flex. i et al., 2014). More closely related to our goal in this work are methods that learn features on graphs, including Graph Neural Networks (Gori et al., 2005[#b24]Scarselli et al., 2009), spectral networks (Bruna et al., 2013) and recent work on learning graph fingerprints for classificati. f the input graph, and (2) learning representations of the internal state during the process of producing a sequence of outputs. Here, (1) is mostly achieved by previous work on Graph Neural Networks [#b24](Scarselli et al., 2009) we make several minor adaptations of this framework, including changing it to use modern practices around Recurrent Neural Networks. ( r. iv GRAPH NEURAL NETWORKSIn this section, we review Graph Neural Networks (GNNs) (Gori et al., 2005[#b24]Scarselli et al., 2009) and introduce notation and concepts that will be used throughout.GNNs are a general neural network architecture defined according to. pairs e  (v, v )  V  V. We will focus in this work on directed graphs, so (v, v ) represents a directed edge v  v , but we note that the framework can easily be adapted to undirected graphs see [#b24]Scarselli et al. (2009). The node vector (or node representation or node embedding) for node v is denoted by h v  R D . Graphs may also contain node labels l v . urrence below until convergence, where t denotes the timesteph (t) v  f  (l v , l CO(v) , l NBR(v) , h (t1) NBR(v)). Several variants are discussed in [#b24]Scarselli et al. (2009) including positional graph forms, nodespecific updates, and alternative representations of neighborhoods. Concretely, ref type"bibr" tar. ts are discussed in [#b24]Scarselli et al. (2009) including positional graph forms, nodespecific updates, and alternative representations of neighborhoods. Concretely, [#b24]Scarselli et al. (2009) suggest decomposing f  () to be a sum of peredge termsf  (l v , l CO(v) , l NBR(v) , h (t) NBR(v) ) . 2"OUTPUT MODEL AND LEARNINGThe output model is defined per node and is a differentiable function g(h v , l v ) that maps to an output. This is generally a linear or neural network mapping. [#b24]Scarselli et al. (2009) focus on outputs that are independent per node, which are implemented by mapping the final node representations hformula xmlid"formu. ffers from GNNs mainly in the output model. GNNs have been applied in several domains (Gori et al., 2005Di Massa et al., 2006[#b24]Scarselli et al., 2009Uwents et al., 2011), but they do not appear to be in widespread use in the ICLR community. Part of our aim here is t </p>
<p> Gated Graph Sequence Neural Networks </p><p> from machine learning to machine reasoning </p><p> assembling neural networks according to a family tree structure in order to predict relations between people. Similar ideas appear in Hammer amp Jain (2004) and [#b2]Bottou (2014).Graph kernels (Shervashidze et al., 2011Kashima et al., 2003) can be </p>
<p> Gated Graph Sequence Neural Networks </p><p> generalization of back-propagation to recurrent neural networks </p><p> classification can be handled in the same manner as nodelevel regression or classification.Learning is done via the AlmeidaPineda algorithm (Almeida, 1990[#b21]Pineda, 1987), which works by running the propagation to convergence, and then computing gradients based upon the converged solution. This has the advantage of not </p>
<p> Gated Graph Sequence Neural Networks </p><p> neural methods for non-standard data </p><p> the work of Hinton (1988) on assembling neural networks according to a family tree structure in order to predict relations between people. Similar ideas appear in [#b11]Hammer amp Jain (2004) and Bottou (2014).Graph kernels (Shervashidze et al., 2011ref </p>
<p> Gated Graph Sequence Neural Networks </p><p> from machine learning to machine reasoning </p><p> assembling neural networks according to a family tree structure in order to predict relations between people. Similar ideas appear in Hammer amp Jain (2004) and [#b2]Bottou (2014).Graph kernels (Shervashidze et al., 2011Kashima et al., 2003) can be </p>
<p> Gated Graph Sequence Neural Networks </p><p> learning to decipher the heap for program verification </p><p> perties such as memory safety (i.e., that there are no null pointer dereferences in a program), a core problem is to find mathematical descriptions of the data structures used in a program. Following [#b3]Brockschmidt et al. (2015), we have phrased this as a machine learning problem where we will learn to map from a set of input graphs, representing the state of memo. machine learning problem where we will learn to map from a set of input graphs, representing the state of memory, to a logical description of the data structures that have been instantiated. Whereas [#b3]Brockschmidt et al. (2015) relied on a large amount of handengineering of features, we show that the system can be replaced with a GGSNN at no cost in accuracy.. ocess, so the training process again can be decomposed to single output single graph training.A more complex scenario allowing for nested data structures (e.g., list of lists) was discussed in [#b3]Brockschmidt et al. (2015). We have also successfully extended the GGSNN model to this case. More details on this can be found in Appendix C. div xmlns. truth equivalence is approximated by canonicalizing names and order of the formulas and then comparing for exact equality.We compared our GGSNNbased model with a method we developed earlier [#b3](Brockschmidt et al., 2015). The earlier approach treats each prediction step as standard classification, and requires complex, manual, problemspecific feature eng </p>
<p> Gated Graph Sequence Neural Networks </p><p> a learning rule for asynchronous perceptrons with feedback in a combinatorial environment </p><p> cial type of edge. Thus, graphlevel regression or classification can be handled in the same manner as nodelevel regression or classification.Learning is done via the AlmeidaPineda algorithm [#b0](Almeida, 1990Pineda, 1987), which works by running the propagation to convergence, and then computing gradients based upon th </p>
<p> Gated Graph Sequence Neural Networks </p><p> grasshopper -complete heap verification with mixed specifications </p><p> run it a few times and extract the state of memory (represented as a graph see below) at relevant program locations, and then predict a separation logic formula. Static program analysis tools (e.g., [#b22](Piskac et al., 2014)) can check whether a candidate formula is sufficient to prove the desired properties (e.g., memory safety). div xmlns"httpwww. </p>
<p> Gated Graph Sequence Neural Networks </p><p> grasshopper -complete heap verification with mixed specifications </p><p> run it a few times and extract the state of memory (represented as a graph see below) at relevant program locations, and then predict a separation logic formula. Static program analysis tools (e.g., [#b22](Piskac et al., 2014)) can check whether a candidate formula is sufficient to prove the desired properties (e.g., memory safety). div xmlns"httpwww. </p>
<p> Gated Graph Sequence Neural Networks </p><p> supervised neural networks for the classification of structures </p><p> ts sequences. Perozzi et al. (2014) convert graphs into sequences by following random walks on the graph then learns node embeddings using sequencebased methods. [#b27]Sperduti amp Starita (1997) map graphs to graph vectors then classify using an output neural network. There are several models that make use of similar propagati </p>
<p> Gated Graph Sequence Neural Networks </p><p> online learning of social representations </p><p> s (Kashima et al., 2003Shervashidze et al., 2011), and methods that define graph features in terms of random walks on graphs [#b20](Perozzi et al., 2014). More closely related to our goal in this work are methods that learn features on graphs, including Graph Neural Networks ref type"bibr" t. et"b14"Kashima et al., 2003) can be used for a variety of kernelbased learning tasks with graphstructured inputs, but we are not aware of work that learns the kernels and outputs sequences. [#b20]Perozzi et al. (2014) convert graphs into sequences by following random walks on the graph then learns node embeddings using sequencebased methods. ref type"bib </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> neural machine translation of rare words with subword units </p><p> h the open vocabulary issue is to break up rare words into subword units (Schuster and Nakajima, 2012Chitnis and DeNero, 2015[#b21]Sennrich et al., 2016Wu et al., 2016).BytePairEncoding  1 Multiple subword sequences encodi. t al., 2016Wu et al., 2016).BytePairEncoding  1 Multiple subword sequences encoding the same sentence "Hello World" (BPE) [#b21](Sennrich et al., 2016) is a de facto standard subword segmentation algorithm applied to many NMT systems and achieving top translation quality in several shared t. is paper, we call these two algorithms onebest decoding and nbest decoding respectively.3 Subword segmentations with language model 3.1 BytePairEncoding (BPE)BytePairEncoding (BPE) [#b21](Sennrich et al., 2016Schuster and Nakajima, 2012) is a subword segmentation algorithm widely used in many NMT systems 1 . BP. ings can be enumerated in O(T ) time and O(20T ) space with the Enhanced Suffix Array algorithm (Nong et al., 2009), where T is the size of the corpus. Similar to [#b21](Sennrich et al., 2016), we do not consider subwords that cross word boundaries.As the final vocabulary V contains all individual characters in the corpus,. rence (p lt 0.05) from baselines with bootstrap resampling (Koehn, 2004). The same mark is used in Table 4 and6. [#b21](Sennrich et al., 2016) and our unigram model with or without subword regularization. The BLEU scores of word, character and mixed wordcharacter models are cited </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> error bounds for convolutional codes and an asymptotically optimum decoding algorithm </p><p> xmlid"formula_7"x   arg max x?S(X) P (x),(7)where S(X) is a set of segmentation candidates built from the input sentence X. x  is obtained with the Viterbi algorithm [#b30](Viterbi, 1967).If the vocabulary V is given, subword occurrence probabilities p(x i ) are estimated via the EM algorithm that maximizes the following margi </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> bayesian methods for hidden markov models: recursive computing in the 21st century </p><p> candidates increases exponentially with respect to the sentence length. In order to exactly sample from all possible segmentations, we use the ForwardFiltering and BackwardSampling algorithm (FFBS) [#b20](Scott, 2002), a variant of the dynamic programming originally introduced by Bayesian hidden Markov model training. In FFBS, all segmentation candidates are repres </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> variablelength word encodings for neural translation models </p><p> n vocabulary setting.A common approach for dealing with the open vocabulary issue is to break up rare words into subword units (Schuster and Nakajima, 2012[#b4]Chitnis and DeNero, 2015Sennrich et al., 2016Wu et al., 2016).BytePairEncoding </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> neural lattice-to-sequence models for uncertain inputs </p><p> ugh an onthefly subword sampling. This approach makes the model simple and independent from NMT architectures.Latticetosequence models (Su et al., 2017[#b22]Sperber et al., 2017) are natural extension of sequencetosequence models, which represent inputs uncertainty through lattices. Lattice is encoded with a variant </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> japanese and korean voice search </p><p> words, which makes the translation inaccurate especially in an open vocabulary setting.A common approach for dealing with the open vocabulary issue is to break up rare words into subword units [#b19](Schuster and Nakajima, 2012Chitnis and DeNero, 2015Sennrich et al., 2016ref type"bib. nbest decoding respectively.3 Subword segmentations with language model 3.1 BytePairEncoding (BPE)BytePairEncoding (BPE) (Sennrich et al., 2016[#b19]Schuster and Nakajima, 2012) is a subword segmentation algorithm widely used in many NMT systems 1 . BPE first splits the whole sentence into individual characters. on a unigram language model, which is capable of outputing multiple subword segmentations with probabilities. The unigram language model makes an assumption that 1 Strictly speaking, wordpiece model [#b19](Schuster and Nakajima, 2012) is different from BPE. We consider wordpiece as a variant of BPE, as it also uses an incremental vocabulary generation with a differe </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> dropout: a simple way to prevent neural networks from overfitting </p><p> tion. Related WorkRegularization by noise is a well studied technique in deep neural networks. A wellknown example is dropout [#b23](Srivastava et al., 2014), which randomly turns off a subset of hidden units during training. Dropout is analyzed as an ensemble training, where many different mod </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> a stochastic japanese morphological analyzer using a forward-dp backward-a* nbest search algorithm </p><p>  </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> a new algorithm for data compression </p><p> to the forward probabilities. BPE vs. Unigram language modelBPE was originally introduced in the data compression literature [#b6](Gage, 1994). BPE is a variant of dictionary (substitution) encoder that incrementally finds a set of symbols such that the total number of symbols for encoding the </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> a neural attention model for abstractive sentence summarization </p><p> apply subword regularization to other NLP tasks based on encoderdecoder architectures, e.g., dialog generation (Vinyals and Le, 2015) and automatic summarization [#b18](Rush et al., 2015). Compared to machine translation, these tasks do not have enough training data, and thus there could be a large room for improvement with subwo </p>
<p> subword regularization: improving neural network translation models with multiple subword candidates </p><p> japanese and korean voice search </p><p> words, which makes the translation inaccurate especially in an open vocabulary setting.A common approach for dealing with the open vocabulary issue is to break up rare words into subword units [#b19](Schuster and Nakajima, 2012Chitnis and DeNero, 2015Sennrich et al., 2016ref type"bib. nbest decoding respectively.3 Subword segmentations with language model 3.1 BytePairEncoding (BPE)BytePairEncoding (BPE) (Sennrich et al., 2016[#b19]Schuster and Nakajima, 2012) is a subword segmentation algorithm widely used in many NMT systems 1 . BPE first splits the whole sentence into individual characters. on a unigram language model, which is capable of outputing multiple subword segmentations with probabilities. The unigram language model makes an assumption that 1 Strictly speaking, wordpiece model [#b19](Schuster and Nakajima, 2012) is different from BPE. We consider wordpiece as a variant of BPE, as it also uses an incremental vocabulary generation with a differe </p>
<p> continual flow pipelines </p><p> checkpoint processing and recovery: towards scalable large instruction window processors </p><p> concept is applicable to a broad range of processor architectures (see Section 4.3). In this paper we use Checkpoint Processing and Recovery (CPR) as the baseline architecture [#b1][2] since it has been shown to outperform conventional ROBbased architectures. CPR is a reorderbufferfree architecture requiring a small number of renamemap tabl. analyzes these limitations. CPR overviewCPR is a ROBfree proposal for building scalable large instruction window processors [#b1][2]. CPR addresses the scalability and performance limitations of conventional branch misprediction recovery mechanisms by using a small number of register rename m </p>
<p> continual flow pipelines </p><p> dynamic register renaming through virtual-physical registers </p><p> 9"10]. The counter method used in CPR for reclaiming physical registers was first proposed [17] for a ROBbased processor. Virtual Physical Registers (VPR) [#b15][16] delay allocation of physical registers until just prior to instruction completion to reduce lifetimes of physical registers. They deal with dependent destinat </p>
<p> continual flow pipelines </p><p> a large, fast instruction window for tolerating cache misses </p><p> instructions do not occupy scheduler entries while waiting for the miss to return. The distributed nonblocking design allows for an effectively large scheduler. The Waiting Instruction Buffer (WIB) [#b13][14] employs a small and fast scheduler backed by a larger buffer for storing instructions dependent upon long latency operations.While nonblocking schedul. wer wasted speculative executiononly 30 for CFP compared to 70 additional uops for runahead execution. CFP and WIBThe WIB [#b13][14] also drains loadmissdependent instructions into a special buffer. However, significant differences exist between the WIB and CFP proposal. Two key differenc. smaller scheduling window. RELATED WORKSection 3.3 discusses nonblocking schedulers [[#b13]]. Various register file organizations have been proposed and include []. The counter. ry [15]. Outoforder commit processors [8] combine a checkpoint proposal [9] with the WIB [#b13][14] to address scheduler limitations for a checkpoint processor since the WIB focused on a ROBbased processor. Similar to the WIB, the paper also assumes a suffi </p>
<p> continual flow pipelines </p><p> register renaming and dynamic speculation: an alternative approach </p><p> ntics of the reorder buffer. This limits the supply of free registers and necessitates larger register files.Our baseline CPR model uses an aggressive counterbased register reclamation scheme [#b16][17] instead of relying on a ROBbased reclamation scheme. CPR thus breaks the limitation of serial register reclamation by guaranteeing architectural state is neve. ions have been proposed and include []. The counter method used in CPR for reclaiming physical registers was first proposed [#b16][17] for a ROBbased processor. Virtual Physical Registers (VPR) [16] delay allocation of physical registers until just prior </p>
<p> continual flow pipelines </p><p> memory dependence prediction using store sets </p><p> s latency) 1024entry L2 store queue (off the critical path). The large L2 store queue is necessary for some benchmark suites to achieve high performance. The baseline CPR uses a store sets predictor [#b6][7] to predict loadstore memory dependences and to issue loads ahead of unknown stores.Completed stores look up a load buffer to roll back execution to an e </p>
<p> continual flow pipelines </p><p> speculative data-driven multi-threading </p><p> d where either auxiliary code [] or a small subset of the program (e.g., a backward slice of a cache miss) is preexecuted [#b18][] on idle contexts of a multithreaded processor prior to encountering the blocked operation.In Datascalar archite </p>
<p> continual flow pipelines </p><p> multiplebanked register file architectures </p><p> schedulers []. Various register file organizations have been proposed and include [[#b9]]. The counter method used in CPR for reclaiming physical registers was first proposed [17] for a ROBbased processor. Virtua </p>
<p> continual flow pipelines </p><p> dynamic register renaming through virtual-physical registers </p><p> 9"10]. The counter method used in CPR for reclaiming physical registers was first proposed [17] for a ROBbased processor. Virtual Physical Registers (VPR) [#b15][16] delay allocation of physical registers until just prior to instruction completion to reduce lifetimes of physical registers. They deal with dependent destinat </p>
<p> continual flow pipelines </p><p> dynamically allocating processor resources between nearby and distant ilp </p><p> mited to a subset of the ROB. A checkpoint of the architected register file is used but only for recovering from exceptions and the ROB is used for retiring instructions.Balasubramonian et al. [#b3][4] dynamically reserve physical registers for a future thread spawned when the main thread stalls due to a long latency operation. In addition to requiring partial </p>
<p> continual flow pipelines </p><p> exploiting ilp, tlp, and dlp with the polymorphous trips architecture </p><p> s memory latency. However, such an approach is resource inefficient since multiple processors execute the same program.Distributed large instruction window processing models have been proposed [#b19][]. These processing models significantly change the underlying processor and have different constraints and tradeoffs o </p>
<p> continual flow pipelines </p><p> a day in the life of a data cache miss </p><p> independent instructions to execute and complete in parallel with the outstanding memory miss. Prior research has shown a significant amount of useful work can be done in the shadow of a memory miss [#b12][13]. CFP uses that observation to achieve memory latency tolerance. By providing mechanisms to obtain nonblocking structures, the register file and scheduler size. 3). As can be seen, a significant portion of the nonspeculative instructionwindow in the shadow of a long latency miss comprises missindependent instructions for all benchmark suites. Others [#b12][13] have also observed similar results for the SINT2K suite. Thus, a significant amount of useful work can be completed while a miss is outstanding allowing the p. ong latency load cannot be resolved until the load data returns. Our experiments show that a very small fraction of mispredicted branches is dependent on a longlatency load miss. Karkhanis and Smith [#b12][13] identified structural, data, and controlinduced stalls as key performance limiters. While branch prediction accuracy is known to be an important performance i </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> state-ofthe-art speech recognition with sequence-to-sequence models </p><p> " target"b9"[10][11] used graphemes in sequencetosequence (seq2seq) models. Subword units were used in seq2seq [12][#b12][13][14] and RNNT [15] models, and word units were used by ref type"bibr" target"b15" </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> latent sequence decompositions </p><p> br" target"b8"[9][10][11] used graphemes in sequencetosequence (seq2seq) models. Subword units were used in seq2seq [#b11][12][13][14] and RNNT [15] models, and word units we. iv Output UnitEndtoend speech recognition models have typically used characters [9], subwords [#b11][12], wordpieces [15] or words [16] as the output unit of choice. Wordbased units are d </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> long short-term memory </p><p> ll (LAS) [9] model, with the output target changed from graphemes to Unicode bytes. The encoder network consists of 5 unidirectional Long ShortTerm Memory (LSTMs) [#b24][25] layers, with each layer having 1, 400 hidden units. The decoder network consists of 2 unidirectional LSTM layers with 1, 024 hidden units. Additive contentba </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> end-to-end attention-based large vocabulary speech recognition </p><p> pular choice. For example, [8] built a Connectionist Temporal Classification (CTC) model to directly output graphemes, while [9][#b9][10][11] used graphemes in sequencetosequence (seq2seq) models. Subword units were used in seq2seq ref type"bibr" target" </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> grapheme based speech recognition </p><p> "bibr" target"b2"[3] when merging different languages.Graphemes have been used as an alternative modeling unit to phonemes for speech processing [4][#b4][5][6][7]. For these systems, an orthographic lexicon instead of a pronunciation dictionary </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> grapheme based speech recognition </p><p> "bibr" target"b2"[3] when merging different languages.Graphemes have been used as an alternative modeling unit to phonemes for speech processing [4][#b4][5][6][7]. For these systems, an orthographic lexicon instead of a pronunciation dictionary </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> long short-term memory </p><p> ll (LAS) [9] model, with the output target changed from graphemes to Unicode bytes. The encoder network consists of 5 unidirectional Long ShortTerm Memory (LSTMs) [#b24][25] layers, with each layer having 1, 400 hidden units. The decoder network consists of 2 unidirectional LSTM layers with 1, 024 hidden units. Additive contentba </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> end-to-end attention-based large vocabulary speech recognition </p><p> pular choice. For example, [8] built a Connectionist Temporal Classification (CTC) model to directly output graphemes, while [9][#b9][10][11] used graphemes in sequencetosequence (seq2seq) models. Subword units were used in seq2seq ref type"bibr" target" </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> latent sequence decompositions </p><p> br" target"b8"[9][10][11] used graphemes in sequencetosequence (seq2seq) models. Subword units were used in seq2seq [#b11][12][13][14] and RNNT [15] models, and word units we. iv Output UnitEndtoend speech recognition models have typically used characters [9], subwords [#b11][12], wordpieces [15] or words [16] as the output unit of choice. Wordbased units are d </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> unicodebased graphemic systems for limited resource languages </p><p> t involved, many languages do not have sufficient linguistic resources available for building such dictionaries. Additionally, the inconsistency in the phonetic systems is also challenging to resolve [#b2][3] when merging different languages.Graphemes have been used as an alternative modeling unit to phonemes for speech processing ref type"bibr" target"b3". needs to pool all the distinct graphemes from all languages together resulting in a very large vocabulary that often has long tail graphemes with very poor coverage.To address these problems, [#b2][3] explored the use of features from Unicode character descriptions to construct decision trees for clustering graphemes. However, when the model changes to suppor </p>
<p> bytes are all you need: end-to-end multilingual speech recognition and synthesis with bytes </p><p> multilingual language processing from bytes </p><p> ing graphemes. However, when the model changes to support a new language, the decision tree needs to be updated. Recently, there has been work on exploring the use of Unicode bytes to represent text. [#b21][22] presented an LSTMbased multilingual bytetospan model. The model consumes the input text bytebybyte and outputs span annotations. The Unicode bytes are la. more languages together, which is more preferable to graphemes for multilingual applications.In this work, we investigate the potential of representing text using byte sequences introduced in [#b21][22] for speech processing. For ASR, we adopt the Listen, Attend and Spell (LAS) [9] model to convert input speech into sequenc </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> node2vec: scalable feature learning for networks </p><p> th, and York, 2003).Early works on graphical structure data can be dated back to the research of graph embedding ( Perozzi, AlRfou, and Skiena, 2014[#b4]Grover and Leskovec, 2016), where graph topology and node relations are embedded as vector space. In light of the rapid advances of deep learning ref type"bibr" t. endtoend training this kind of errors will accumulate as the depth increases.We contrast the performance of our algorithm against several unsupervised graph learning counterparts Node2Vec [#b4](Grover and Leskovec, 2016), VGAE (Kipf and Welling, 2016), GraphSAGE (Hamilton, Ying, and Leskov. sified into two groups random walksbased methods, and graph convolutional networks (GCN)based methods. DeepWalk (Perozzi, AlRfou, and Skiena, 2014) and Node2vec [#b4](Grover and Leskovec, 2016) are representative random walkbased methods to model homogeneous graphs. Some followup works embed 1storder, 2ndorder and even higho. ode embedding baselines Raw features This indicates a naive classification model that learns from nodes' raw features, without using any graph structure information incorporated.  Node2Vec [#b4](Grover and Leskovec, 2016) This approach is an extension of Word2Vec (Mikolov et al., 2013) on graph, which learns a feature </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> representation learning for scene graph completion via jointly structural and visual embedding </p><p> (Wang, Cui, and Zhu, 2016Qiu et al., 2018), and visual understanding (Yang et al., 2018[#b20]Wan et al., 2018) to name a few. Amongst their varying forms, bipartite graphs belong to one type of the most central structures. A bipartite graph (depicted in Fi </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> distributed representations of words and phrases and their compositionality </p><p> nodes' raw features, without using any graph structure information incorporated.  Node2Vec (Grover and Leskovec, 2016) This approach is an extension of Word2Vec [#b13](Mikolov et al., 2013) on graph, which learns a feature representations by simulating a biased random walks on the graph. We run Node2Vec on the bipartite graph an </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> meta-path2vec: scalable representation learning for heterogeneous networks </p><p> s. Some followup works embed 1storder, 2ndorder and even highorder proximities between vertices on homogeneous graphs, such as LINE (Tang et al., 2015), GraRep [#b0](Cao, Lu, and Xu, 2015), SDNE (Wang, Cui, and Zhu, 2016), DVNE (Zhu et al., 2018). However </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> adversarially regularized graph autoencoder for graph embedding </p><p> tradomain alignment trick to minimize the divergence between input features and interdomain representations, by using adversarial models (Goodfellow et al., 2014[#b14]Pan et al., 2018), a kind of tool that has been applied successfully for distribution matching. In contrast to feature concatenation, our alignment trick is unsupe </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> meta-path2vec: scalable representation learning for heterogeneous networks </p><p> s. Some followup works embed 1storder, 2ndorder and even highorder proximities between vertices on homogeneous graphs, such as LINE (Tang et al., 2015), GraRep [#b0](Cao, Lu, and Xu, 2015), SDNE (Wang, Cui, and Zhu, 2016), DVNE (Zhu et al., 2018). However </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> graph convolutional policy network for goal-directed molecular graph generation </p><p> text xmllang"en"  IntroductionGraphs that characterize relations among data arise in various domains including drug discovery [#b23](You et al., 2018Jin, Barzilay, and Jaakkola, 2018), social networks analysis (Wang, Cui, and Z </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> distributed representations of words and phrases and their compositionality </p><p> nodes' raw features, without using any graph structure information incorporated.  Node2Vec (Grover and Leskovec, 2016) This approach is an extension of Word2Vec [#b13](Mikolov et al., 2013) on graph, which learns a feature representations by simulating a biased random walks on the graph. We run Node2Vec on the bipartite graph an </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> amazon.com recommendations: item-to-item collaborative filtering </p><p> le, users and products correspond to two distinct components, and how to take benefit of the buying correlations between them plays an important role in accurate and effective recommendation services [#b12](Linden, Smith, and York, 2003).Early works on graphical structure data can be dated back to the research of graph embedding ( ref type"bibr" target"b15 </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> amazon.com recommendations: item-to-item collaborative filtering </p><p> le, users and products correspond to two distinct components, and how to take benefit of the buying correlations between them plays an important role in accurate and effective recommendation services [#b12](Linden, Smith, and York, 2003).Early works on graphical structure data can be dated back to the research of graph embedding ( ref type"bibr" target"b15 </p>
<p> Adversarial Representation Learning on Large-Scale Bipartite Graphs </p><p> deep learning </p><p> kiena, 2014Grover and Leskovec, 2016), where graph topology and node relations are embedded as vector space. In light of the rapid advances of deep learning [#b11](LeCun, Bengio, and Hinton, 2015), current research attention has been paid to the application of deep neural networks on graphs, giving rise to a novel and also p </p>
<p> modular multiplication without trial division </p><p> a carry-free algorithm for finding the greatest common divisor of two integers </p><p> presentation of residue classes so as to speed modular multiplication without affecting the modular addition and subtraction algorithms.Other recent algorithms for modular arithmetic appear in [#b2][3], [6].Fix N gt 1. Define an Nresidue to be a residue class modulo N. Select a radix R coprime to N (possibly the ma </p>
<p> modular multiplication without trial division </p><p> a monte carlo method for factorization </p><p> div      1. Description. Some algorithms [1], [#b1][2], [4], [5] require extensive modular arithmetic. We propose a representation of residue c </p>
<p> modular multiplication without trial division </p><p> a monte carlo method for factorization </p><p> div      1. Description. Some algorithms [1], [#b1][2], [4], [5] require extensive modular arithmetic. We propose a representation of residue c </p>
<p> modular multiplication without trial division </p><p> a monte carlo method for factorization </p><p> div      1. Description. Some algorithms [1], [#b1][2], [4], [5] require extensive modular arithmetic. We propose a representation of residue c </p>
<p> modular multiplication without trial division </p><p> theorems on factorization and primality testing </p><p> ubtraction algorithms are unchanged.      1. Description. Some algorithms [#b0][1], [2], [4], [5] require extensive modular arithmetic. </p>
<p> modular multiplication without trial division </p><p> fast probabilistic algorithms for verification of polynomial identities </p><p> 1. Description. Some algorithms [1], [2], [4], [#b4][5] require extensive modular arithmetic. We propose a representation of residue classes so as to speed modular multiplication without affecting the modular additio </p>
<p> modular multiplication without trial division </p><p> a monte carlo method for factorization </p><p> div      1. Description. Some algorithms [1], [#b1][2], [4], [5] require extensive modular arithmetic. We propose a representation of residue c </p>
<p> modular multiplication without trial division </p><p> theorems on factorization and primality testing </p><p> ubtraction algorithms are unchanged.      1. Description. Some algorithms [#b0][1], [2], [4], [5] require extensive modular arithmetic. </p>
<p> modular multiplication without trial division </p><p> fast probabilistic algorithms for verification of polynomial identities </p><p> 1. Description. Some algorithms [1], [2], [4], [#b4][5] require extensive modular arithmetic. We propose a representation of residue classes so as to speed modular multiplication without affecting the modular additio </p>
<p> modular multiplication without trial division </p><p> a monte carlo method for factorization </p><p> div      1. Description. Some algorithms [1], [#b1][2], [4], [5] require extensive modular arithmetic. We propose a representation of residue c </p>
<p> modular multiplication without trial division </p><p> a monte carlo method for factorization </p><p> div      1. Description. Some algorithms [1], [#b1][2], [4], [5] require extensive modular arithmetic. We propose a representation of residue c </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> tensorflow: a system for large-scale machine learning </p><p> ameworks, such as TensorFlow, MXNet, Caffe, and PyTorch, rely on a computational graph intermediate representation to implement optimizations, e.g., auto differentiation and dynamic memory management [#b2][]. Graphlevel optimizations, however, are often too highlevel to handle hardware bac. ort new backends. Optimizing Computational GraphsComputational graphs are a common way to represent programs in DL frameworks [#b2][]. Figure 3. XE Q INSTRUCTION FETCH UNIT LOAD CMD Q COMPUTE CMD Q COMPUTE STORE CMD Q controller Related WorkDeep learning frameworks [#b2][] provide convenient interfaces for users to exp. stack to generate optimized code for a larger number of hardware devices.Highlevel computation graph DSLs are a typical way to represent and perform highlevel optimizations. Tensorflow's XLA [#b2][3] and the recently introduced DLVM [45] fall into this category. The representations of computation graphs in these works are </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> xgboost: a scalable tree boosting system </p><p> ead, we use a rank objective to predict the relative order of runtime costs.We implement several types of models in our ML optimizer. We employ a gradient tree boosting model (based on XGBoost [#b7][8]), which makes predictions based on features extracted from the loop program these features include the memory access count and reuse ratio of each memory buff </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> optimization by simulated annealing </p><p> uration through the cost model, selecting the topk predicted performers. However, this strategy becomes intractable with large search spaces. Instead, we run a parallel simulated annealing algorithm [#b21][22]. The explorer starts with random configurations, and, at each step, randomly walks to a nearby configuration. This transition is successful if cost decreases </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> xgboost: a scalable tree boosting system </p><p> ead, we use a rank objective to predict the relative order of runtime costs.We implement several types of models in our ML optimizer. We employ a gradient tree boosting model (based on XGBoost [#b7][8]), which makes predictions based on features extracted from the loop program these features include the memory access count and reuse ratio of each memory buff </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> mxnet: a flexible and efficient machine learning library for heterogeneous distributed systems </p><p> nal graph intermediate representation to implement optimizations, e.g., auto differentiation and dynamic memory management [[#b8]]. Graphlevel optimizations, however, are often too highlevel to handle hardware backendspecific operatorlevel transformations. Most of these frameworks focus. headComputational graphs are a common way to represent programs in DL frameworks [[#b8]]. Figure 3 shows an example computational graph representation of a twolayer convolutional neural network. The main diffe. " target"b27"[28] and Deep Convolutional Generative Adversarial Networks (DCGAN) [31]. We compare our approach to existing DL frameworks, including MxNet [#b8][9] and TensorFlow [2], that rely on highly engineered, vendorspecific libraries. TVM performs endtoend automatic optimizati. pwww.teic.orgns1.0"Related WorkDeep learning frameworks [[#b8]] provide convenient interfaces for users to express DL workloads and deploy them easily on different hardware backends. While existing frameworks currently depen </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> from high-level deep neural models to fpgas </p><p> operties of TPUlike accelerators and enables a concrete case study on how to compile code for accelerators. Our approach could potentially benefit existing systems that compile deep learning to FPGA [#b33][], as well. This paper provides a generic solution to effectively target accelerators via tensorization and compilerdri </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> human-level control through deep reinforcement learning </p><p> ding ResNet [16], MobileNet [19], the LSTM Language Model [48], the Deep Q Network (DQN) [#b27][28] and Deep Convolutional Generative Adversarial Networks (DCGAN) [31]. We compare our approach to existing DL frameworks, i </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> automatically scheduling halide image processing pipelines </p><p> hyper parametertuning algorithms [26] apply domainagnostic search. A predefined cost model is used to automatically schedule image processing pipelines in Halide [#b28][29]. TVM's ML model uses effective domainaware cost modeling that considers program structure. The based distributed schedule optimizer scales to a larger search </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> eyeriss: a spatial architecture for energy-efficient dataflow for convolutional neural networks </p><p> the key challenges described below.Leveraging Specific Hardware Features and Abstractions. DL accelerators introduce optimized tensor compute primitives [[#b11]], while GPUs and CPUs continuously improve their processing elements. This poses a significant challenge in generating o. sor operators like matrixmatrix multiplication or 1D convolution. These natural decompositions have led to the recent trend of adding tensor compute primitives [[#b11]]. These new primitives create both opportunities and challenges for schedulebased compilation while using them can imp. ric inference accelerator design we prototyped on an FPGA. We used in this evaluation the Vanilla Deep  Learning Accelerator (VDLA) which distills characteristics from previous accelerator proposals [#b11][] into a minimalist hardware architecture to demonstrate TVM's ability to gener </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> in-datacenter performance analysis of a tensor processing unit </p><p> lfdriving cars and embedded devices. Mapping DL workloads to these devices is complicated by the diversity of hardware characteristics, including embedded CPUs, GPUs, FPGAs, and ASICs (e.g., the TPU [#b20][21]). These hardware targets diverge in  terms of memory organization, compute functional units, etc., as shown in Figure 1re. Leveraging Specific Hardware Features and Abstractions. DL accelerators introduce optimized tensor compute primitives [[#b20]], while GPUs and CPUs continuously improve their processing elements. This poses a significant challenge in generating optimized code for a given operator descr. e special requirements for memory hierarchy. The system must effectively exploit these complex primitives to benefit from acceleration. Further, accelerator designs also commonly favor leaner control [#b20][21] and offload most scheduling complexity to the compiler stack. For specialized accelerators, the system now needs to generate code that explicitly controls pip. ication or 1D convolution. These natural decompositions have led to the recent trend of adding tensor compute primitives [[#b20]]. These new primitives create both opportunities and challenges for schedulebased compilation while using them can improve performance, the compilation framew. type"bibr" target"b19"20]. GPUs rely on rapid context switching of many warps of threads [44]. In contrast, specialized DL accelerators such as the TPU [#b20][21] usually favor leaner control with a decoupled accessexecute (DAE) architecture [35] and offload the problem of finegrai. typed on an FPGA. We used in this evaluation the Vanilla Deep  Learning Accelerator (VDLA) which distills characteristics from previous accelerator proposals [[#b20]] into a minimalist hardware architecture to demonstrate TVM's ability to generate highly efficient schedules that can t. tion13th USENIX Symposium on Operating Systems Design and Implementation 591Despite the emerging popularity of accelerators for deep learning [[#b20]], it remains unclear how a compilation stack can be built to effectively target these devices. The VDLA design used in our evaluation provides a generic way to </p>
<p> TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. </p><p> human-level control through deep reinforcement learning </p><p> ding ResNet [16], MobileNet [19], the LSTM Language Model [48], the Deep Q Network (DQN) [#b27][28] and Deep Convolutional Generative Adversarial Networks (DCGAN) [31]. We compare our approach to existing DL frameworks, i </p>
<p> Temporal ensembling for semi-supervised learning </p><p> regularization with stochastic transformations and perturbations for deep semi-supervised learning </p><p> ve that selfensembling improves the classification accuracy in fully labeled cases as well, and provides tolerance against incorrect labels.The recently introduced transformstability loss of [#b20]Sajjadi et al. (2016b) is based on the same principle as our work, and the model can be seen as a special case of it. The model can also be seen as a simplific. ensembling, while model can randomize once per a pair of evaluations, which according to our measurements is 0.5 percentage points better than independent flips.A principled comparison with [#b20]Sajjadi et al. (2016b) is difficult due to several reasons. They provide results only for a fairly extreme set of augmentations (translations, flipping, rotations,. differs from the model in removing the parametric nonlinearity and denoising, having two corrupted paths, and comparing the outputs of the network instead of preactivation data of the final layer. [#b20]Sajjadi et al. (2016b) recently introduced a new loss function for semisupervised learning, so called transformstability loss, which is founded on the same princ </p>
<p> Temporal ensembling for semi-supervised learning </p><p> learning with pseudo-ensembles </p><p> loss term as the sum of all pairwise squared distances between the obtained n network outputs. As such, their technique follows the general pseudoensemble agreement (PEA) regularization framework of [#b0]Bachman et al. (2014). In addition, they employ a mutual exclusivity loss term (Sajjadi et al., 2016a) that we do not use. Our </p>
<p> Temporal ensembling for semi-supervised learning </p><p> bagging predictors </p><p> fective ensemble we obtain via the averaging of previous epochs' predictions.In bootstrap aggregating, or bagging, multiple networks are trained independently based on subsets of training data [#b1](Breiman, 1996). This results in an ensemble that is more stable and accurate than the individual networks. Our approach can be seen as pulling the predictions from </p>
<p> Temporal ensembling for semi-supervised learning </p><p> distributional smoothing with virtual adversarial training </p><p> ions we can compare against the best fully supervised results as well. After all, the fully supervised results should indicate the upper bound of obtainable accuracy. 36.02  0.10 Virtual Adversarial [#b14](Miyato et al., 2016) 24.63 ADGM (Maale et al., 2016) 22.86 SDGM (Maale et al., 2016) 1 </p>
<p> Temporal ensembling for semi-supervised learning </p><p> learning with pseudo-ensembles </p><p> loss term as the sum of all pairwise squared distances between the obtained n network outputs. As such, their technique follows the general pseudoensemble agreement (PEA) regularization framework of [#b0]Bachman et al. (2014). In addition, they employ a mutual exclusivity loss term (Sajjadi et al., 2016a) that we do not use. Our </p>
<p> Temporal ensembling for semi-supervised learning </p><p> unsupervised and semi-supervised learning with categorical generative adversarial networks </p><p> over multiple epochs.Generative Adversarial Networks (GAN) have been recently used for semisupervised learning with promising results (Maale et al., 2016[#b25]Springenberg, 2016Odena, 2016Salimans et al., 2016). It Additive Gaussian noise   0.15 conv1a 128 f </p>
<p> Temporal ensembling for semi-supervised learning </p><p> bagging predictors </p><p> fective ensemble we obtain via the averaging of previous epochs' predictions.In bootstrap aggregating, or bagging, multiple networks are trained independently based on subsets of training data [#b1](Breiman, 1996). This results in an ensemble that is more stable and accurate than the individual networks. Our approach can be seen as pulling the predictions from </p>
<p> Temporal ensembling for semi-supervised learning </p><p> snapshot ensembles: train 1, get m for free </p><p> d on a single network, and the variability is a result of evaluating it under different dropout and augmentation conditions instead of training on different subsets of data. In work parallel to ours, [#b8]Huang et al. (2017)   amp Ghahramani, 2002) infer labels for unlabeled training data by comparing the associated inputs to labeled training </p>
<p> Temporal ensembling for semi-supervised learning </p><p> mutual exclusivity loss for semi-supervised deep learning </p><p> ique follows the general pseudoensemble agreement (PEA) regularization framework of Bachman et al. (2014). In addition, they employ a mutual exclusivity loss term [#b19](Sajjadi et al., 2016a) that we do not use. Our model can be seen as a special case of the transformstability loss obtained by setting n  2. The computational </p>
<p> Temporal ensembling for semi-supervised learning </p><p> semi-supervised learning with deep generative models </p><p>  </p>
<p> Temporal ensembling for semi-supervised learning </p><p> semi-supervised learning with deep generative models </p><p>  </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> predicting parameters in deep learning </p><p> uctionCNNs require a large number of parameters and high computational cost in both training and testing phases. Recent studies have investigated the significant redundancy in deep networks [#b5][6] and reduced the number of neurons and filters [3,14,25,. p Related WorkThere has been recent interest in reducing the redundancy of deep CNNs to achieve acceleration and compression. In [#b5][6] the redundancy in the parameterization of deep learning models has been studied and demonstrated. Cheng et al. [2] exploited. rget"b41"42,12,45], the redundancy in the parameterization of deep learning models has been studied and demonstrated [#b5][6]. We present NISP to efficiently propagate the importance scores from final responses to all other neurons to guide network pruning to achieve acceleration and c </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> template regularized sparse coding for face verification </p><p> s1.0"Supplementary MaterialDespite their impressive predictive power on a wide range of tasks [33,40,[#b40]41,13,15,48,46, </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> remotenet: efficient relevant motion event detection for large-scale home surveillance videos </p><p> ocuses on network compression, other methods speedup deep network inference by refining the pipelines of certain tasks [[#b45]]. Our method prunes a pretrained network and requires a fastconverging finetuning process, rather than retraining a. 40,41,13,15,48,[#b45]46,24,44,42,12, </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> dynamic zoom-in network for fast object detection in large images </p><p> nference. Besides the above work which focuses on network compression, other methods speedup deep network inference by refining the pipelines of certain tasks [[#b12]]. Our method prunes a pretrained network and requires a fastconverging finetu. alDespite their impressive predictive power on a wide range of tasks [33,40,41,[#b12]13,15,48,46,24, </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> sparse convolutional neural networks </p><p> "b13"[14] studied the weight sparsity and compressed CNNs by combining pruning, quantization, and Huffman coding. Sparsity regularization terms have been use to learn sparse CNN structure in [#b25][]. Miao et al. [30] studied network compres </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> infinite feature selection </p><p> on ("final response layer" (FRL)) to retrain its predictive power, since those responses are the direct inputs of the classification task (which is also suggested by feature selection methods, e.g., [#b33][34]). We define the importance of neurons in early layers based on a unified goal minimizing the reconstruction errors of the responses produced in FRL. We first. ng the reconstruction errors of the responses produced in FRL. We first measure the importance of responses in the FRL by treating them as features and applying some feature ranking techniques (e.g., [#b33][34]), then propagate the importance of neurons backwards from the FRL to earlier layers. We prune only nodes which have low propagated importance (i.e., those who. sponses.It is worth noting that our method can work with any feature selection that scores features w.r.t. their classification power. We employ the recently introduced filtering method InfFS [#b33][34] because of its efficiency and effectiveness on CNN feature selection. InfFS utilizes properties of the power series of matrices to efficiently compute the im. e formulate this problem as a binary integer programming (optimization) and provide a closedform approximate solution. Based on our theoretical analysis, we 1 Details of the method are introduced in [#b33][34] and its codes taken from develop the Neuron Importance Score Propagation algorithm to efficiently compute the neuron importance for the whole network.di. etermine neuron importance, we conduct experiments by fixing other parts of NISP and only comparing the pruning results with different measurements of importance 1. using feature selection method in [#b33][34] (NISPFS) and 2. considering only magnitude of weights (NISPMag). For the Magnitudebased pruning, the importance of a neuron in the final response layer equ. ning and trainfromscratch baselines, which shows the effectiveness of NISP with different measurement of importance. In the remainder of this paper, we employ the feature ranking method proposed in [#b33][34] in NISP. NISP v.s. LayerbyLayer PruningTo demonstrate the advantage of the NISP' </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> learning rich features for image manipulation detection </p><p> ref type"bibr" target"b32"[33,40,41,13,15,[#b47]48,46,24,44,42, </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> dynamic zoom-in network for fast object detection in large images </p><p> nference. Besides the above work which focuses on network compression, other methods speedup deep network inference by refining the pipelines of certain tasks [[#b12]]. Our method prunes a pretrained network and requires a fastconverging finetu. alDespite their impressive predictive power on a wide range of tasks [33,40,41,[#b12]13,15,48,46,24, </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> deep fried convnets </p><p> n Taylor expansion.Focusing on compressing the fully connected (FC) layers, Srinivas et al. [35] pruned neurons that are similar to each other. Yang et al. [#b42][43] applied the "Fastfood" transform to reparameterize the matrixvector multiplication of FC layers. Ciresan et al. [3] reduc </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> second order derivatives for network pruning: optimal brain surgeon </p><p> ess, rather than retraining a network from scratch. To measure the importance of neurons in a CNN, the exact solution is very hard to obtain given the complexity of nonlinearity. Some previous works [#b7][] approximate it using 2ndorder Taylor expansion. Our work is a different approximat </p>
<p> nisp: pruning networks using neuron importance score propagation </p><p> faster r-cnn: towards real-time object detection with region proposal networks </p><p> proposed to skip layers for speeding up inference. Besides the above work which focuses on network compression, other methods speedup deep network inference by refining the pipelines of certain tasks [#b32][]. Our method prunes a pretrained netwo. etwork acceleration and compression. Supplementary MaterialDespite their impressive predictive power on a wide range of tasks [#b32][33,40,41,13,15,ref </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> inductive representation learning on large graphs </p><p> followed by mean pooling and nonlinearity. By stacking multiple graph convolution layers, GCNs can learn node representations by utilizing information from distant neighbors. GCNs and their variants [#b4](Hamilton et al., 2017aVelikovi et al., 2018) have been applied to semisupervised node classification (Kip. refVelikovi et al., 2018) have been applied to semisupervised node classification (Kipf amp Welling, 2017), inductive node embedding [#b4](Hamilton et al., 2017a), link prediction (Kipf amp Welling, 2016Berg et al., 2017) and k. representations of all the nodes altogether. However, batch algorithms cannot handle largescale datasets because of their slow convergence and the requirement to fit the entire dataset in GPU memory. [#b4]Hamilton et al. (2017a) make an initial attempt to develop stochastic training algorithms for GCNs via a scheme of neighbor sampling (NS). Instead of considering al. sification (Kipf amp Welling, 2017). However, the algorithm is neither limited to the task nor the model. Our algorithm is applicable to other models including GraphSAGEmean [#b4](Hamilton et al., 2017a) and graph attention networks (GAT) (Velikovi et al., 2018), and other tasks ref type"bibr" target. g of neighbors (Sec. 2.3) and the random dropout of features (Sec. 5). Neighbor SamplingTo reduce the receptive field size, [#b4]Hamilton et al. (2017a) propose a neighbor sampling (NS) algorithm. NS randomly chooses D (l) neighbors for each node at layer l and develops an estimator NS (l) u. rix P is replaced by a sparser unbiased estimator P (l) , i.e., E P (l)  P , whereP (l) uv  n(u) D (l) P uv if v  n(l) (u), and P (l) uv  0 otherwise. [#b4]Hamilton et al. (2017a) propose to perform an approximate forward propagation as Eq. ( 4), and do stochastic gradient. eed, unless the sample size D (l) goes to infinity. Because of the biased gradient, the sample size D (l) needs to be large for NS, to keep comparable predictive performance with the exact algorithm. [#b4]Hamilton et al. (2017a) choose D (1)  10 and D (2)  25, and the receptive field size D (1)  D (2)  250 is much larger than one, so the training is still expensi. the variance vanishes eventually. Implementation DetailsTraining with the CV estimator is similar as with the NS estimator [#b4](Hamilton et al., 2017a). Particularly, each iteration of the algorithm involves the following stepsStochastic GCN with Variance Reduction 1. Randomly selec. d by one the first layer is merely a fullyconnected layer instead of a graph convolution one. Since most GCNs only have two graph convolution layers (Kipf amp Welling, 2017[#b4]Hamilton et al., 2017a), this gives a significant reduction of the receptive field size and speeds up the computation. We refer this optimization as the preprocessi. xamine the variance and convergence of our algorithms empirically on six datasets, including Citeseer, Cora, PubMed and NELL from Kipf amp Welling (2017) and Reddit, PPI from [#b4]Hamilton et al. (2017a), with the same train  validation  test splits, as summarized in Table 1. To measure the predictive. sure the predictive performance, we report MicroF1 for the multilabel PPI dataset, and accuracy for all the other multiclass datasets. The model is GCN for the former 4 datasets and GraphSAGEmean [#b4](Hamilton et al., 2017a) for the latter 2 datasets, see Appendix E for the details on the architectures. We repeat the convergence experiments 10 times on Citeseer,. ighbor selected, as we mentioned in Sec. 2.4. Our accuracy result for ISPP can match the result reported by Chen et al. (2018), while their NS baseline, GraphSAGE [#b4](Hamilton et al., 2017a), does not implement the preprocessing technique in Sec. 5.3. Further Anal </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> semi-supervised classification with graph convolutional networks </p><p>  </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> online learning of social representations </p><p> national Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).do not use the graph structure, and graph embedding approaches [#b9](Perozzi et al., 2014Tang et al., 2015Grover amp Leskovec, 2016) that do not use node f </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> line: large-scale information network embedding </p><p> Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).do not use the graph structure, and graph embedding approaches (Perozzi et al., 2014[#b13]Tang et al., 2015Grover amp Leskovec, 2016) that do not use node features.However, the graph convolution operation ma </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> scalable feature learning for networks </p><p> by the author(s).do not use the graph structure, and graph embedding approaches (Perozzi et al., 2014Tang et al., 2015[#b3]Grover amp Leskovec, 2016) that do not use node features.However, the graph convolution operation makes GCNs difficult to be trained efficiently. The repre </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> scalable feature learning for networks </p><p> by the author(s).do not use the graph structure, and graph embedding approaches (Perozzi et al., 2014Tang et al., 2015[#b3]Grover amp Leskovec, 2016) that do not use node features.However, the graph convolution operation makes GCNs difficult to be trained efficiently. The repre </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> line: large-scale information network embedding </p><p> Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).do not use the graph structure, and graph embedding approaches (Perozzi et al., 2014[#b13]Tang et al., 2015Grover amp Leskovec, 2016) that do not use node features.However, the graph convolution operation ma </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> line: large-scale information network embedding </p><p> Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).do not use the graph structure, and graph embedding approaches (Perozzi et al., 2014[#b13]Tang et al., 2015Grover amp Leskovec, 2016) that do not use node features.However, the graph convolution operation ma </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> dropout: a simple way to prevent neural networks from overfitting </p><p> div Handling Dropout of FeaturesIn this section, we consider introducing a third source of randomness, the random dropout of features [#b12](Srivastava et al., 2014), which is adopted in various GCN models as a regularization (Kipf amp Welling, 2017ref type"bibr" target"b1. uTable 2. Variance from neighbor sampling (VNS) and variance from dropout (ND) of different estimators.Our method is based on the weight scaling procedure [#b12](Srivastava et al., 2014) to approximately compute the mean (l) v  E M h (l) v .That is, along with the dropout mo </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> semi-supervised classification with graph convolutional networks </p><p>  </p>
<p> Stochastic Training of Graph Convolutional Networks with Variance Reduction </p><p> scalable feature learning for networks </p><p> by the author(s).do not use the graph structure, and graph embedding approaches (Perozzi et al., 2014Tang et al., 2015[#b3]Grover amp Leskovec, 2016) that do not use node features.However, the graph convolution operation makes GCNs difficult to be trained efficiently. The repre </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> shared reconfigurable architectures for cmps </p><p> nterface not shown for simplicity. Each of the two clusters on the left hand side consists of a multithreaded SPL fabric shared by four single issue outoforder processor cores. In our previous work [#b44][43], we evaluated the use of SPL with a range of inorder and outoforder core types and found that a simple outoforder core coupled with SPL provided the best. ters. Of course, different mixes of SPL and conventional clusters (as well as other cluster types) are possible, but this consideration is beyond the scope of this paper.Each SPL, adopted from [#b44][43] and shown in more detail in Figures 1(b) and (c), is a highly pipelined rowbased [22,. ion each SPL as appropriate to optimize performance and power efficiency. In the remainder of Section 2, we provide an overview of the SPL microarchitecture. A more complete treatment is available in [#b44][43].  Rows SPLTotal hea. Rows SPLTotal SPL Hardware MicroarchitectureWe adopt the rowbased fabric of our earlier work [#b44][43] in which the space of shared SPL configurations was explored using validated SPL delay, power, and area models. The SPL is tightly integrated with the process. se to reside onchip. Thus, reconfiguration latency is not an issue as all configurations are immediately available after the initial configuration overhead is paid.Using our analytical models [#b44][43], we arrive at the area and power results for eight single issue outoforder cores, eight private 12row SPLs, and two fourway shared SPLs shown in Table re. latter is much more compact, requiring 4X less area than the private SPLs, and is much more powerefficient as well. While one might consider shrinking the private SPL even further, our previous work [#b44][43] has shown that that this yields poor performance. SPL VirtualizationVirtualizing. ated at runtime. shows how the SPL design permits temporal sharing among the threads executing on the four processor cores, as well as spatial partitioning to permit private or semiprivate operation [#b44][43]. Spatial partitioning is enabled by inserting additional multiplexers at each point where the SPL pool might be partitioned. To keep the hardware overhead rea. lticore processor and find that combining program parallelization with custom ISA support provides larger speedups than the product of the two techniques applied in isolation.Our previous work [#b44][43] identifies a number of characteristics of past reconfigurable proposals that are found to be highly amenable to incorporating reconfigurable fabrics in CMPs.. g reconfigurable fabrics in CMPs. We designed a shared SPL based on these features, and analyzed the impact of incorporating the fabric with processors of different complexity. While the emphasis of [#b44][43] is on the fabric design, this paper proposes a complete hardwaresoftware approach to managing multithreaded SPL clusters in future CMPs, including spatial pa. gDescFigure1(b)  shows how the SPL design permits temporal sharing among the threads executing on the four processor cores, as well as spatial partitioning to permit private or semiprivate operation[#b44][43]. Spatial partitioning is enabled by inserting additional multiplexers at each point where the SPL pool might be partitioned. To keep the hardware overhead rea </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> managing distributed, shared l2 caches through os-level page allocation </p><p> ployed.Previous research has proposed sharing other architectural components among multiple cores. Several efforts investigate how to best allocate shared L2 cache space among multiple threads [#b9][]. Sun's UltraSPARC T1 [39] shares a single f </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> performance of multithreaded chip multiprocessors and implications for operating system design </p><p> Scheduling and Dynamic Resource SharingThe benefits of dynamic thread scheduling in small scale CMPSMT systems has been explored for a number of purposes, including cacheaware scheduling [#b18][], thermal management [11], and SMT resourc </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> picking statistically valid and early simulation points </p><p> mpletion. Due to the long running time of SPEC benchmarks with reference inputs, however, we are only able to run our nonSPEC benchmarks to completion. For our SPEC benchmarks we use Early SimPoints [#b32][31] to select two 250 million instruction SimPoints from the original source code (i.e., code not utilizing the SPL). Since using the SPL changes the number of in </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> managing distributed, shared l2 caches through os-level page allocation </p><p> ployed.Previous research has proposed sharing other architectural components among multiple cores. Several efforts investigate how to best allocate shared L2 cache space among multiple threads [#b9][]. Sun's UltraSPARC T1 [39] shares a single f </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> a reconfigurable hardware interface for a modern computing system </p><p> econfigurable blocks. Configurations can map to these blocks both spatially and temporally. A number of research efforts [[#b21]] have investigated the high level integration of a reconfigurable fabric onchip. All of these, however, only investigate the integration with a single core, al. b21"20] have investigated the high level integration of a reconfigurable fabric onchip. All of these, however, only investigate the integration with a single core, although Garcia and Compton [#b21][20] state that their technique could be extended to a multicore system.In [21], configuration data for a reconfigurabl </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> the garp architecture and c compiler </p><p> ype"bibr" target"b42"41]. Researchers have proposed specialized fabrics that are specifically designed for more efficient integration with general purpose processors than conventional FPGAs [#b4][]. Despite these advances in fabric architecture, reconfigurable logic still incur. rations are then created for those functions by hand, although previous work has shown that compilers can produce good mappings for reconfigurable architectures [[#b4]]. Since dynamic thread scheduling is most useful when applications experience phase changes, we need to run the benchmarks </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> the garp architecture and c compiler </p><p> ype"bibr" target"b42"41]. Researchers have proposed specialized fabrics that are specifically designed for more efficient integration with general purpose processors than conventional FPGAs [#b4][]. Despite these advances in fabric architecture, reconfigurable logic still incur. rations are then created for those functions by hand, although previous work has shown that compilers can produce good mappings for reconfigurable architectures [[#b4]]. Since dynamic thread scheduling is most useful when applications experience phase changes, we need to run the benchmarks </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> the convey hc-1 computer </p><p> ref19]. Convey Computer's HC1 pairs an Intel processor with a reconfigurable coprocessor and allows different instruction sets to be loaded into the coprocessor [#b13][12]. Thread Scheduling and Dynamic Resource SharingThe benefits of dynamic thread sched </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> kernel sharing on reconfigurable multiprocessor systems </p><p> only investigate the integration with a single core, although Garcia and Compton [20] state that their technique could be extended to a multicore system.In [#b22][21], configuration data for a reconfigurable coprocessor is shared among multiple cores in order to increase fabric utilization by allowing a larger number of con </p>
<p> dynamically managed multithreaded reconfigurable architectures for chip multiprocessors </p><p> picking statistically valid and early simulation points </p><p> mpletion. Due to the long running time of SPEC benchmarks with reference inputs, however, we are only able to run our nonSPEC benchmarks to completion. For our SPEC benchmarks we use Early SimPoints [#b32][31] to select two 250 million instruction SimPoints from the original source code (i.e., code not utilizing the SPL). Since using the SPL changes the number of in </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> deeply-recursive convolutional network for image super-resolution </p><p> IntroductionSuperResolution (SR) from a single image has recently received a huge boost in performance using DeepLearning based methods [[#b9]]. The recent SotA (State of the Art) method. onvolutional network, with 8 hidden layers, each has 64 channels. We use ReLU activations on each layer. The network input is interpolated to the output size. As done in previous CNNbased SR methods [#b9][], we only learn the residual between the interpolated LR and its HR parent. We use L. een pretrained). However, on 'nonideal' datasets, ZSSR surpasses SotA SR by a large margin. All reported numerical were produced using the evaluation script of [[#b9]]. The 'Ideal' CaseWhile this is not the aim of ZSSR, we tested it also on the standar </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> learning a deep convolutional network for image super-resolution </p><p> iv xmlns"httpwww.teic.orgns1.0"IntroductionSuperResolution (SR) from a single image has recently received a huge boost in performance using DeepLearning based methods [#b3][]. Th. activations on each layer. The network input is interpolated to the output size. As done in previous CNNbased SR methods [[#b3]], we only learn the residual between the interpolated LR and its HR parent. We use L 1 loss with ADAM optimizer [11]. We star. imagespecific ZSSR achieves competitive results against externallysupervised methods that were exhaustively trained for these conditions. In fact, ZSSR is significantly better than the older SRCNN [#b3][4], and in some cases achieves comparable or better results than VDSR [9] (which was the SotA until a year ago). Within the uns </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> blind dehazing using internal patch recurrence </p><p> SR [15] (when the downscaling kernel is unknown), BlindDeblurring [], BlindDehazing [#b2][3], and more. While such unsupervised methods can exploit imagespecific information (hence are less subject to the abovementioned supervised restrictions), they </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> image and video upscaling from local self-examples </p><p> Art) method [13] exceeds previous nonDeep SR methods (supervised [22] or unsupervised [[#b5]]) by a few dBs a huge margin! This boost in performance was obtained with very deep and well engineered CNNs, which were tr. target"b4"[]. This formed the basis for many unsupervised image enhancement methods, including unsupervised SR [[#b5]], BlindSR [15] (when the downscaling kernel is unknown), BlindDeblurring ref type"b </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a+: adjusted anchored neighborhood regression for fast super-resolution </p><p> " target"b11"12,13]. The recent SotA (State of the Art) method [13] exceeds previous nonDeep SR methods (supervised [#b21][22] or unsupervised []) by a few dBs a huge marg </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> accurate image superresolution using very deep convolutional networks </p><p> rResolution (SR) from a single image has recently received a huge boost in performance using DeepLearning based methods [[#b8]]. The recent SotA (State of the Art) method [13]r. rs, each has 64 channels. We use ReLU activations on each layer. The network input is interpolated to the output size. As done in previous CNNbased SR methods [[#b8]], we only learn the residual between the interpolated LR and its HR parent. We use L 1 loss with ADAM optimizer ref type"b. gure"1). In order to quantitatively evaluate ZSSR's performance, we ran several controlled experiments on a variety of settings. Interestingly, ZSSR produces competitive results (although VDSR [#b8][9] EDSR [13] BlindSR [15] ZSSR [estimated kernel] (ours) ZSSR [true kernel] (ours) 27.7. though our CNN is small, and has not been pretrained). However, on 'nonideal' datasets, ZSSR surpasses SotA SR by a large margin. All reported numerical were produced using the evaluation script of [#b8][]. The 'Ideal' CaseWhile this is not the aim of. ely trained for these conditions. In fact, ZSSR is significantly better than the older SRCNN [4], and in some cases achieves comparable or better results than VDSR [#b8][9] (which was the SotA until a year ago). Within the unsupervisedSR regime, ZSSR outperforms the leading method SelfExSR [7] b. s, each LR image was subsampled by a different random kernel. Table 2 compares our against the leading externallysupervised SR methods [[#b8]]. We also compared our performance to the unsupervised BlindSR method of [15]. We considered two cases for applying ZSSR (i </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a+: adjusted anchored neighborhood regression for fast super-resolution </p><p> " target"b11"12,13]. The recent SotA (State of the Art) method [13] exceeds previous nonDeep SR methods (supervised [#b21][22] or unsupervised []) by a few dBs a huge marg </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> separating signal from noise using patch recurrence across scales </p><p> tions (Gaussian noise, speckle noise, JPEG artifacts, and more). We attribute this phenomenon to the fact that imagespecific information tends to repeat across scales, whereas noise artifacts do not [#b24][25]. Adding a bit of synthetic noise to the LR sons (but not to their HR fathers) teaches the network to ignore uncorrelated crossscale information (the noise), w </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a+: adjusted anchored neighborhood regression for fast super-resolution </p><p> " target"b11"12,13]. The recent SotA (State of the Art) method [13] exceeds previous nonDeep SR methods (supervised [#b21][22] or unsupervised []) by a few dBs a huge marg </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> nonparametric blind superresolution </p><p> or many unsupervised image enhancement methods, including unsupervised SR [], BlindSR [#b14][15] (when the downscaling kernel is unknown), BlindDeblurring [], BlindDehazing re. ically rely on simple Eucledian similarity of small image patches, of predefined size (typically 5  5), using K  The unknown imagespecific kernel is estimated directly from the LR test image using [#b14][15], and fed into our imagespecific CNN as the downscaling kernel (note that externallytrained networks cannot make use of such imagespecific information at te. t image at hand, one of a kind, and nothing else. Nevertheless, when additional information is available and provided (e.g., the downscaling kernel can be estimated directly from the test image using [#b14][15]), our imagespecific CNN can make good use of this at test time, to further improve the results.  head n". vided to our network. When the downscaling kernel is unknown (which is usually the case), a rough estimate of the kernel can be computed directly from the test image itself (e.g., using the method of [#b14][15]). Such rough kernel estimations suffice to obtain 1dB improvement over EDSR on nonideal kernels (see examples in Figs. 1 and 2, and. experiments on a variety of settings. Interestingly, ZSSR produces competitive results (although VDSR [9] EDSR [13] BlindSR [#b14][15] ZSSR [estimated kernel] (ours) ZSSR [true kernel] (ours) 27.7212  0.7635 27.7826  0.7660 28.420  0.7834 28.8118  0.8306 29.6814  0.8414 Table ref type". st the leading externallysupervised SR methods []. We also compared our performance to the unsupervised BlindSR method of [#b14][15]. We considered two cases for applying ZSSR (i) The more realistic scenario of unknown downscaling kernel. For this mode we used ref type"bibr" target"b14. upervised BlindSR method of [#b14][15]. We considered two cases for applying ZSSR (i) The more realistic scenario of unknown downscaling kernel. For this mode we used [#b14][15] to evaluate the kernel directly from the test image and fed it to ZSSR. The unknown SR kernel is estimated in [#b14][15] by see. known downscaling kernel. For this mode we used [#b14][15] to evaluate the kernel directly from the test image and fed it to ZSSR. The unknown SR kernel is estimated in [#b14][15] by seeking a nonparametric downscaling kernel which maximizes the similarity of patches across scales in the LR test image. (ii) We applied ZSSR with the tru. ided the true kernels. Visually, the images generated by SotA SR methods are very blurry (see Fig. 2, and project website). Interestingly, the unsupervised BlindSR method of [#b14][15], which does not use deep learning, also outperforms SotA SR methods. This supports the analysis and observations of [18], </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a+: adjusted anchored neighborhood regression for fast super-resolution </p><p> " target"b11"12,13]. The recent SotA (State of the Art) method [13] exceeds previous nonDeep SR methods (supervised [#b21][22] or unsupervised []) by a few dBs a huge marg </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> image and video upscaling from local self-examples </p><p> Art) method [13] exceeds previous nonDeep SR methods (supervised [22] or unsupervised [[#b5]]) by a few dBs a huge margin! This boost in performance was obtained with very deep and well engineered CNNs, which were tr. target"b4"[]. This formed the basis for many unsupervised image enhancement methods, including unsupervised SR [[#b5]], BlindSR [15] (when the downscaling kernel is unknown), BlindDeblurring ref type"b </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> internal statistics of a single natural image </p><p> recurrence of small pieces of information (e.g., small image patches) across scales of a single image, was shown to be a very strong property of natural images [[#b23]]. This formed the basis for many unsupervised image enhancement methods, including unsupervised SR [5,ref type"bibr" targe. duce the HR output. This outperforms unsupervised patchbased SR by a large margin.Since the visual entropy inside a single image is much smaller than in a general external collection of images [#b23][24], a small and simple CNN suffices for this imagespecific task. Hence, even though our network is trained at test time, its traintest runtime is comparable to. n to repeat many times inside a single image, both within the same scale, as well as across different image scales. This observation was empirically verified by [[#b23]] using hundreds of natural images, and was shown to be true for almost any small patch in almost any natural image.Fig. ref type"figure" target"fig_2. 'fractallike' image, the internal predictivepower was analyzed and shown to be strong for almost any natural image [5].In fact, it was empirically shown by [#b23][24] that the internal entropy of patches inside a single image is much smaller than the external entropy of patches in a general collection of natural images. Thi. r predictivepower than external statistics obtained from a general image collection. This preference was further shown to be particularly strong under growing uncertainty and image degradations (see [#b23][] for details). ImageSpecific CNNOur imagesp </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> enhanced deep residual networks for single image super-resolution </p><p> rformance using DeepLearning based methods [[#b12]]. The recent SotA (State of the Art) method [#b12][13] exceeds previous nonDeep SR methods (supervised ref type"bibr" target". ref type"bibr" target"b9"10,9,12,[#b12]13]. The recent SotA (State of the Art) method [#b12][13] exceeds previous nonDeep SR methods (supervised [22] or unsupervised [5,ref type"b. s probability to be sampled. This reflects the higher reliability of nonsynthesized HR examples over synthesize ones.Lastly, we use a method similar to the geometric selfensemble proposed in [#b12][13] (which generates 8 different outputs for the 8 rotationsflips of the test image I, and then combines them). We take the median of these 8 outputs rather than. he runtime to 1 min per image (on V100). There is therefore a tradeoff between runtime and the output quality, which is up to the user to choose.For compariosn, the testtime of leading EDSR [#b12][13] grows quadratically with the image size. While it is fast on small images, for a 800800 image it performs 5   . etails).Indeed, our experiments show that for lowquality LR images, and for a wide variety of degradation types, the imagespecific CNN obtains significantly better SR results than SotA EDSR [#b12][13] (see Sec. 4). Similarly, in the case of nonideal downscaling kernels, the imagespecific CNN obtains a significant improvement over SotA (even in the absence. luate ZSSR's performance, we ran several controlled experiments on a variety of settings. Interestingly, ZSSR produces competitive results (although VDSR [9] EDSR [#b12][13] BlindSR [15] ZSSR [estimated kernel] (ours) ZSSR [true kernel] (ours) 27.7212  0.7635 27.7826  0.7660 28.420  0.7834. ng kernels (of reasonable size). SR2 was then applied to those images. Please see text for more details. Ground Truth VDSR [9]EDSR [#b12][13] ZSSR (ours) (PSNR, SSIM) (20.11, 0.9136) (25.29  0.9627) (25.68  0.9546) Figure 5 In images with strong internal repetitive struct. even though the LR image was generated using the 'ideal' supervised setting (i.e., bicubic downscaling). Bicubic interpolationEDSR [#b12][13] ZSSR (ours) 27.9216  0.7504 27.5600  0.7135 28.6148  0.7809 Table 3 SR in the presence of unknown image degradation. Each LR image. re s is the HRLR downscaling factor. Thus, each LR image was subsampled by a different random kernel. Table 2 compares our against the leading externallysupervised SR methods [#b12][]. We also compared our performance to the unsupervised BlindSR method of [15]. We c </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> blind deblurring using internal patch recurrence </p><p> 4"[], BlindSR [15] (when the downscaling kernel is unknown), BlindDeblurring [#b15][], BlindDehazing [3], and more. While such unsupervised methods can exploit imagespe </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a+: adjusted anchored neighborhood regression for fast super-resolution </p><p> " target"b11"12,13]. The recent SotA (State of the Art) method [13] exceeds previous nonDeep SR methods (supervised [#b21][22] or unsupervised []) by a few dBs a huge marg </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> zero-shot learning -the good, the bad and the ugly </p><p> rical evidence of these statements.The term "ZeroShot" used here, is borrowed from the domains of recognitionclassification. Note however, that unlike these approaches for ZeroShot Learning [#b22][23] or Oneshot Learning [19], our approach does not require any side informationattributes or any additional images. We may </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> accurate blur models vs. image priors in single image super-resolution </p><p> ngly, the unsupervised BlindSR method of [15], which does not use deep learning, also outperforms SotA SR methods. This supports the analysis and observations of [#b17][18], that (i) an accurate downscaling model is more important than sophisticated image priors, and (ii) using the wrong donwscaling kernel leads to oversmoothed S </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a+: adjusted anchored neighborhood regression for fast super-resolution </p><p> " target"b11"12,13]. The recent SotA (State of the Art) method [13] exceeds previous nonDeep SR methods (supervised [#b21][22] or unsupervised []) by a few dBs a huge marg </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> blind dehazing using internal patch recurrence </p><p> SR [15] (when the downscaling kernel is unknown), BlindDeblurring [], BlindDehazing [#b2][3], and more. While such unsupervised methods can exploit imagespecific information (hence are less subject to the abovementioned supervised restrictions), they </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> accurate image superresolution using very deep convolutional networks </p><p> rResolution (SR) from a single image has recently received a huge boost in performance using DeepLearning based methods [[#b8]]. The recent SotA (State of the Art) method [13]r. rs, each has 64 channels. We use ReLU activations on each layer. The network input is interpolated to the output size. As done in previous CNNbased SR methods [[#b8]], we only learn the residual between the interpolated LR and its HR parent. We use L 1 loss with ADAM optimizer ref type"b. gure"1). In order to quantitatively evaluate ZSSR's performance, we ran several controlled experiments on a variety of settings. Interestingly, ZSSR produces competitive results (although VDSR [#b8][9] EDSR [13] BlindSR [15] ZSSR [estimated kernel] (ours) ZSSR [true kernel] (ours) 27.7. though our CNN is small, and has not been pretrained). However, on 'nonideal' datasets, ZSSR surpasses SotA SR by a large margin. All reported numerical were produced using the evaluation script of [#b8][]. The 'Ideal' CaseWhile this is not the aim of. ely trained for these conditions. In fact, ZSSR is significantly better than the older SRCNN [4], and in some cases achieves comparable or better results than VDSR [#b8][9] (which was the SotA until a year ago). Within the unsupervisedSR regime, ZSSR outperforms the leading method SelfExSR [7] b. s, each LR image was subsampled by a different random kernel. Table 2 compares our against the leading externallysupervised SR methods [[#b8]]. We also compared our performance to the unsupervised BlindSR method of [15]. We considered two cases for applying ZSSR (i </p>
<p> Zero-Shot Super-Resolution using Deep Internal Learning </p><p> a database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics </p><p> caling kernelsThe purpose of this experiment is to test more realistic blur kernels with the ability to numerically evaluate the results. For this purpose we created a new dataset from BSD100 [#b13][14] by downscaling the HR images using random (but reasonably sized) Gaussian kernels. For each image, the covariance matrix  of its downscaling kernel was chose. LR imagesIn this experiment, we tested images with different types of quality degradation. To test the robustness of ZSSR in coping with unknown damage, we chose for each image from BSD100 [#b13][14] a random type of degradation out of 3 degradations (i) Gaussian noise [  .], (ii) Speckle noise [  .], (iii) JPEG compression [quality  45 (By MAT </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> neural machine translation by jointly learning to align and translate </p><p> text. Then we learn the interactions between context and question by standard attentions (Xiong et al., 2016Seo et al., 2016[#b2]Bahdanau et al., 2015). The resulting representation is encoded again with our recurrencyfree encoder before finally decoding to the probability of each position b. The augmentation process is illustrated in Figure 2 with French as a pivotal language.In this work, we consider attentionbased neural machine translation (NMT) models [#b2]Bahdanau et al. (2015) Luong et al. (2015), which have demonstrated excellent translation quality ref type"bibr" target"b4 </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> attention is all you need </p><p> een made to replace the recurrent networks by full convolution or full attention architectures (Kim, 2014Gehring et al., 2017[#b36]Vaswani et al., 2017bShen et al., 2017a). Those models have been shown to be not only faster than the RNN architectures, but </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> learning paraphrastic sentence embeddings from back-translated bitext </p><p> cept of backtranslation has been introduced before, it is often used to improve either the same translation task Sennrich et al. ( 2016) or instrinsic paraphrase evaluations [#b41]Wieting et al. (2017) Mallinson et al. (2017). Our approach is a novel application of backtranslation to enrich training data </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> learning to skim text </p><p> Short Term Memory architectures (Hochreiter amp Schmidhuber, 1997). For simple tasks such as text classification, with reinforcement learning techniques, models [#b44](Yu et al., 2017) have been proposed to skip irrelevant tokens to both further address the long dependencies issue and speed up the procedure. However, it is not c </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> triviaqa: a large scale distantly supervised challenge dataset for reading comprehension </p><p> model on the SQuAD dataset (Rajpurkar et al., 2016), considered to be one of the most competitive datasets in QampA. We also conduct similar studies on TriviaQA [#b17](Joshi et al., 2017), another QampA dataset, to show that the effectiveness and efficiency of our model are general. div xmlns"httpwww.teic.orgn. ia subdataset contains around 92K training and 11K development examples. The average context and question lengths are 495 and 15 respectively. In addition to the full development set, the authors of [#b17]Joshi et al. (2017) also pick a verified subset that all the contexts inside can answer the associated questions. As the text could be long, we adopt the data proc. fied subset that all the contexts inside can answer the associated questions. As the text could be long, we adopt the data processing similar to Hu et al. (2017) [#b17]Joshi et al. (2017). In particular, for training and validation, we randomly select a window of length 256 and 400 encapsulating the answer respectively. All the r. ic in the NLP domain. Their popularity can be attributed to an increase in publicly available annotated datasets, such as SQuAD (Rajpurkar et al., 2016), TriviaQA [#b17](Joshi et al., 2017), CNNDaily News (Hermann et al., 2015), WikiReading (Hewlett et al., 2016. res on the adversarial SQuAD test set. EXPERIMENTS ON TRIVIAQAIn this section, we test our model on another dataset TriviaQA [#b17](Joshi et al., 2017), which consists of 650K contextqueryanswer triples. There are 95K distinct questionanswer pairs, which are authored by Trivia enthusiasts,. elated to the answer at all, as it is crawled by key words.In this paper, we focus on testing our model on the subset consisting of answers from Wikipedia.According to the previous work [#b17](Joshi et al., 2017Hu et al., 2017Pan et al., 2017), the same model would have similar </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> adversarial examples for evaluating reading comprehension systems </p><p> bmitted for test set evaluation. ROBUSTNESS STUDYIn the following, we conduct experiments on the adversarial SQuAD dataset [#b16](Jia amp Liang, 2017) to study the robustness of the proposed model. In this dataset, one or more sentences are appended to the original SQuAD context of test se. F1 on test set), but now it is submitted to the adversarial server for evaluation. The results are shown in Table 6, where the F1 scores of other models are all extracted from [#b16]Jia amp Liang (2017). 15 Again, we only compare the performance of single models. From Table 6,. _15"The code is directly downloaded from httpsgithub.comallenaibiattflow Only F1 scores are reported in[#b16]Jia amp Liang (2017)  Rico Sennrich, Barry Haddow, and Alexandra Birch. Improvi </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> adversarial examples for evaluating reading comprehension systems </p><p> bmitted for test set evaluation. ROBUSTNESS STUDYIn the following, we conduct experiments on the adversarial SQuAD dataset [#b16](Jia amp Liang, 2017) to study the robustness of the proposed model. In this dataset, one or more sentences are appended to the original SQuAD context of test se. F1 on test set), but now it is submitted to the adversarial server for evaluation. The results are shown in Table 6, where the F1 scores of other models are all extracted from [#b16]Jia amp Liang (2017). 15 Again, we only compare the performance of single models. From Table 6,. _15"The code is directly downloaded from httpsgithub.comallenaibiattflow Only F1 scores are reported in[#b16]Jia amp Liang (2017)  Rico Sennrich, Barry Haddow, and Alexandra Birch. Improvi </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> glove: global vectors for word//w representation </p><p> the embedding of each word w by concatenating its word embedding and character embedding. The word embedding is fixed during training and initialized from the p 1  300 dimensional pretrained GloVe [#b28](Pennington et al., 2014) word vectors, which are fixed during training. All the outofvocabulary words are mapped to an ltUNKgt token, whose embedding is tra. aining, we batch the examples by length and dynamically pad the short sentences with special symbol ltPADgt. The maximum answer length is set to 30. We use the pretrained 300D word vectors GLoVe [#b28](Pennington et al., 2014), and all the outofvocabulary words are replace with ltUNKgt, whose embedding is updated during training. Each character embedding i </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> squad: 100, 000+ questions for machine comprehension of text </p><p> ful combination of these two ingredients is the Bidirectional Attention Flow (BiDAF) model by Seo et al. (2016), which achieve strong results on the SQuAD dataset [#b30](Rajpurkar et al., 2016). A weakness of these models is that they are often slow for both training and inference due to their recurrent nature, especially for long. "4"EXPERIMENTSIn this section, we conduct experiments to study the performance of our model and the data augmentation technique. We will primarily benchmark our model on the SQuAD dataset [#b30](Rajpurkar et al., 2016), considered to be one of the most competitive datasets in QampA. We also conduct similar studies on TriviaQA ref type"bibr" target"b. ERIMENTS ON SQUAD DATASET AND EXPERIMENTAL SETTINGSDataset. We consider the Stanford Question Answering Dataset (SQuAD) [#b30](Rajpurkar et al., 2016) for machine reading comprehension.8 SQuAD contains 107.7K queryanswer pairs, with 87.5K for train. ere are exceptionally long cases. Only the training and validation data are publicly available, while the test data is hidden that one has to submit the code to a Codalab and work with the authors of [#b30](Rajpurkar et al., 2016) to retrieve the final test score. In our experiments, we report the test set result of our best single model.ref type"foot" target"foo. t the RNN models, we also test the corresponding model architecture with each encoder block replaced with a stack of bidirectional Published 12 LeaderBoard 13 Single Model EM  F1 EM  F1 LR Baseline [#b30](Rajpurkar et al., 2016) 40.4  51.0 40.4  51.0 Dynamic Chunk Reader (Yu et al., 2016) 62.5  71.0 62.5  71.0 MatchLSTM wit. mprehension and automated question answering has become an important topic in the NLP domain. Their popularity can be attributed to an increase in publicly available annotated datasets, such as SQuAD [#b30](Rajpurkar et al., 2016), TriviaQA (Joshi et al., 2017), CNNDaily News (Hermann et al., 2015). The injected noise in the training data might not only improve the generalization of the model but also make it robust to the adversarial sentences.Single Model AddSent AddOneSent Logistic [#b30](Rajpurkar et al., 2016) 23.2 30.4 Match (Wang amp Jiang, 2016) 27.3 39.0 SEDT (Liu et al., 2 </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> learning to skim text </p><p> Short Term Memory architectures (Hochreiter amp Schmidhuber, 1997). For simple tasks such as text classification, with reinforcement learning techniques, models [#b44](Yu et al., 2017) have been proposed to skip irrelevant tokens to both further address the long dependencies issue and speed up the procedure. However, it is not c </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> learning to skim text </p><p> Short Term Memory architectures (Hochreiter amp Schmidhuber, 1997). For simple tasks such as text classification, with reinforcement learning techniques, models [#b44](Yu et al., 2017) have been proposed to skip irrelevant tokens to both further address the long dependencies issue and speed up the procedure. However, it is not c </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> xception: deep learning with depthwise separable convolutions </p><p>  </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> character-level convolutional networks for text classification </p><p> than ours. The elimination of attention further has sacrificed the performance (with EM 68.4 and F1 77.1).Data augmentation has also been explored in natural language processing. For example, [#b47]Zhang et al. (2015) proposed to enhance the dataset by replacing the words with their synonyms and showed its effectiveness in text classification. ref type"bibr </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> glove: global vectors for word//w representation </p><p> the embedding of each word w by concatenating its word embedding and character embedding. The word embedding is fixed during training and initialized from the p 1  300 dimensional pretrained GloVe [#b28](Pennington et al., 2014) word vectors, which are fixed during training. All the outofvocabulary words are mapped to an ltUNKgt token, whose embedding is tra. aining, we batch the examples by length and dynamically pad the short sentences with special symbol ltPADgt. The maximum answer length is set to 30. We use the pretrained 300D word vectors GLoVe [#b28](Pennington et al., 2014), and all the outofvocabulary words are replace with ltUNKgt, whose embedding is updated during training. Each character embedding i </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> making neural qa as simple as possible but not simpler </p><p> nal convolution. The output of this layer is a also of dimension d  128.3. ContextQuery Attention Layer. This module is standard in almost every previous reading comprehension models such as [#b40]Weissenborn et al. (2017) and Chen et al. (2017). We use C and Q to denote the encoded context and query. The contexttoquery. ctive Matching (Wang et al., 2016) 65.5  75.1 70.4  78.8 Dynamic Coattention Networks (Xiong et al., 2016) 66.2  75.9 66.2  75.9 FastQA [#b40](Weissenborn et al., 2017) 68.4  77.1 68.4  77.1 BiDAF (Seo et al., 2016) 68.0  77.3 68.0  77.3 SEDT ref type"bibr" targ. 77.3 68.0  77.3 SEDT (Liu et al., 2017a) 68.1  77.5 68.5  78.0 RaSoR (Lee et al., 2016) 70.8  78.7 69.6  77.7 FastQAExt [#b40](Weissenborn et al., 2017) 70.8  78.9 70.8  78.9 ReasoNet (Shen et al., 2017b) 69.1  78.9 70.6  79.4 Document Reader ref. bidirectional attention and making computation conditional on the search beams. Nevertheless, their model is still based on the RNNs and the accuracy is not competitive, with an EM 68.4 and F1 76.2. [#b40]Weissenborn et al. (2017) also tried to build a fast QampA model by deleting the contextquery attention module. However, it again relied on RNN and is thus intr </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> paraphrasing revisited with neural machine translation </p><p> ten used to improve either the same translation task Sennrich et al. ( 2016) or instrinsic paraphrase evaluations Wieting et al. (2017) [#b26]Mallinson et al. (2017). Our approach is a novel application of backtranslation to enrich training data for downstream tasks, in this case, the question answering </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> xception: deep learning with depthwise separable convolutions </p><p>  </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> xception: deep learning with depthwise separable convolutions </p><p>  </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> paraphrasing revisited with neural machine translation </p><p> ten used to improve either the same translation task Sennrich et al. ( 2016) or instrinsic paraphrase evaluations Wieting et al. (2017) [#b26]Mallinson et al. (2017). Our approach is a novel application of backtranslation to enrich training data for downstream tasks, in this case, the question answering </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> reading wikipedia to answer opendomain questions </p><p>  128.3. ContextQuery Attention Layer. This module is standard in almost every previous reading comprehension models such as Weissenborn et al. (2017) and [#b3]Chen et al. (2017). We use C and Q to denote the encoded context and query. The contexttoquery attention is constructed as follows We first computer the similari. ments and previous works, such as (Seo et al., 2016Xiong et al., 2016Wang et al., 2017[#b3]Chen et al., 2017), the validation score is well correlated with the test score.Data Preprocessing. We use the NLTK tokenizer to preprocess the data. ref ty. AExt (Weissenborn et al., 2017) 70.8  78.9 70.8  78.9 ReasoNet (Shen et al., 2017b) 69.1  78.9 70.6  79.4 Document Reader [#b3](Chen et al., 2017) 70.0  79.0 70.7  79.4 Ruminating Reader (Gong amp Bowman, 2017) 70.6  79.5 70.6  79.5 jNet ref type. lly, each (embedding and model) encoder block is replaced with a 1, 2, or 3 layer Bidirectional LSTMs respectively, as such layer numbers fall into the usual range of the reading comprehension models [#b3](Chen et al., 2017). All of these LSTMs have hidden size 128. The results of the speedup comparison are shown in Table 3. We can easily see. type"bibr" target"b38"(Wang et al., 2017), DCN (Xiong et al., 2016), ReasoNet (Shen et al., 2017b), Document Reader [#b3](Chen et al., 2017), Interactive AoA Reader (Cui et al., 2017) and Reinforced Mnemonic Reader (Hu </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> globally normalized reader </p><p> ing the beam search decoding and paraphrasing questions and answers in the dataset as well. In addition, we can combine this method with other data augmentation methods, such as, the type swap method [#b29](Raiman amp Miller, 2017), to acquire more diversity in paraphrases.In our experiments, we observe that the proposed data augmentation can bring nontrivi. avor of feed forward architectures.Our paper is also first to mix selfattention and convolutions, which proves to be empirically effective and achieves a significant gain of 2.7 F1. Note that [#b29]Raiman amp Miller (2017) recently proposed to accelerate reading comprehension by avoiding bidirectional attention and making computation conditional on the sea. . For example, Zhang et al. (2015) proposed to enhance the dataset by replacing the words with their synonyms and showed its effectiveness in text classification. [#b29]Raiman amp Miller (2017) suggested using type swap to augment the SQuAD dataset, which essentially replaces the words in the original paragraph with others with </p>
<p> QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension. </p><p> paraphrasing revisited with neural machine translation </p><p> ten used to improve either the same translation task Sennrich et al. ( 2016) or instrinsic paraphrase evaluations Wieting et al. (2017) [#b26]Mallinson et al. (2017). Our approach is a novel application of backtranslation to enrich training data for downstream tasks, in this case, the question answering </p>
<p> taming hardware event samples for fdo compilation </p><p> profileme: hardware support for instruction-level profiling on out-of-order processors </p><p> For example, previous work shows that on an Alpha 21064, the recorded PC corresponds to the instruction that is at the head of the instruction queue 6cycles after the one that triggered the overflow [#b11][12]. On an Intel Core 2 machine, we observed a similar phenomenon. The reported PC corresponds to the instruction that is at the head of the instruction queue som. g with randomized sampling periods appears to be a more promising approach.AMD processors, on the other hand, provide instructionbased sampling (IBS) which is similar to the ProfileMe approach [#b11][12]. Unfortunately, this facility only allows sampling instructions fetched (which include instructions on mispredicted paths) or ?ops retired (which are at a fi. ation to perform the mapping.Specialized hardware has also been proposed to facilitate PMUbased profiling. ProfileMe was proposed hardware support to allow accurate instructionlevel sampling [#b11][12] for Alpha processors. AMD adopts the ProfileMe approach in the Opteron processors. As discussed in Section 3.2, it cannot produce profiles accurate enough for </p>
<p> taming hardware event samples for fdo compilation </p><p> a hardware-driven profiling scheme for identifying program hot spots to support runtime optimization </p><p> Opteron processors. As discussed in Section 3.2, it cannot produce profiles accurate enough for compiler use. Merten et al. also propose specialized hardware support for identifying program hot spots [#b19][20]. Unfortunately, the hardware they propose is not available in today's commercial processors.Orthogonal to collecting profiles, recent work has studied </p>
<p> taming hardware event samples for fdo compilation </p><p> optimally profiling and tracing programs </p><p> ent and identifying a set of representative input can be very difficult.Fourth, the instrumented profile collection run typically incurs significant overhead (reported to range from 9 to 105 [#b4][5], [6], but has been observed to be as much as 10x on an industrial web search application) due to the additional instrumentat </p>
<p> taming hardware event samples for fdo compilation </p><p> taming hardware event samples for fdo compilation </p><p> s provides an absolute speedup of 14.24. This speedup is due to a series of components in the framework. Initially, using traditional PMUbased sampling to collect frequency profile, as described in [#b8][9], approximately 4.35 speedup can be achieved. If we use LBR to collect the profile, the speedup increases to 7.38. After enabling the lightweight interprocedu </p>
<p> taming hardware event samples for fdo compilation </p><p> a hardware-driven profiling scheme for identifying program hot spots to support runtime optimization </p><p> Opteron processors. As discussed in Section 3.2, it cannot produce profiles accurate enough for compiler use. Merten et al. also propose specialized hardware support for identifying program hot spots [#b19][20]. Unfortunately, the hardware they propose is not available in today's commercial processors.Orthogonal to collecting profiles, recent work has studied </p>
<p> taming hardware event samples for fdo compilation </p><p> can hardware performance counters be trusted </p><p> today's commercial processors.Orthogonal to collecting profiles, recent work has studied the stability and accuracy of hardware performance counters [21], [#b25][26]. In that work, the authors measured the total number of instructions retired across a range of benchmarks on various x86 machines running identical binaries. </p>
<p> taming hardware event samples for fdo compilation </p><p> lightweight feedback-directed cross-module optimization </p><p> file. In traditional interprocedural optimization (IPO), a compiler reads in all the modules to carry out a wholeprogram analysis, which is usually extremely expensive and not scalable.LIPO [#b17][18] is a technique aimed at using a lightweight approach to perform IPO. The basic idea is to identify modules that have large degree of affinity. When compiling </p>
<p> taming hardware event samples for fdo compilation </p><p> continuous profiling: where have all the cycles gone? </p><p> . The sample count attributed to each instruction is still proportional to  the total amount of cycles it consumes. As a result, this phenomenon does not affect the precision of the collected profile [#b2][3]. However, for INST_RETIRED event sampling, the effects of skid are important. Figure 2 shows how this effect interacts. ounts. We refer to this as the shadow effect. Previous work suggests accounting for this phenomenon by approximating the amount of time that an instruction spends at the head of the instruction queue [#b2][3]. Unfortunately, estimating this quantity on a modern outoforder, superscalar processor with a deep cache hierarchy is difficult. In the next section, we show h </p>
<p> taming hardware event samples for fdo compilation </p><p> value profiling </p><p> ors show, for example, how to collect flow sensitive cache miss profiles from an application.Besides the frequency profiling, instrumentation based value profiling has been proven to be useful [#b7][8], [15], and has been adopted in some compilers such as GCC. However, the instrumentation based approach suffers from excessi </p>
<p> taming hardware event samples for fdo compilation </p><p> value profiling </p><p> ors show, for example, how to collect flow sensitive cache miss profiles from an application.Besides the frequency profiling, instrumentation based value profiling has been proven to be useful [#b7][8], [15], and has been adopted in some compilers such as GCC. However, the instrumentation based approach suffers from excessi </p>
<p> taming hardware event samples for fdo compilation </p><p> exploiting hardware performance counters with flow and context sensitive profiling </p><p> pSimilarly, there have been proposals that combine instrumentation and hardware performance counters. Ammons, Ball, and Larus proposed instrumenting programs to read hardware performance counters [#b1][2]. By selecting where to reset and sample the counters, the authors are able to extract flow and context sensitive profiles. These profiles are not limited to sim </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> running sparse and low-precision neural network: when algorithm meets hardware </p><p> platform is 669.1 GOPs, which is very close to this roof.The third type of designs reduce the number of MAC operations by directly pruning the CNN model [[#b1]]. Unimportant weights are forced to zero during the training (or finetuning) stage so that they will not contribute to comp. apped sparse CNNs onto FPGA accelerator. The reported performance was 271.6 GOPs on a Zynq VC706 FPGA without further information disclosed on resource utilization and working frequency. The work of [#b1][2] presented an algorithmhardware codesign scheme to improve the efficiency of sparse convolutional layers executed in hardware. A structurally pruned AlexNet mod </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> improving the performance of opencl-based fpga accelerator for convolutional neural network </p><p> tal operations for most CNNs. According to the way in which convolution computation is implemented, existing designs can be divided into three major categories. The first category of designs, such as [#b3][]  of the convolution computation in Spatial Domain (referred to as SDConv) by usi. d by the average inference time. Moreover, in order to make a fair comparison, we only use the number achieved by FPGA accelerator rather than the whole system in the following discussion. Designs of [#b3][] are based on spatial convolution, while the works of ref type"bibr" target"b. that implements spatial convolution [13] on the same device, we achieve considerably 3.8? improvement in throughput when normalized by frequency. To compare with [#b3][4], [12] and [10] that are implemented on a different type of FPGA device, we further norm </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> an fpga design framework for cnn sparsification and acceleration </p><p> close to this roof.The third type of designs reduce the number of MAC operations by directly pruning the CNN model [[#b7]]. Unimportant weights are forced to zero during the training (or finetuning) stage so that they will not contribute to computational workload and memory bandwidt. ques presented in this work were resource utilization and power optimization orientated. The CNN model evaluated was of low complexity (0.44 GOP) and the performance achieved was only 31.79 GOPs. In [#b7][8], the authors reported an design framework which mapped sparse CNNs onto FPGA accelerator. The reported performance was 271.6 GOPs on a Zynq VC706 FPGA without </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> sparcnet: a hardware accelerator for efficient deployment of sparse convolutional networks </p><p> target"b2"[3] on a Intel HARP platform is 669.1 GOPs, which is very close to this roof.The third type of designs reduce the number of MAC operations by directly pruning the CNN model [#b0][]. Unimportant weights are forced to zero during the training (or finetuning) stage s. used. It is clear that our design shows over 3? advantage in performance density than all three designs. RELATED WORKStudy of [#b0][1] presented an energyefficient accelerator that deployed sparse convolutional neural networks on a Artix7 FPGA. Techniques presented in this work were resource </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> a framework for generating high throughput cnn implementations on fpgas </p><p> GA which has 256 DSPs, the maximum attainable inference throughput is 204.8 GOPs under frequency of 200 MHz. (each DSP can perform two 168bit fixedpoint MACs).The second category of designs [#b2][] perform convolution in the Frequency Domain (referred to as FDConv). By reducing the number of MAC operations required fo. ccelerator raises the computational roof over SDConvbased design by a factor of R mac , where R mac is the reduction rate in MAC operation. For instance, up to 69.2 of the MAC operation is saved in [#b2][3], resulting in a theoretical speedup of 3.3? in peak performance. The throughput achieved by [#b2][3] on a Intel HARP platform is. eration. For instance, up to 69.2 of the MAC operation is saved in [#b2][3], resulting in a theoretical speedup of 3.3? in peak performance. The throughput achieved by [#b2][3] on a Intel HARP platform is 669.1 GOPs, which is very close to this roof.The third type of designs reduce the number of MAC operations by directly pruni. SpConvbased accelerators share a similar computational roof of 2 ? R mac ? N mac ? Freq with FDConvbased ones. The performance of the reported SpConvbased FPGA accelerators have not exceed that of [#b2][3].From an architecture view, existing FPGA accelerators tend to utilize a similar underlying architecture based on MAC arrays. The practical consequence is. orming ABMSpConv on a pruned VGG16 model [7]. 83.6 of the total operations (accumulate and multiply) is saved compared to SDConv, while the reduction over FDConv [#b2][3] and SpConv [7] are 47.1 and 50, respectively. HARDWARE ARCH. ing discussion. Designs of [] are based on spatial convolution, while the works of [#b2][] use frequency domain convolution.The latest work of [#b2][3] uses a frequency domai. 3] are based on spatial convolution, while the works of [#b2][] use frequency domain convolution.The latest work of [#b2][3] uses a frequency domain convolution scheme which gains 3.3? reduction in MAC operations for both CNN models. For VGG16, the model pruning scheme adopted in our. or both CNN models. For VGG16, the model pruning scheme adopted in our design maintains a similar reduction rate of 3.06?. The implemented accelerator achieves 1.55? speedup in throughput compared to [#b2][3] as a result of being able to utilize 1.6? accumulators to accelerate the convolution computation. Note that, although our scheme quantizes the CNN model in 8bi. able to utilize 1.6? accumulators to accelerate the convolution computation. Note that, although our scheme quantizes the CNN model in 8bit, the precision of the datapath is of the same (16bit) as [#b2][3]. For AlexNet, the pruning scheme adopted by us only reduces the total MAC operations by 2.3? (30  lower than that of [#b2][3]),. f the datapath is of the same (16bit) as [#b2][3]. For AlexNet, the pruning scheme adopted by us only reduces the total MAC operations by 2.3? (30  lower than that of [#b2][3]), but our scheme still improves the inference throughput by 5.4. When compared with design that implements spatial convolution [ </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> a framework for generating high throughput cnn implementations on fpgas </p><p> GA which has 256 DSPs, the maximum attainable inference throughput is 204.8 GOPs under frequency of 200 MHz. (each DSP can perform two 168bit fixedpoint MACs).The second category of designs [#b2][] perform convolution in the Frequency Domain (referred to as FDConv). By reducing the number of MAC operations required fo. ccelerator raises the computational roof over SDConvbased design by a factor of R mac , where R mac is the reduction rate in MAC operation. For instance, up to 69.2 of the MAC operation is saved in [#b2][3], resulting in a theoretical speedup of 3.3? in peak performance. The throughput achieved by [#b2][3] on a Intel HARP platform is. eration. For instance, up to 69.2 of the MAC operation is saved in [#b2][3], resulting in a theoretical speedup of 3.3? in peak performance. The throughput achieved by [#b2][3] on a Intel HARP platform is 669.1 GOPs, which is very close to this roof.The third type of designs reduce the number of MAC operations by directly pruni. SpConvbased accelerators share a similar computational roof of 2 ? R mac ? N mac ? Freq with FDConvbased ones. The performance of the reported SpConvbased FPGA accelerators have not exceed that of [#b2][3].From an architecture view, existing FPGA accelerators tend to utilize a similar underlying architecture based on MAC arrays. The practical consequence is. orming ABMSpConv on a pruned VGG16 model [7]. 83.6 of the total operations (accumulate and multiply) is saved compared to SDConv, while the reduction over FDConv [#b2][3] and SpConv [7] are 47.1 and 50, respectively. HARDWARE ARCH. ing discussion. Designs of [] are based on spatial convolution, while the works of [#b2][] use frequency domain convolution.The latest work of [#b2][3] uses a frequency domai. 3] are based on spatial convolution, while the works of [#b2][] use frequency domain convolution.The latest work of [#b2][3] uses a frequency domain convolution scheme which gains 3.3? reduction in MAC operations for both CNN models. For VGG16, the model pruning scheme adopted in our. or both CNN models. For VGG16, the model pruning scheme adopted in our design maintains a similar reduction rate of 3.06?. The implemented accelerator achieves 1.55? speedup in throughput compared to [#b2][3] as a result of being able to utilize 1.6? accumulators to accelerate the convolution computation. Note that, although our scheme quantizes the CNN model in 8bi. able to utilize 1.6? accumulators to accelerate the convolution computation. Note that, although our scheme quantizes the CNN model in 8bit, the precision of the datapath is of the same (16bit) as [#b2][3]. For AlexNet, the pruning scheme adopted by us only reduces the total MAC operations by 2.3? (30  lower than that of [#b2][3]),. f the datapath is of the same (16bit) as [#b2][3]. For AlexNet, the pruning scheme adopted by us only reduces the total MAC operations by 2.3? (30  lower than that of [#b2][3]), but our scheme still improves the inference throughput by 5.4. When compared with design that implements spatial convolution [ </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> sparcnet: a hardware accelerator for efficient deployment of sparse convolutional networks </p><p> target"b2"[3] on a Intel HARP platform is 669.1 GOPs, which is very close to this roof.The third type of designs reduce the number of MAC operations by directly pruning the CNN model [#b0][]. Unimportant weights are forced to zero during the training (or finetuning) stage s. used. It is clear that our design shows over 3? advantage in performance density than all three designs. RELATED WORKStudy of [#b0][1] presented an energyefficient accelerator that deployed sparse convolutional neural networks on a Artix7 FPGA. Techniques presented in this work were resource </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> a framework for generating high throughput cnn implementations on fpgas </p><p> GA which has 256 DSPs, the maximum attainable inference throughput is 204.8 GOPs under frequency of 200 MHz. (each DSP can perform two 168bit fixedpoint MACs).The second category of designs [#b2][] perform convolution in the Frequency Domain (referred to as FDConv). By reducing the number of MAC operations required fo. ccelerator raises the computational roof over SDConvbased design by a factor of R mac , where R mac is the reduction rate in MAC operation. For instance, up to 69.2 of the MAC operation is saved in [#b2][3], resulting in a theoretical speedup of 3.3? in peak performance. The throughput achieved by [#b2][3] on a Intel HARP platform is. eration. For instance, up to 69.2 of the MAC operation is saved in [#b2][3], resulting in a theoretical speedup of 3.3? in peak performance. The throughput achieved by [#b2][3] on a Intel HARP platform is 669.1 GOPs, which is very close to this roof.The third type of designs reduce the number of MAC operations by directly pruni. SpConvbased accelerators share a similar computational roof of 2 ? R mac ? N mac ? Freq with FDConvbased ones. The performance of the reported SpConvbased FPGA accelerators have not exceed that of [#b2][3].From an architecture view, existing FPGA accelerators tend to utilize a similar underlying architecture based on MAC arrays. The practical consequence is. orming ABMSpConv on a pruned VGG16 model [7]. 83.6 of the total operations (accumulate and multiply) is saved compared to SDConv, while the reduction over FDConv [#b2][3] and SpConv [7] are 47.1 and 50, respectively. HARDWARE ARCH. ing discussion. Designs of [] are based on spatial convolution, while the works of [#b2][] use frequency domain convolution.The latest work of [#b2][3] uses a frequency domai. 3] are based on spatial convolution, while the works of [#b2][] use frequency domain convolution.The latest work of [#b2][3] uses a frequency domain convolution scheme which gains 3.3? reduction in MAC operations for both CNN models. For VGG16, the model pruning scheme adopted in our. or both CNN models. For VGG16, the model pruning scheme adopted in our design maintains a similar reduction rate of 3.06?. The implemented accelerator achieves 1.55? speedup in throughput compared to [#b2][3] as a result of being able to utilize 1.6? accumulators to accelerate the convolution computation. Note that, although our scheme quantizes the CNN model in 8bi. able to utilize 1.6? accumulators to accelerate the convolution computation. Note that, although our scheme quantizes the CNN model in 8bit, the precision of the datapath is of the same (16bit) as [#b2][3]. For AlexNet, the pruning scheme adopted by us only reduces the total MAC operations by 2.3? (30  lower than that of [#b2][3]),. f the datapath is of the same (16bit) as [#b2][3]. For AlexNet, the pruning scheme adopted by us only reduces the total MAC operations by 2.3? (30  lower than that of [#b2][3]), but our scheme still improves the inference throughput by 5.4. When compared with design that implements spatial convolution [ </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> ristretto: a framework for empirical study of resource-efficient inference in convolutional neural networks </p><p> rnel.Iteratively repeating step (1) and ( 2) for all convolution channels will generate all M ? R ? ? C ? output feature map pixels.Studies [#b5][6] have shown that the weight can be quantized with 8bit (or less) precision with less than 1 decrease in inference accuracy. Thus, with a 8bit quantized weight. summarized in Table 3. Both models were pruned by the scheme proposed by Han et al. [7] and quantized with 8bit precision [#b5][6] with less than 1 accuracy drop compared to the original model. Comparison with StateoftheAr </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> an fpga design framework for cnn sparsification and acceleration </p><p> close to this roof.The third type of designs reduce the number of MAC operations by directly pruning the CNN model [[#b7]]. Unimportant weights are forced to zero during the training (or finetuning) stage so that they will not contribute to computational workload and memory bandwidt. ques presented in this work were resource utilization and power optimization orientated. The CNN model evaluated was of low complexity (0.44 GOP) and the performance achieved was only 31.79 GOPs. In [#b7][8], the authors reported an design framework which mapped sparse CNNs onto FPGA accelerator. The reported performance was 271.6 GOPs on a Zynq VC706 FPGA without </p>
<p> abm-spconv: a novel approach to fpga-based acceleration of convolutional neural network inference </p><p> ristretto: a framework for empirical study of resource-efficient inference in convolutional neural networks </p><p> rnel.Iteratively repeating step (1) and ( 2) for all convolution channels will generate all M ? R ? ? C ? output feature map pixels.Studies [#b5][6] have shown that the weight can be quantized with 8bit (or less) precision with less than 1 decrease in inference accuracy. Thus, with a 8bit quantized weight. summarized in Table 3. Both models were pruned by the scheme proposed by Han et al. [7] and quantized with 8bit precision [#b5][6] with less than 1 accuracy drop compared to the original model. Comparison with StateoftheAr </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> temporal generative adversarial nets with singular value clipping </p><p> [pos is Facial Sythesizer] nsition between frames, challenging. Some video generation methods have dealt with this problem by generating the entire sequence at once [25] or in small batches [#b19][20]. However, this introduces a lag in the generation process, prohibiting their use in realtime applications and requiring fixed length sequences for training.. [pos is Facial Sythesizer] ,25,24].Straightforward adaptations of GANs for videos are proposed in [[#b19]], replacing the 2D convolutional layers with 3D convolutional layers. Using 3D convolutions in the generator and discriminator networks is able to capture tempo. [pos is Facial Sythesizer] h 3D convolutional layers. Using 3D convolutions in the generator and discriminator networks is able to capture temporal dependencies but requires fixed length videos. This limitation was overcome in [#b19][20] but constraints need to be imposed in the latent space to generate consistent videos.The MoCoGAN system proposed in [24] </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> generating videos with scene dynamics </p><p> [pos is Facial Sythesizer] g natural sequences, which are characterized by a seamless transition between frames, challenging. Some video generation methods have dealt with this problem by generating the entire sequence at once [#b24][25] or in small batches [20]. However, this introduces a lag in the generation process, prohibiting their use in realtime ap. [pos is Facial Sythesizer] mpared to L 1 and L 2 losses. However, GANs are not limited to these applications and can be extended to handle videos [[#b24]].Straightforward adaptations of GANs for videos are proposed in [#b24][25,ref ty. [pos is Facial Sythesizer] 6,14,[#b24]25,24].Straightforward adaptations of GANs for videos are proposed in [#b24][], replacing the 2D convolutional layers with 3D convolutional layers. Using 3D convolutions in the generator and discri </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> audio-visual integration in multimodal communication </p><p> [pos is Facial Sythesizer] ed in [14] uses a combination of variational auto encoders (VAE) and GANs in its generating network and a 3D CNN as a sequence discriminator. Finally, Chen et al. [#b3][4] propose a GANbased encoderdecoder architecture that uses CNNs in order to convert audio spectrograms to frames and vice versa.3 EndtoEnd SpeechDrive </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> very deep convolutional neural networks for raw waveforms </p><p> [pos is Facial Sythesizer] io frames are encoded using a network comprising of 1D convolutions followed by batch normalization and ReLU activations. The initial convolutional layer starts with a large kernel, as recommended in [#b6][7], which helps limit the depth of the network while ensuring that the lowlevel features are meaningful. Subsequent layers use smaller kernels until an embedding </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> image sharpness measure for blurred images in frequency domain </p><p> [pos is Facial Sythesizer] ur detection (CPBD) measure [17], which determines blur based on the presence of edges in the image and the frequency domain blurriness measure (FDBM) proposed in [#b7][8], which is based on the spectrum of the image. For these metrics larger values imply better quality. The content of the videos is evaluated based on how well the </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> audio-visual integration in multimodal communication </p><p> [pos is Facial Sythesizer] ed in [14] uses a combination of variational auto encoders (VAE) and GANs in its generating network and a 3D CNN as a sequence discriminator. Finally, Chen et al. [#b3][4] propose a GANbased encoderdecoder architecture that uses CNNs in order to convert audio spectrograms to frames and vice versa.3 EndtoEnd SpeechDrive </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> video rewrite </p><p> [pos is Facial Sythesizer] methods to generate realistic faces [12]. Some methods avoid the use of CG by selecting frames from a personspecific database and combining them to form a video [#b2][]. Regardless of which approach is used these methods are subject dependent and are often associated with a considerable o. [pos is Facial Sythesizer] ecover the most likely mouth shapes for a speech signal. A similar approach is used in [26] to estimate the sequence of lip parameters. Finally, the Video Rewrite [#b2][3] method relies on the same principals to obtain a sequence of triphones that are used to look up mouth images from a database.Although HMMs were initially </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> audio-visual integration in multimodal communication </p><p> [pos is Facial Sythesizer] ed in [14] uses a combination of variational auto encoders (VAE) and GANs in its generating network and a 3D CNN as a sequence discriminator. Finally, Chen et al. [#b3][4] propose a GANbased encoderdecoder architecture that uses CNNs in order to convert audio spectrograms to frames and vice versa.3 EndtoEnd SpeechDrive </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> generative adversarial networks </p><p> [pos is Facial Sythesizer] resulting in faces that are mostly static except for the mouth. GANBased Video SynthesisThe recent introduction of GANs in [#b9][10] has shifted the focus of the machine learning community to generative modelling. GANs consist of two competing networks a generative network and a discriminat </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> you said that? </p><p> [pos is Facial Sythesizer] ependent and are often associated with a considerable overhead when transferring to new speakers.Subject independent approaches have been proposed that transform audio features to video frames [#b4][5] but there is still no method to directly transform raw audio to video. Furthermore, many methods restrict the problem to generating only the mouth. Even techniq. [pos is Facial Sythesizer] primarily focused on obtaining realistic lip movements, and typically neglect the importance of generating natural facial expressions. Some methods generate frames based solely on present information [#b4][5], without taking into account the facial dynamics. This makes generating natural sequences, which are characterized by a seamless transition between frames, chal. [pos is Facial Sythesizer] to 3D meshes of a specific person. This system is conceptually broken into subnetworks responsible for capturing articulation dynamics and estimating the 3D points of the mesh. Finally, Chung et al. [#b4][5] proposed a CNN applied on Melfrequency cepstral coefficients (MFCCs) that generates subject independent videos from an audio clip and a still frame. The method. [pos is Facial Sythesizer] fig_9"7.  Coarticulation is evident in (a) where "bin" is followed by the word "blue".   The works that are closest to ours are those proposed in [22] and [#b4][5]. The former method is subject dependent and requires a large amount of data for a specific person to generate videos. For the latter method there is no publicly. [pos is Facial Sythesizer] os. For the latter method there is no publicly available implementation so we compare our model to a static method that produces video frames using a sliding window of audio samples like that used in [#b4][5]. This is a GANbased method that uses a combination of an L 1 loss and an adversarial loss on individual frames. We will also use this method as the baseline fo. [pos is Facial Sythesizer] erence in the WER. We believe that these improvements are not only a result of using a temporal generator but also due to the use of the conditional Sequence Discriminator. Unlike previous approaches [#b4][5] that prohibit the generation of facial expressions, the adversarial loss on the entire sequence encourages spontaneous facial gestures. This has been demonstrat </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> generation of mouthshapes for a synthetic talking head </p><p> [pos is Facial Sythesizer] bibr" target"b27"[28].Some of the earliest methods for facial animation relied on hidden Markov models (HMMs) to capture the dynamics of the video and speech sequences. Simons and Cox [#b20][21] used vector quantization to achieve a compact representation of video and audio features, which were used as the states for their HMM. The HMM was used to rec </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> audio-driven facial animation by joint end-to-end learning of pose and emotion </p><p> [pos is Facial Sythesizer] ajority of research in this domain has focused on mapping audio features (e.g. MFCCs) to visual features (e.g. landmarks, visemes) and using computer graphics (CG) methods to generate realistic faces [#b11][12]. Some methods avoid the use of CG by selecting frames from a personspecific database and combining them to form a video [3,re. [pos is Facial Sythesizer] arget"b21"22], producing realistic results but are subject dependent and require retraining or retargeting steps to adapt to new faces.Convolutional neural networks (CNN) are used in [#b11][12] to transform audio features to 3D meshes of a specific person. This system is conceptually broken into subnetworks responsible for capturing articulation dyn </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> quantitative association of vocal-tract and facial behavior </p><p> [pos is Facial Sythesizer] btle abnormalities in facial motion and audiovisual synchronization.Of particular interest is speechdriven facial animation since speech acoustics are highly correlated with facial movements [#b26][27]. These systems could simplify the film animation process through automatic generation from the voice acting. They can also be applied in movie dubbing to achi. [pos is Facial Sythesizer] ns1.0"SpeechDriven Facial AnimationThe problem of speechdriven video synthesis is not new in computer vision and has been the subject of interest for decades. Yehia et al. [#b26][27] first examined the relationship between acoustics, vocaltract and facial motion, showing a strong correlation between visual and audio features and a weak co </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> very deep convolutional neural networks for raw waveforms </p><p> [pos is Facial Sythesizer] io frames are encoded using a network comprising of 1D convolutions followed by batch normalization and ReLU activations. The initial convolutional layer starts with a large kernel, as recommended in [#b6][7], which helps limit the depth of the network while ensuring that the lowlevel features are meaningful. Subsequent layers use smaller kernels until an embedding </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> tcd-timit: an audio-visual corpus of continuous speech </p><p> [pos is Facial Sythesizer] o ensure that the identity of the speaker is maintained throughout the sequence. Evaluation is performed in a subject independent way on the GRID [6] and TCD TIMIT [#b10][11] datasets, where our model achieves truly natural results. Finally, the realism of the videos is assessed through an online Turing test, where users are shown </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> lip movement synthesis from speech based on hidden markov models </p><p> [pos is Facial Sythesizer] ct representation of video and audio features, which were used as the states for their HMM. The HMM was used to recover the most likely mouth shapes for a speech signal. A similar approach is used in [#b25][26] to estimate the sequence of lip parameters. Finally, the Video Rewrite [3] method relies on the same principals to obtain </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> a no-reference perceptual image sharpness metric based on a cumulative probability of blur detection </p><p> [pos is Facial Sythesizer] take into account the fact that reconstruction metrics penalize videos for any spontaneous expression. The frame sharpness is evaluated using the cumulative probability blur detection (CPBD) measure [#b16][17], which determines blur based on the presence of edges in the image and the frequency domain blurriness measure (FDBM) proposed in ref type"bibr" target"b7 </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> video rewrite </p><p> [pos is Facial Sythesizer] methods to generate realistic faces [12]. Some methods avoid the use of CG by selecting frames from a personspecific database and combining them to form a video [#b2][]. Regardless of which approach is used these methods are subject dependent and are often associated with a considerable o. [pos is Facial Sythesizer] ecover the most likely mouth shapes for a speech signal. A similar approach is used in [26] to estimate the sequence of lip parameters. Finally, the Video Rewrite [#b2][3] method relies on the same principals to obtain a sequence of triphones that are used to look up mouth images from a database.Although HMMs were initially </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> a no-reference perceptual image sharpness metric based on a cumulative probability of blur detection </p><p> [pos is Facial Sythesizer] take into account the fact that reconstruction metrics penalize videos for any spontaneous expression. The frame sharpness is evaluated using the cumulative probability blur detection (CPBD) measure [#b16][17], which determines blur based on the presence of edges in the image and the frequency domain blurriness measure (FDBM) proposed in ref type"bibr" target"b7 </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> quantitative association of vocal-tract and facial behavior </p><p> [pos is Facial Sythesizer] btle abnormalities in facial motion and audiovisual synchronization.Of particular interest is speechdriven facial animation since speech acoustics are highly correlated with facial movements [#b26][27]. These systems could simplify the film animation process through automatic generation from the voice acting. They can also be applied in movie dubbing to achi. [pos is Facial Sythesizer] ns1.0"SpeechDriven Facial AnimationThe problem of speechdriven video synthesis is not new in computer vision and has been the subject of interest for decades. Yehia et al. [#b26][27] first examined the relationship between acoustics, vocaltract and facial motion, showing a strong correlation between visual and audio features and a weak co </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> an audio-visual corpus for speech perception and automatic speech recognition </p><p> [pos is Facial Sythesizer] e accuracy of the spoken words and face verification to ensure that the identity of the speaker is maintained throughout the sequence. Evaluation is performed in a subject independent way on the GRID [#b5][6] and TCD TIMIT [11] datasets, where our model achieves truly natural results. Finally, the realism of the videos is assessed </p>
<p> end-to-end speech-driven facial animation with temporal gans </p><p> you said that? </p><p> [pos is Facial Sythesizer] ependent and are often associated with a considerable overhead when transferring to new speakers.Subject independent approaches have been proposed that transform audio features to video frames [#b4][5] but there is still no method to directly transform raw audio to video. Furthermore, many methods restrict the problem to generating only the mouth. Even techniq. [pos is Facial Sythesizer] primarily focused on obtaining realistic lip movements, and typically neglect the importance of generating natural facial expressions. Some methods generate frames based solely on present information [#b4][5], without taking into account the facial dynamics. This makes generating natural sequences, which are characterized by a seamless transition between frames, chal. [pos is Facial Sythesizer] to 3D meshes of a specific person. This system is conceptually broken into subnetworks responsible for capturing articulation dynamics and estimating the 3D points of the mesh. Finally, Chung et al. [#b4][5] proposed a CNN applied on Melfrequency cepstral coefficients (MFCCs) that generates subject independent videos from an audio clip and a still frame. The method. [pos is Facial Sythesizer] fig_9"7.  Coarticulation is evident in (a) where "bin" is followed by the word "blue".   The works that are closest to ours are those proposed in [22] and [#b4][5]. The former method is subject dependent and requires a large amount of data for a specific person to generate videos. For the latter method there is no publicly. [pos is Facial Sythesizer] os. For the latter method there is no publicly available implementation so we compare our model to a static method that produces video frames using a sliding window of audio samples like that used in [#b4][5]. This is a GANbased method that uses a combination of an L 1 loss and an adversarial loss on individual frames. We will also use this method as the baseline fo. [pos is Facial Sythesizer] erence in the WER. We believe that these improvements are not only a result of using a temporal generator but also due to the use of the conditional Sequence Discriminator. Unlike previous approaches [#b4][5] that prohibit the generation of facial expressions, the adversarial loss on the entire sequence encourages spontaneous facial gestures. This has been demonstrat </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> combining trace sampling with single pass methods for efficient cache simulation </p><p> y assumption 4 and get? ? ? ? ? ? ??? ? ? ? ? ? ? ? ? ? ??. Furthermore, the left side of expression 3 becomes equal to AE ? ?. Thus AE ? ? AE ?? ? ? ? ?? [#b4](5) Consider the sum in this expression. The number of terms with ? ? equal to some constant ?, is equal to the number of memory references with reuse distance ?. T. on simulation. The common methods of sampling are time sampling [22][11] [5] [8] and set sampling [11]  [#b4][5].Hardware monitoring tools collect statistics from hardware and present the information in aggregated form to the user. Examples are DCPI ref type"bibr" </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> tools for application-oriented performance tuning </p><p> between 5 and 50 times is common. They can simulate caches to the desired detail, but cannot capture operating system interaction. Source instrumentation have also been explored, for example in MHSIM [#b9][10].Trace sampling is used to speed up cache hierarchy simulation. It can be applied to all levels of detail of computer and application simulation. The com </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> eel: machineindependent executable editing </p><p> uffer from large slowdown. Many tools have been built using binary code instrumentation tools like DIOTA [16], ATOM [7] or EEL [#b12][13]. Examples are SIGMA [6], CPROF [14] and MemSpy [18]r </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> simics/sun4m: a virtual workstation </p><p> Experimental EvaluationWe have evaluated StatCache by comparing it to a functional cache simulator. The evaluation is based on tracedriven simulation, using traces generated by the Simics [#b16][17] full system simulator. It simulates a Sun UltraSPARC II workstationlike computer. We simulate both StatCache and the fullyassociative caches we compare with. imulation or code instrumentation, source code instrumentation, trap driven cache simulation and measurements on hardware using hardware profiling support.Full system simulators include Simics [#b16][17] and SimOS [15]. They allow very detailed cache simulations, but suffer from large slowdown. Many tools have been built us </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> evaluation techniques for storage hierarchies </p><p> cate the reuse distance. Note that this differs from the stack distance in that it counts all intermediate references, not just different ones. For example the stack distance of reference 6 is only 2 [#b19][20] .   Reuse Distance HistogramThe distribution of reuse distances can be viewed as a </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> tuning memory performance of sequential and parallel programs </p><p> type"bibr" target"b12"[13]. Examples are SIGMA [6], CPROF [14] and MemSpy [18] [#b18][19]. These tools are much faster than simulators, but their slowdowns are still considerable, between 5 and 50 times is common. They can simulate caches to the de </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> a model for estimating trace-sample miss ratios </p><p>  </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> cache profiling and the spec benchmarks: a case study </p><p> type"bibr" target"b15"[16], ATOM [7] or EEL [13]. Examples are SIGMA [6], CPROF [#b13][14] and MemSpy [18] [19]. These tools are much faster than simulators, but their slowdow </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> adapting the spec 2000 benchmark suite for simulation-based computer architecture research </p><p> luated, and exclude possible deficiencies in an implementation. To cut simulation time, we used the twenty benchmarks from the SPEC CPU2000 suite that are available with large reduced input data sets [#b11][12]. The length of the reduced traces are between ? ? ?? and ?? ? ?? references.The StatCache simulator sequentially reads the trace and increments a commo </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> cache miss equations: a compiler framework for analyzing and tuning memory behavior </p><p> d up cache hierarchy simulation. It can be applied to all levels of detail of computer and application simulation. The common methods of sampling are time sampling [22][11] [5] [#b7][8] and set sampling [11]  [5].Hardware monitoring tools collect statistics from har </p>
<p> statcache: a probabilistic approach to efficient and accurate data locality analysis </p><p> cache miss equations: a compiler framework for analyzing and tuning memory behavior </p><p> d up cache hierarchy simulation. It can be applied to all levels of detail of computer and application simulation. The common methods of sampling are time sampling [22][11] [5] [#b7][8] and set sampling [11]  [5].Hardware monitoring tools collect statistics from har </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> bypass and insertion algorithms for exclusive last-level caches </p><p> shared memory applications. For exclusive LLCs, the best CHAR proposal achieves an average throughput improvement of 3.2 compared to the twobit TCAGE baseline (analogue of SRRIP for exclusive LLC) [#b5][5] while saving 66.6 data write transactions from the L2 cache to the ondie interconnect for the multiprogrammed workloads. div xmlns"httpwww.tei. rns in the L2 cache eviction stream. L2 cache eviction patterns have been used to arrive at bypass decisions and assign insertion ages to the nonbypassed blocks in the context of exclusive L3 caches [#b5][5]. LLC insertion and replacement policies based on static and dynamic rereference interval prediction (SRRIP and DRRIP) have been explored ref type"bibr" targe. tion of the L2 cache blocks is inspired by the classification based on trip count and use count of cache blocks presented in an earlier study in the context of a cache hierarchy with an exclusive LLC [#b5][5]. According to the terminology used in that study, the set C0 ? C1 ? C2 ? C3 contains the zero trip count blocks i.e., the blocks that are filled in the L2 cache. pe"table"2 shows how our five classes of cache blocks can be encoded in the L2 cache with just two extra state bits (S1, S0) per L2 cache block (as opposed to three bits per L2 cache block in [#b5][5]). Figure 4, through the class transitions, unambiguously defines the state transitions of these two bits on hits and wr. discuss the working of the CHAR algorithm in an exclusive LLC. Our baseline exclusive LLC allocates all L2 cache evictions and decides the insertion age of a block based on the twobit TCAGE policy [#b5][5]. This policy is the analogue of SRRIP for exclusive LLCs. It inserts all C0, C1, C2, and C3 blocks at age two and the C4 blocks at age zero. Note that a block i. www.teic.orgns1.0" place"foot" n"6" xmlid"foot_4"We use the term "age" instead of "RRPV" in this discussion to conform to the terminology used in the prior work on exclusive LLC management[#b5][5]. Age can be considered synonymous to RRPV in this discussion.     ACKNOWLEDGMENTS </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> achieving non-inclusive cache performance with inclusive caches </p><p>  </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> automatically large scale program behavior </p><p> ns drawn from SPEC 2000 and SPEC 2006 suites. The L2 cache access trace of each application is collected for a representative set of one billion dynamic instructions chosen using the SimPoint toolset [#b22][22]. The cache hierarchy consists of 32 KB 8way L1 instruction and data caches, a 256 KB 8way L2 cache, and a 2 MB 16way inclusive LLC. The L1 and L2 caches im. per kilo instructions (MPKI) for the baseline SRRIP policy, as shown in Table 6. We simulate one billion dynamic instructions chosen using the SimPoint toolset [#b22][22] from each application executed on the ref input set.The singlethreaded applications are mixed to prepare one hundred 4way heterogeneous multiprogram </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> decoupled dynamic cache segmentation </p><p> ions with liveness of cache blocks. A recent work constructs a PCless deadonfill predictor for use in cache bypassing by dynamically segmenting the LLC between referenced and not referenced blocks [#b11][11]. PCless lightweight dead block predictors exploiting the fill order of LLC blocks have also been proposed [2]. Our basic </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> achieving non-inclusive cache performance with inclusive caches </p><p>  </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> adaptive insertion policies for high performance caching </p><p> n the LLC and enjoy additional reuses.The fact that 60 of the L2 cache evictions are dead corresponds well with the already known fact that the blocks brought into the LLC have low use counts [#b21][21]. For the data in Figure 2, the average use count per LLC block is about 1.67 (reciprocal of dead percentage). In summ </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> dead block replacement and bypass with a sampling predictor </p><p> sal shares some similarities with the dead block predictors. The existing dead block predictors predict the last access or the last burst of accesses to a block [[#b12]]. Singlethreaded ApplicationsFigure 7 compares the performance of CHAR, DRRIP [8], CHARPC, SDBP [#b12][12], and SHiPPC [24]. The last three policies require the program counter of the loadstore instructions. SDBP is the state. shared memory applications, we execute each application completely and compare the policies in terms of the execution time of the parallel computation.   [8], SDBP [#b12][12], SHiPPC [24], ECI [7], and QBS [7]. These data represent the average acros. d"fig_11"Figure 99Figure9summarizes the normalized average throughput and LLC miss counts delivered by CHAR, TADRRIP[8], SDBP[#b12][12], SHiPPC[24], ECI[7], and QBS[7]. These data represent the average across one hundred heterogeneous mixes with the hardwa </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> dead block replacement and bypass with a sampling predictor </p><p> sal shares some similarities with the dead block predictors. The existing dead block predictors predict the last access or the last burst of accesses to a block [[#b12]]. Singlethreaded ApplicationsFigure 7 compares the performance of CHAR, DRRIP [8], CHARPC, SDBP [#b12][12], and SHiPPC [24]. The last three policies require the program counter of the loadstore instructions. SDBP is the state. shared memory applications, we execute each application completely and compare the policies in terms of the execution time of the parallel computation.   [8], SDBP [#b12][12], SHiPPC [24], ECI [7], and QBS [7]. These data represent the average acros. d"fig_11"Figure 99Figure9summarizes the normalized average throughput and LLC miss counts delivered by CHAR, TADRRIP[8], SDBP[#b12][12], SHiPPC[24], ECI[7], and QBS[7]. These data represent the average across one hundred heterogeneous mixes with the hardwa </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> deconstructing the inefficacy of global cache replacement policies </p><p> antage of such global schemes is limited to specific scenarios. A subsequent study further analyzes the limited utility of access hintbased global replacement schemes using a reuse distance argument [#b4][4].A recent work shows that innerlevel access hints can improve performance of an inclusive LLC significantly for a selected set of multiprogrammed worklo </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> evaluation techniques for storage hierarchies </p><p> of this oracleassisted policy normalized to the baseline SRRIP. The bar on the right in each group shows the number of LLC misses in Belady's optimal algorithm [[#b20]] normalized to the baseline. These experiments are carried out on an offline cache hierarchy simulator that takes as input the entire L2 cache access trace of t </p>
<p> introducing hierarchy-awareness in replacement and bypass algorithms for last-level caches </p><p> cache replacement policy revisited </p><p> d global) replacement policies for inclusive LLCs. The first such study explored a number of global replacement policies where different types of access hints from the innerlevel are sent to the LLC [#b26][26]. It showed that the advantage of such global schemes is limited to specific scenarios. A subsequent study further analyzes the limited utility of access hint </p>
<p> get to the point: summarization with pointer-generator networks </p><p> modeling coverage for neural machine translation </p><p> Miao and Blunsom's (2016) ForcedAttention Sentence Compression, that were applied to shorttext summarization. We propose a novel variant of the coverage vector [#b25](Tu et al., 2016) from Neural Machine Translation, which we use to track and control coverage of the source document. We show that coverage is remarkably effective. in equation ( 9). Coverage mechanismRepetition is a common problem for sequencetosequence models [#b25](Tu et al., 2016Mi et al., 2016Sankaran et al., 2016Suzuki and Nagata. Suzuki and Nagata, 2016), and is especially pronounced when generating multisentence text (see Figure 1). We adapt the coverage model of [#b25]Tu et al. (2016) to solve the problem. In our coverage model, we maintain a coverage vector c t , which is the sum of attention distributions over all previous dec. m to work together to perform abstractive copying.Coverage. Originating from Statistical Machine Translation (Koehn, 2009), coverage was adapted for NMT by [#b25]Tu et al. (2016) and Mi et al. (2016), who both use a GRU to update the coverage vector each step. We find that a simpler appr </p>
<p> get to the point: summarization with pointer-generator networks </p><p> abstractive text summarization using sequence-to-sequence rnns and beyond </p><p> "et al., 2014), in which recurrent neural networks (RNNs) both read and freely generate text, has made abstractive summarization viable (Chopra et al., 2016[#b17]Nallapati et al., 2016Rush et al., 2015Zeng et al., 2016). Though these systems are pro. action while avoiding repetition) and ultimately more useful. Therefore we apply our model to the recentlyintroduced CNN Daily Mail dataset (Hermann et al., 2015[#b17]Nallapati et al., 2016), which contains news articles (39 sentences on average) paired with multisentence summaries, and show that we outperform the stateofthea. ne.1  Sequencetosequence attentional modelOur baseline model is similar to that of [#b17]Nallapati et al. (2016), and is depicted in Figure 2. The tokens of the article w i are fed onebyone into the encoder (a. d with recurrent decoders (Chopra et al., 2016), Abstract Meaning Representations (Takase et al., 2016), hierarchical networks [#b17](Nallapati et al., 2016), variational autoencoders (Miao and Blunsom, 2016), and direct optimization of the performance metric. nce metric (Ranzato et al., 2016), further improving performance on those datasets.However, largescale datasets for summarization of longer text are rare. [#b17]Nallapati et al. (2016) adapted the DeepMind questionanswering dataset (Hermann et al., 2015) for summarization, resulting in. 16), and summarization (Gu et al., 2016Gulcehre et al., 2016Miao and Blunsom, 2016[#b17]Nallapati et al., 2016Zeng et al., 2016).Our approach is close to the ForcedAttention Sentence Compression model of . opies a word while attending to multiple occurrences of it in the source text.Our approach is considerably different from that of Gulcehre et al. (2016) and [#b17]Nallapati et al. (2016). Those works train their pointer components to activate only for outofvocabulary words or named entities (whereas we allow our model to f. mula"11) into neural summarization of longer text.Temporal attention is a related technique that has been applied to NMT (Sankaran et al., 2016) and summarization [#b17](Nallapati et al., 2016). In this approach, each attention distribution is divided by the sum of the previous, which effectively dampens repeated attention. We tri. is supported by the large boost that coverage gives our ROUGE scores (see Table 1), compared to the smaller boost given by temporal attention for the same task [#b17](Nallapati et al., 2016). DatasetWe use the CNNDaily Mail dataset ref type"bibr" target. lapati et al., 2016). DatasetWe use the CNNDaily Mail dataset (Hermann et al., 2015[#b17]Nallapati et al., 2016), which contains online news articles (781 tokens on average) paired with multisentence summaries (3.75 sentences or 56 tokens on average).. "Nallapati et al., 2016), which contains online news articles (781 tokens on average) paired with multisentence summaries (3.75 sentences or 56 tokens on average). We used scripts supplied by [#b17]Nallapati et al. (2016) to obtain the same version of the the data, which has 287,226 training pairs, 13,368 validation pairs and 11,490 test pairs. Both the datas. "b17"Nallapati et al. (2016) to obtain the same version of the the data, which has 287,226 training pairs, 13,368 validation pairs and 11,490 test pairs. Both the dataset's published results [#b17](Nallapati et al., 2016(Nallapati et al., , 2017) ) use the anonymized version of the data, which has been preprocessed to re. odel has 21,499,600 parameters, the pointergenerator adds 1153 extra parameters (w h  , w s , w x and b ptr in equation 8), and coverage adds 512 extra parameters (w c in equation 11).Unlike [#b17]Nallapati et al. (2016), we do not pretrain the word embeddings they are learned from scratch during training. We train using Adagrad ref type"bibr" target"b5. get"foot_4"5In addition to our own models, we also report the lead3 baseline (which uses the first three sentences of the article as a summary), and compare to the only existing abstractive [#b17](Nallapati et al., 2016) and extractive (Nallapati et al., 2017) models on the full dataset. The output of our models is avail. b16"(Nallapati et al., 2017) models on the full dataset. The output of our models is available online. 6Given that we generate plaintext summaries but [#b17]Nallapati et al. (20162017) generate anonymized summaries (see Section 4), our ROUGE scores are not strictly comparable. Ther. omparison with Nallapati et al.'s work. Nevertheless, given that the disparity in the lead3 scores is (1.1 ROUGE1, 2.0 ROUGE2, 1.1 ROUGEL) points respectively, and our best model scores exceed [#b17]Nallapati et al. (2016) by (4.07 ROUGE1, 3.98 ROUGE2, 3.73 ROUGEL) points, we may estimate that we outperform the only previous abstractive system by at leas. to death an unarmed black man has exposed discrepancies in the reports of the first officers on the scene. (...) Summary more questions than answers emerge in controversial s.c. police shooting. of [#b17]Nallapati et al. (2016) by several ROUGE points. Despite the brevity of the coverage training phase (about 1 of the total training time), the repetition problem i </p>
<p> get to the point: summarization with pointer-generator networks </p><p> pointer networks </p><p> , and show that we outperform the stateoftheart abstractive system by at least 2 ROUGE points.Our hybrid pointergenerator network facilitates copying words from the source text via pointing [#b26](Vinyals et al., 2015), which improves accuracy and handling of OOV words, while retaining the ability to generate new words. The network, which can be viewed as a. ss t (7) Pointergenerator networkOur pointergenerator network is a hybrid between our baseline and a pointer network [#b26](Vinyals et al., 2015), as it allows both copying words via pointing, and generating words from a fixed vocabulary.In the pointergenerator model (depicted.  explored cutting unimportant parts of sentences to create summaries, and Cheung and Penn (2014) explore sentence fusion using dependency trees.Pointergenerator networks. The pointer network [#b26](Vinyals et al., 2015) is a sequencetosequence model that uses the soft attention distribution of Bahdanau et al. (2015) to pr </p>
<p> get to the point: summarization with pointer-generator networks </p><p> pointing the unknown words </p><p> pe"bibr" target"b0"Bahdanau et al. (2015) to produce an output sequence consisting of elements from the input sequence. The pointer network has been used to create hybrid approaches for NMT [#b7](Gulcehre et al., 2016), language modeling (Merity et al., 2016), and summarization (Gu et al., 2. "bibr" target"b7"(Gulcehre et al., 2016), language modeling (Merity et al., 2016), and summarization (Gu et al., 2016[#b7]Gulcehre et al., 2016Miao and Blunsom, 2016Nallapati et al., 2016ref type"bibr" targe. ffices, and (iii) we observe that the pointer mechanism often copies a word while attending to multiple occurrences of it in the source text.Our approach is considerably different from that of [#b7]Gulcehre et al. (2016) and Nallapati et al. (2016). Those works train their pointer components to activate only for outofvoca </p>
<p> get to the point: summarization with pointer-generator networks </p><p> adaptive subgradient methods for online learning and stochastic optimization </p><p> equation 11).Unlike Nallapati et al. (2016), we do not pretrain the word embeddings they are learned from scratch during training. We train using Adagrad [#b5](Duchi et al., 2011) with learning rate 0.15 and an initial accumulator value of 0.1. (This was found to work best of Stochastic Gradient Descent, Adadelta, Momentu </p>
<p> get to the point: summarization with pointer-generator networks </p><p> sequence to sequence learning with neural networks </p><p>  </p>
<p> get to the point: summarization with pointer-generator networks </p><p> coverage embedding models for neural machine translation </p><p> Coverage mechanismRepetition is a common problem for sequencetosequence models (Tu et al., 2016[#b14]Mi et al., 2016Sankaran et al., 2016Suzuki and Nagata, 2016), and is especially pronounced when gener. overage. Originating from Statistical Machine Translation (Koehn, 2009), coverage was adapted for NMT by Tu et al. (2016) and [#b14]Mi et al. (2016), who both use a GRU to update the coverage vector each step. We find that a simpler approach summing the attention distributions to obtain the co </p>
<p> get to the point: summarization with pointer-generator networks </p><p> teaching machines to read and comprehend </p><p> is both more challenging (requiring higher levels of abstraction while avoiding repetition) and ultimately more useful. Therefore we apply our model to the recentlyintroduced CNN Daily Mail dataset [#b8](Hermann et al., 2015Nallapati et al., 2016), which contains news articles (39 sentences on average) paired with multisentenc. e datasets.However, largescale datasets for summarization of longer text are rare. Nallapati et al. (2016) adapted the DeepMind questionanswering dataset [#b8](Hermann et al., 2015) for summarization, resulting in the CNNDaily Mail dataset, and provided the first abstractive baselines. The same authors then published a n. tion for the same task (Nallapati et al., 2016). DatasetWe use the CNNDaily Mail dataset [#b8](Hermann et al., 2015Nallapati et al., 2016), which contains online news articles (781 tokens on average) paired with multise </p>
<p> get to the point: summarization with pointer-generator networks </p><p> adaptive subgradient methods for online learning and stochastic optimization </p><p> equation 11).Unlike Nallapati et al. (2016), we do not pretrain the word embeddings they are learned from scratch during training. We train using Adagrad [#b5](Duchi et al., 2011) with learning rate 0.15 and an initial accumulator value of 0.1. (This was found to work best of Stochastic Gradient Descent, Adadelta, Momentu </p>
<p> get to the point: summarization with pointer-generator networks </p><p> language as a latent variable: discrete generative models for sentence compression </p><p> ing the ability to generate new words. The network, which can be viewed as a balance between extractive and abstractive approaches, is similar to Gu et al.'s (2016) CopyNet and [#b15]Miao and Blunsom's (2016) ForcedAttention Sentence Compression, that were applied to shorttext summarization. We propose a novel variant of the coverage vector . tract Meaning Representations (Takase et al., 2016), hierarchical networks (Nallapati et al., 2016), variational autoencoders [#b15](Miao and Blunsom, 2016), and direct optimization of the performance metric (Ranzato et al., 2016), further improving performa. e modeling (Merity et al., 2016), and summarization (Gu et al., 2016Gulcehre et al., 2016[#b15]Miao and Blunsom, 2016Nallapati et al., 2016Zeng et al., 2016).Our approach is c. Nallapati et al., 2016Zeng et al., 2016).Our approach is close to the ForcedAttention Sentence Compression model of [#b15]Miao and Blunsom (2016) and the CopyNet model of Gu et al. (2016), with some small differences (i) We calculate an explicit sw </p>
<p> get to the point: summarization with pointer-generator networks </p><p> automatic text summarization: past, present and future </p><p> difficulty of abstractive summarization, the great majority of past work has been extractive (Kupiec et al., 1995Paice, 1990[#b21]Saggion and Poibeau, 2013). However, the recent success of sequencetosequence models (Sutskever   et al., 2014), in which recurrent neural </p>
<p> get to the point: summarization with pointer-generator networks </p><p> show, attend and tell: neural image caption generation with visual attention </p><p> a GRU to update the coverage vector each step. We find that a simpler approach summing the attention distributions to obtain the coverage vector suffices. In this respect our approach is similar to [#b27]Xu et al. (2015), who apply a coveragelike method to image captioning, and Chen et al. (2016), who also incorporate a coverag </p>
<p> get to the point: summarization with pointer-generator networks </p><p> language as a latent variable: discrete generative models for sentence compression </p><p> ing the ability to generate new words. The network, which can be viewed as a balance between extractive and abstractive approaches, is similar to Gu et al.'s (2016) CopyNet and [#b15]Miao and Blunsom's (2016) ForcedAttention Sentence Compression, that were applied to shorttext summarization. We propose a novel variant of the coverage vector . tract Meaning Representations (Takase et al., 2016), hierarchical networks (Nallapati et al., 2016), variational autoencoders [#b15](Miao and Blunsom, 2016), and direct optimization of the performance metric (Ranzato et al., 2016), further improving performa. e modeling (Merity et al., 2016), and summarization (Gu et al., 2016Gulcehre et al., 2016[#b15]Miao and Blunsom, 2016Nallapati et al., 2016Zeng et al., 2016).Our approach is c. Nallapati et al., 2016Zeng et al., 2016).Our approach is close to the ForcedAttention Sentence Compression model of [#b15]Miao and Blunsom (2016) and the CopyNet model of Gu et al. (2016), with some small differences (i) We calculate an explicit sw </p>
<p> get to the point: summarization with pointer-generator networks </p><p> language as a latent variable: discrete generative models for sentence compression </p><p> ing the ability to generate new words. The network, which can be viewed as a balance between extractive and abstractive approaches, is similar to Gu et al.'s (2016) CopyNet and [#b15]Miao and Blunsom's (2016) ForcedAttention Sentence Compression, that were applied to shorttext summarization. We propose a novel variant of the coverage vector . tract Meaning Representations (Takase et al., 2016), hierarchical networks (Nallapati et al., 2016), variational autoencoders [#b15](Miao and Blunsom, 2016), and direct optimization of the performance metric (Ranzato et al., 2016), further improving performa. e modeling (Merity et al., 2016), and summarization (Gu et al., 2016Gulcehre et al., 2016[#b15]Miao and Blunsom, 2016Nallapati et al., 2016Zeng et al., 2016).Our approach is c. Nallapati et al., 2016Zeng et al., 2016).Our approach is close to the ForcedAttention Sentence Compression model of [#b15]Miao and Blunsom (2016) and the CopyNet model of Gu et al. (2016), with some small differences (i) We calculate an explicit sw </p>
<p> get to the point: summarization with pointer-generator networks </p><p> automatic text summarization: past, present and future </p><p> difficulty of abstractive summarization, the great majority of past work has been extractive (Kupiec et al., 1995Paice, 1990[#b21]Saggion and Poibeau, 2013). However, the recent success of sequencetosequence models (Sutskever   et al., 2014), in which recurrent neural </p>
<p> get to the point: summarization with pointer-generator networks </p><p> teaching machines to read and comprehend </p><p> is both more challenging (requiring higher levels of abstraction while avoiding repetition) and ultimately more useful. Therefore we apply our model to the recentlyintroduced CNN Daily Mail dataset [#b8](Hermann et al., 2015Nallapati et al., 2016), which contains news articles (39 sentences on average) paired with multisentenc. e datasets.However, largescale datasets for summarization of longer text are rare. Nallapati et al. (2016) adapted the DeepMind questionanswering dataset [#b8](Hermann et al., 2015) for summarization, resulting in the CNNDaily Mail dataset, and provided the first abstractive baselines. The same authors then published a n. tion for the same task (Nallapati et al., 2016). DatasetWe use the CNNDaily Mail dataset [#b8](Hermann et al., 2015Nallapati et al., 2016), which contains online news articles (781 tokens on average) paired with multise </p>
<p> get to the point: summarization with pointer-generator networks </p><p> sentence reduction for automatic text summarization </p><p> our knowledge, these are the only two published results on the full dataset.Prior to modern neural methods, abstractive summarization received less attention than extractive summarization, but [#b9]Jing (2000) explored cutting unimportant parts of sentences to create summaries, and Cheung and Penn (2014) explore sentence fusion using dependency trees.Po </p>
<p> get to the point: summarization with pointer-generator networks </p><p> looking for a few good metrics: automatic summarization evaluation-how many samples are enough? in nacsis/nii test collection for information retrieval (ntcir) workshop. chin-yew lin </p><p> mlns"httpwww.teic.orgns1.0"PreliminariesOur results are given in Table 1. We evaluate our models with the standard ROUGE metric [#b12](Lin, 2004b), reporting the F 1 scores for ROUGE1, ROUGE2 and ROUGEL (which respectively measure the wordoverlap, bigramoverlap, and longest common sequence b. t to the reference summary. This inflexibility of ROUGE is exacerbated by only having one reference summary, which has been shown to lower ROUGE's reliability compared to multiple reference summaries [#b12](Lin, 2004a).Due to the subjectivity of the task and thus the diversity of valid summaries, it seems that ROUGE rewards safe strategies such as selecting th </p>
<p> get to the point: summarization with pointer-generator networks </p><p> sequence level training with recurrent neural networks </p><p> ref type"bibr" target"b17"(Nallapati et al., 2016), variational autoencoders (Miao and Blunsom, 2016), and direct optimization of the performance metric [#b19](Ranzato et al., 2016), further improving performance on those datasets.However, largescale datasets for summarization of longer text are rare. ref type" </p>
<p> get to the point: summarization with pointer-generator networks </p><p> sequence level training with recurrent neural networks </p><p> ref type"bibr" target"b17"(Nallapati et al., 2016), variational autoencoders (Miao and Blunsom, 2016), and direct optimization of the performance metric [#b19](Ranzato et al., 2016), further improving performance on those datasets.However, largescale datasets for summarization of longer text are rare. ref type" </p>
<p> get to the point: summarization with pointer-generator networks </p><p> pointing the unknown words </p><p> pe"bibr" target"b0"Bahdanau et al. (2015) to produce an output sequence consisting of elements from the input sequence. The pointer network has been used to create hybrid approaches for NMT [#b7](Gulcehre et al., 2016), language modeling (Merity et al., 2016), and summarization (Gu et al., 2. "bibr" target"b7"(Gulcehre et al., 2016), language modeling (Merity et al., 2016), and summarization (Gu et al., 2016[#b7]Gulcehre et al., 2016Miao and Blunsom, 2016Nallapati et al., 2016ref type"bibr" targe. ffices, and (iii) we observe that the pointer mechanism often copies a word while attending to multiple occurrences of it in the source text.Our approach is considerably different from that of [#b7]Gulcehre et al. (2016) and Nallapati et al. (2016). Those works train their pointer components to activate only for outofvoca </p>
<p> get to the point: summarization with pointer-generator networks </p><p> meteor universal: language specific translation evaluation for any target language </p><p> between the reference summary and the summary to be evaluated). We obtain our ROUGE scores using the pyrouge package. 4 We also evaluate with the METEOR metric [#b4](Denkowski and Lavie, 2014), both in exact match mode (rewarding only exact matches between words) and full mode (which additionally rewards matching stems, synonym </p>
<p> get to the point: summarization with pointer-generator networks </p><p> sentence reduction for automatic text summarization </p><p> our knowledge, these are the only two published results on the full dataset.Prior to modern neural methods, abstractive summarization received less attention than extractive summarization, but [#b9]Jing (2000) explored cutting unimportant parts of sentences to create summaries, and Cheung and Penn (2014) explore sentence fusion using dependency trees.Po </p>
<p> get to the point: summarization with pointer-generator networks </p><p> show, attend and tell: neural image caption generation with visual attention </p><p> a GRU to update the coverage vector each step. We find that a simpler approach summing the attention distributions to obtain the coverage vector suffices. In this respect our approach is similar to [#b27]Xu et al. (2015), who apply a coveragelike method to image captioning, and Chen et al. (2016), who also incorporate a coverag </p>
<p> get to the point: summarization with pointer-generator networks </p><p> unsupervised sentence enhancement for automatic summarization </p><p>  </p>
<p> get to the point: summarization with pointer-generator networks </p><p> automatic text summarization: past, present and future </p><p> difficulty of abstractive summarization, the great majority of past work has been extractive (Kupiec et al., 1995Paice, 1990[#b21]Saggion and Poibeau, 2013). However, the recent success of sequencetosequence models (Sutskever   et al., 2014), in which recurrent neural </p>
<p> get to the point: summarization with pointer-generator networks </p><p> pointer sentinel mixture models </p><p> ce consisting of elements from the input sequence. The pointer network has been used to create hybrid approaches for NMT (Gulcehre et al., 2016), language modeling [#b13](Merity et al., 2016), and summarization (Gu et al., 2016Gulcehre et al., 2016ref type" </p>
<p> get to the point: summarization with pointer-generator networks </p><p> sequence to sequence learning with neural networks </p><p>  </p>
<p> get to the point: summarization with pointer-generator networks </p><p> a trainable document summarizer </p><p> only in an abstractive framework (see Figure 5).Due to the difficulty of abstractive summarization, the great majority of past work has been extractive [#b11](Kupiec et al., 1995Paice, 1990Saggion and Poibeau, 2013). However, the recent success </p>
<p> get to the point: summarization with pointer-generator networks </p><p> unsupervised sentence enhancement for automatic summarization </p><p>  </p>
<p> get to the point: summarization with pointer-generator networks </p><p> coverage embedding models for neural machine translation </p><p> Coverage mechanismRepetition is a common problem for sequencetosequence models (Tu et al., 2016[#b14]Mi et al., 2016Sankaran et al., 2016Suzuki and Nagata, 2016), and is especially pronounced when gener. overage. Originating from Statistical Machine Translation (Koehn, 2009), coverage was adapted for NMT by Tu et al. (2016) and [#b14]Mi et al. (2016), who both use a GRU to update the coverage vector each step. We find that a simpler approach summing the attention distributions to obtain the co </p>
<p> get to the point: summarization with pointer-generator networks </p><p> neural machine translation by jointly learning to align and translate </p><p> ining, this is the previous word of the reference summary at test time it is the previous word emitted by the decoder), and has decoder state s t . The attention distribution a t is calculated as in [#b0]Bahdanau et al. (2015)e t i  v T tanh(W h h i W s s t  b attn )(1)a t  sof. cy trees.Pointergenerator networks. The pointer network (Vinyals et al., 2015) is a sequencetosequence model that uses the soft attention distribution of [#b0]Bahdanau et al. (2015) to produce an output sequence consisting of elements from the input sequence. The pointer network has been used to create hybrid approaches f </p>
<p> get to the point: summarization with pointer-generator networks </p><p> looking for a few good metrics: automatic summarization evaluation-how many samples are enough? in nacsis/nii test collection for information retrieval (ntcir) workshop. chin-yew lin </p><p> mlns"httpwww.teic.orgns1.0"PreliminariesOur results are given in Table 1. We evaluate our models with the standard ROUGE metric [#b12](Lin, 2004b), reporting the F 1 scores for ROUGE1, ROUGE2 and ROUGEL (which respectively measure the wordoverlap, bigramoverlap, and longest common sequence b. t to the reference summary. This inflexibility of ROUGE is exacerbated by only having one reference summary, which has been shown to lower ROUGE's reliability compared to multiple reference summaries [#b12](Lin, 2004a).Due to the subjectivity of the task and thus the diversity of valid summaries, it seems that ROUGE rewards safe strategies such as selecting th </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> map-matching for lowsampling-rate gps trajectories </p><p> grate trajectories and can achieve good performance. In recent years, there are some researchers pay close attention to map matching techniques on lowsamplingrate trajectories. STMatching algorithm [#b3][4] is the first one solving the problem about lowsamplingrate map matching. IVMM [5] improved STMatching algorithm by adding. quence and the hidden state is the road segments to be matched. Besides, some methods rely on the outer information, such as the data from mobile devices [13]. In [#b3][4], the author combines the spatial structures of the road network and the temporalspeed constraints of the trajectories. It improves the accuracy of map matching </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> large-scale joint map matching of gps traces </p><p> des. Geometric algorithms pay close attention to the shape of individual links in a road network or the patterns connected by whole or part of trajectories. E.g., matching a point to the nearest road [#b7][8]. Topological map matching methods concentrate on the connectivity of a road network. There are two kinds of representative algorithms one uses the Fr?chet dist </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> an interactive-voting based map matching algorithm </p><p> map matching techniques on lowsamplingrate trajectories. STMatching algorithm [4] is the first one solving the problem about lowsamplingrate map matching. IVMM [#b4][5] improved STMatching algorithm by adding weighted influence model and interactive voting. HRIS [6] and featurebasedmapmat. structures of the road network and the temporalspeed constraints of the trajectories. It improves the accuracy of map matching for trajectories with time interval no less than 2 minutes. Then, paper [#b4][5] improves STMatching algorithm by considering the weight of different points. After that, more algorithms [14], ref type" </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> adaptive fastest path computation on a road network: a traffic mining approach </p><p> opment of wireless communication techniques and GPSenabled devices, a large amount of trajectory data are generated by moving objects and the data are applied to several services, such as route plan [#b0][1], hot route discover [2] and even social relationship infer [3]. However, due to the limi </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> discovering similar multidimensional trajectories </p><p> total number points in the trajectory T .Secondly, we discuss the temporal dimension measure factor S(P i ). Usually, when object moves, it tend to be close to the max speed limit of the road [#b17][18]. Therefore, we calculate the deviation between the average moving speed and the limit speed. Considering the waiting time spent at the road intersections, we. correct path, denoted as P true . Then, for each lowsamplingrate trajectory, we get the map matching path using STMatching and MSTM respectively, denoted as P st and P mstm . We calculate the LCSS [#b17][18] similarity of LCSS st (P true , P st ) and LCSS mstm (P true , P mstm ) as the accuracy. Secondly, we use the algorithm IVMM to generate the p true and calcul </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> semmatch: road semantics-based accurate map matching for challenging positioning data </p><p> in which the observation state is the point sequence and the hidden state is the road segments to be matched. Besides, some methods rely on the outer information, such as the data from mobile devices [#b12][13]. In [4], the author combines the spatial structures of the road network and the temporalspeed constraints of the trajecto </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> a general featurebased map matching framework with trajectory simplification </p><p> ype"bibr" target"b4"[5] improved STMatching algorithm by adding weighted influence model and interactive voting. HRIS [6] and featurebasedmapmatching [#b6][7] concerned on the history features and action features of trajectories respectively. However, most algorithms tend to choose the shortest paths as the candidate. ] try to solve the problem of lowsamplingrate trajectories matching by incorporating different factors. History information is referred to in [6] and paper [#b6][7] takes human factors into consideration to estimate the missing movement details. C. Novelty and Contrib </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> geolife: managing and understanding your past life over maps </p><p> and the data are applied to several services, such as route plan [1], hot route discover [2] and even social relationship infer [#b2][3]. However, due to the limitations caused by the equipment accuracy and the environment, there are a certain number of inevitable errors among trajectories. What' </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> a general featurebased map matching framework with trajectory simplification </p><p> ype"bibr" target"b4"[5] improved STMatching algorithm by adding weighted influence model and interactive voting. HRIS [6] and featurebasedmapmatching [#b6][7] concerned on the history features and action features of trajectories respectively. However, most algorithms tend to choose the shortest paths as the candidate. ] try to solve the problem of lowsamplingrate trajectories matching by incorporating different factors. History information is referred to in [6] and paper [#b6][7] takes human factors into consideration to estimate the missing movement details. C. Novelty and Contrib </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> discovering similar multidimensional trajectories </p><p> total number points in the trajectory T .Secondly, we discuss the temporal dimension measure factor S(P i ). Usually, when object moves, it tend to be close to the max speed limit of the road [#b17][18]. Therefore, we calculate the deviation between the average moving speed and the limit speed. Considering the waiting time spent at the road intersections, we. correct path, denoted as P true . Then, for each lowsamplingrate trajectory, we get the map matching path using STMatching and MSTM respectively, denoted as P st and P mstm . We calculate the LCSS [#b17][18] similarity of LCSS st (P true , P st ) and LCSS mstm (P true , P mstm ) as the accuracy. Secondly, we use the algorithm IVMM to generate the p true and calcul </p>
<p> mstm: a novel map matching approach for low-sampling-rate trajectories </p><p> adaptive fastest path computation on a road network: a traffic mining approach </p><p> opment of wireless communication techniques and GPSenabled devices, a large amount of trajectory data are generated by moving objects and the data are applied to several services, such as route plan [#b0][1], hot route discover [2] and even social relationship infer [3]. However, due to the limi </p>
<p> fast transformer decoding: one write-head is all you need </p><p> attention is all you need </p><p> p      IntroductionThe Transformer neural sequence model [#b4][Vaswani et al. ] has emerged as a popular alternative to recurrent sequence models. Transformer relies on attention layers to communicate information between. ming across all dimensions not in the desired output shape. Multihead AttentionThe "Transformer" seuqencetosequence model [#b4][Vaswani et al. ] uses h different attention layers (heads) in parallel, which the authors refer to as "Multihead attention". The query vectors for the h diff. ( " hk , hmkgthm" , q , K) w e i g h t s  t f . so ftma x ( l o g i t s ) o  t f . einsum ( "hm, hmvgthv " , weig hts , V) y  t f . einsum ( " hv , hdvgtd " , o , P_o) r e t u r n y Note [#b4][Vaswani et al. ] include a constant scaling factor on the logits. We omit this in our code, as it can be folded into the linear projections P q or P k .. queries from n different positions in a sequence. These queries all interact with the same keys and values. In addition, we process a batch of b different noninteracting sequences at once. Following [#b4][Vaswani et al. ], in an autoregressive model, we can prevent backwardinformationflow by adding a "mask" to the logits containing the value ? in the illegal. ed Multihead AttentionTo simplify the performance analysis, we will make several simplifying assumptions? m  n ? k  v  dh , as suggested by [#b4][Vaswani et al. ] ? n ? dThe total number of arithmetic operations is ?(bnd 2 ). (Since the complexity of each of the tf.einsum operations above is O(bn. settings, data dependencies make it is impossible to process queries from multiple positions in parallel. An example is a selfattention layer in an autoregressive language model such as Transformer [#b4][Vaswani et al. ]. The queries produced at each position attend to keyvalue pairs produced at all positions up to and including that position. During training. in the queries. MultiQuery AttentionWe introduce multiquery Attention as a variation of multihead attention as described in [#b4][Vaswani et al. ]. Multihead attention consists of multiple attention layers (heads) in parallel with different linear transformations on the queries, keys, v. high. Experiments and Results Experimental SetupFollowing [#b4][Vaswani et al. ], we evaluate on the WMT 2014 EnglishGerman translation task. As a baseline, we use an encoderdecoder Transformer model with 6 layers, using </p>
<p> fast transformer decoding: one write-head is all you need </p><p> a time-restricted selfattention layer for asr </p><p> local neighborhood, or by otherwise compressing the number of memory positions, as in [Liu et al. ], [Zhang et al. ], [#b3][Povey et al. ]. In this paper we present an orthogonal approach to reducing the size of the K and V tensors namely removing their "heads" dimension, while ma </p>
<p> fast transformer decoding: one write-head is all you need </p><p> generating wikipedia by summarizing long sequences </p><p> t the sequence length n. Another is to reduce the number of positions being attendedto, either by attending to a local neighborhood, or by otherwise compressing the number of memory positions, as in [#b2][Liu et al. ], [Zhang et al. ], [Povey et al. ]. In this paper we present an </p>
<p> fast transformer decoding: one write-head is all you need </p><p> generating wikipedia by summarizing long sequences </p><p> t the sequence length n. Another is to reduce the number of positions being attendedto, either by attending to a local neighborhood, or by otherwise compressing the number of memory positions, as in [#b2][Liu et al. ], [Zhang et al. ], [Povey et al. ]. In this paper we present an </p>
<p> fast transformer decoding: one write-head is all you need </p><p> generating wikipedia by summarizing long sequences </p><p> t the sequence length n. Another is to reduce the number of positions being attendedto, either by attending to a local neighborhood, or by otherwise compressing the number of memory positions, as in [#b2][Liu et al. ], [Zhang et al. ], [Povey et al. ]. In this paper we present an </p>
<p> fast transformer decoding: one write-head is all you need </p><p> generating wikipedia by summarizing long sequences </p><p> t the sequence length n. Another is to reduce the number of positions being attendedto, either by attending to a local neighborhood, or by otherwise compressing the number of memory positions, as in [#b2][Liu et al. ], [Zhang et al. ], [Povey et al. ]. In this paper we present an </p>
<p> fast transformer decoding: one write-head is all you need </p><p> a time-restricted selfattention layer for asr </p><p> local neighborhood, or by otherwise compressing the number of memory positions, as in [Liu et al. ], [Zhang et al. ], [#b3][Povey et al. ]. In this paper we present an orthogonal approach to reducing the size of the K and V tensors namely removing their "heads" dimension, while ma </p>
<p> fast transformer decoding: one write-head is all you need </p><p> generating wikipedia by summarizing long sequences </p><p> t the sequence length n. Another is to reduce the number of positions being attendedto, either by attending to a local neighborhood, or by otherwise compressing the number of memory positions, as in [#b2][Liu et al. ], [Zhang et al. ], [Povey et al. ]. In this paper we present an </p>
<p> fast transformer decoding: one write-head is all you need </p><p> a time-restricted selfattention layer for asr </p><p> local neighborhood, or by otherwise compressing the number of memory positions, as in [Liu et al. ], [Zhang et al. ], [#b3][Povey et al. ]. In this paper we present an orthogonal approach to reducing the size of the K and V tensors namely removing their "heads" dimension, while ma </p>
<p> fast transformer decoding: one write-head is all you need </p><p> generating wikipedia by summarizing long sequences </p><p> t the sequence length n. Another is to reduce the number of positions being attendedto, either by attending to a local neighborhood, or by otherwise compressing the number of memory positions, as in [#b2][Liu et al. ], [Zhang et al. ], [Povey et al. ]. In this paper we present an </p>
<p> fast transformer decoding: one write-head is all you need </p><p> a time-restricted selfattention layer for asr </p><p> local neighborhood, or by otherwise compressing the number of memory positions, as in [Liu et al. ], [Zhang et al. ], [#b3][Povey et al. ]. In this paper we present an orthogonal approach to reducing the size of the K and V tensors namely removing their "heads" dimension, while ma </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> deep crossmodal audio-visual generation </p><p> ther modality is a fundamental problem in computer vision, where applications are ranging from audiotovideo generation [[#b1]] to texttovideo generation [] and to skeletontoimagevideo generation ref type </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> out of time: automated lip sync in the wild </p><p> annot be inferred from speech audio. Those complicated dynamics, if modeled in the pixel space [30], will result in lowquality videos. For example, in web videos [#b4][] (e.g., LRW and VoxCeleb datasets), speakers move significantly when they are talking. Nonetheless, all the recent photo. r significant head movements and noisy audio conditions. We evaluate our model along with stateoftheart methods on several popular datasets (e.g., GRID [6], LRW [#b4][5], VoxCeleb [24] and TCD [13]). Experimental results show that our model outperforms all. xtra VGGM network pretrained on VGG Face dataset [25] and Wilels et al. [35] need extra MFCC feature extractor pretrained by [#b4][5]. The quantitative results are illustrated in Table 2. The Baseline model is a straightforward model without any features. " target"b2"[3] and Zhou et al. [12]. The ground truth videos are selected from different sources we randomly select samples from the testing set of LRW [#b4][5], VoxCeleb [24], TCD [13], GRID [6] and realworld s </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> audio-driven facial animation by joint end-to-end learning of pose and emotion </p><p> o they are also sensitive to slight misalignment between facial movements and speech audio. However, recent researchers [[#b16]] tended to formulate video generation as a temporally independent image generation problem. For example, Chung et al. [3] pr </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> synthesizing obama: learning lip sync from audio </p><p> of traditional approaches has been mainly limited to synthesizing a talking face from speech audio of a specific person [[#b28]]. For example, Suwajanakorn et al. [#b28][29] synthesized a taking face of President Obama with accurate lip synchronization, giv. g face from speech audio of a specific person [[#b28]]. For example, Suwajanakorn et al. [#b28][29] synthesized a taking face of President Obama with accurate lip synchronization, given his speech audio. The mechanism is to first retrieve the bestmatched li </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> synthesizing obama: learning lip sync from audio </p><p> nModeling the dynamics of a moving human facebody conditioned on another modality is a fundamental problem in computer vision, where applications are ranging from audiotovideo generation [#b27][] to texttovideo generation [23,ref type"bi. realistic talking face generation methods [[#b27]] failed to consider this problem. In this paper, we propose a hierarchical structure that utilizes a highlevel facial l. o move. By adopting human body landmarks, Villegas et al. [31] proposed an encoderdecoder network which achieves longterm future prediction. Suwajanakorn et al. [#b27][28] transferred the audio signal to lip shapes and then synthesized the mouth texture based on the transferred lip shapes. These works have inspired us to use the </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> lip movements generation at a glance </p><p> ing. Nonetheless, all the recent photorealistic talking face generation methods [[#b0]] failed to consider this problem. In this paper, we propose a hierarchical structu. ynthesized facial movements of the humancartoon characters who are not in any dataset to demonstrate the robustness of our approach.The contributions of our work can be summarized as follows [#b0](1) We propose a novel cascade network structure to reduce the effects of the soundirrelevant visual dynamics in the image space. Our model explicitly constructs h. the target person. More recently, by combining the GANencoderdecoder structure and the datadriven training strategy, [[#b0]] can generate arbitrary faces from arbitrary input audio. HighLevel Representations In recent years, highlevel represent. better understanding. AttentionBased Dynamic Pixelwise LossRecent works on video generation adopt either GANbased methods [#b0][] or EncoderDecoderbased methods [3]. Howeve. DiscriminatorRecently, people find that perceptual loss [16] is helpful for generating sharp images in GANVAE [[#b0]]. Perceptual loss utilizes highlevel features to compare generated images and groundtruth images resulting in better sharpness of the synthesized images. The ke. et"b32"[33]. To evaluate whether the synthesized video contains accurate lip movements that correspond to the input audio, we adopt the evaluation matrix Landmarks Distance (LMD) proposed in [#b0][1]. We compare our model with other three stateoftheart methods [#b0][1,3,ref type"bibr" t. espond to the input audio, we adopt the evaluation matrix Landmarks Distance (LMD) proposed in [#b0][1]. We compare our model with other three stateoftheart methods [#b0][]. All of them are trained on LRW dataset while Chung et al. ref type"bibr" target </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> dlib-ml: a machine learning toolkit </p><p> oken by 33 different speakers in the experimental condition. For the image stream, all the talking faces in the videos are aligned based on keypoints (eyes and nose) of the extracted landmarks using [#b17][18] at the sampling rate of 25FPS, and then resize to 128  128. As for audio data, each audio segment corresponds to 280ms audio. We extract MFCC at the window s </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> voxceleb: a large-scale speaker identification dataset </p><p> ose complicated dynamics, if modeled in the pixel space [30], will result in lowquality videos. For example, in web videos [[#b23]] (e.g., LRW and VoxCeleb datasets), speakers move significantly when they are talking. Nonetheless, all the recent photorealistic talking face generation metho. tions. We evaluate our model along with stateoftheart methods on several popular datasets (e.g., GRID [6], LRW [5], VoxCeleb [#b23][24] and TCD [13]). Experimental results show that our model outperforms all compared methods and all the proposed features co. "bibr" target"b11"[12]. The ground truth videos are selected from different sources we randomly select samples from the testing set of LRW [5], VoxCeleb [#b23][24], TCD [13], GRID [6] and realworld samples from YouTube (in total 38 videos). Three me </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> voxceleb: a large-scale speaker identification dataset </p><p> ose complicated dynamics, if modeled in the pixel space [30], will result in lowquality videos. For example, in web videos [[#b23]] (e.g., LRW and VoxCeleb datasets), speakers move significantly when they are talking. Nonetheless, all the recent photorealistic talking face generation metho. tions. We evaluate our model along with stateoftheart methods on several popular datasets (e.g., GRID [6], LRW [5], VoxCeleb [#b23][24] and TCD [13]). Experimental results show that our model outperforms all compared methods and all the proposed features co. "bibr" target"b11"[12]. The ground truth videos are selected from different sources we randomly select samples from the testing set of LRW [5], VoxCeleb [#b23][24], TCD [13], GRID [6] and realworld samples from YouTube (in total 38 videos). Three me </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> talking face generation by adversarially disentangled audio-visual representation </p><p> inuities and subtle artifacts) in a video they are also sensitive to slight misalignment between facial movements and speech audio. However, recent researchers [[#b11]] tended to formulate video generation as a temporally independent image generation problem. For example, Chung et al. r. e.g., LRW and VoxCeleb datasets), speakers move significantly when they are talking. Nonetheless, all the recent photorealistic talking face generation methods [[#b11]] f. combining the GANencoderdecoder structure and the datadriven training strategy, [[#b11]] can generate arbitrary faces from arbitrary input audio. HighLevel Representations In recent years, highlevel representations of images ref type"bibr" targ.  shows generation time during inference stage. We can find that our inference time can achieve around 34.5 frames per second (FPS), which is much faster than [[#b11]] and slightly faster than real time (30 FPS). Resultsh. ref type"figure" target"fig_7"6) is conducted to investigate the visual qualities of our generated results compared with Chung et al. [3] and Zhou et al. [#b11][12]. The ground truth videos are selected from different sources we randomly select samples from the testing set of LRW [5],. ns1.0" xmlid"fig_9"Figure 7 Figure 8 78Figure 7 Qualitative results produced by ATVGnet, Chung et al.[3] and Zhou et al.[#b11][12] on samples from LRW and VoxCeleb dataset. We can observe from it that our mouth opening is closer to ground truth compared with the other two methods. It is w </p>
<p> hierarchical cross-modal talking face generation with dynamic pixel-wise loss </p><p> inferring semantic layout for hierarchical text-to-image synthesis </p><p> ghLevel Representations In recent years, highlevel representations of images [[#b14]] have been exploited in video generation tasks by using an encoderdecoder structure as the main approach. Given a condition, we can transfer it to highlevel re </p>
<p> How to bid the cloud </p><p> tube: time-dependent pricing for mobile data </p><p> ice (per workload or per hour) to access cloud resources [21]. Usagebased pricing can affect overall demand levels, but does not even out shortterm fluctuations [#b11][13]. To manage these fluctuations in demand for a fixed amount of available datacenter capacity, cloud providers could introduce more flexible pricing plans in wh. ases with p. As the bid price p increases, the job is less likely to be interrupted and will therefore have a shorter expected running time. Job interruptibility. We can use the expected running time [#b11](13) to observe the effect of the recovery time parameter, t r , on a job's feasibility for spot instances. Intuitively, spot instances are more effective for more. ery time is less than one time slot length, t r lt min p t k 1F(p)  t k , and a spot instance is feasible at any price.The optimal bid price. We can now multiply the expected running time [#b11](13) with the expected spot price (9) to find that the cost of a job with a persistent request is  sp (p)  T F  (p)E(   . raint ensures that the job is sufficiently interruptible. We use p to denote the optimal bid price to (15).We now observe that the expected running time in [#b11](13) decreases with the bid price, while the expected spot price increases with the bid price. We find that the expected cost  sp (p) first decreases and then inc.  M i1 T i F  (p) 1  F  (p) t k  1 t r t s t o ,i.e., it is the sum of the recovery, execution, and overhead times. Hence, we can extend the result for a single persistent bid in [#b11](13) asM i1 T i F  (p)  t s  t o  M t r 1  tr t k 1  F  (p) . (17) </p>
<p> How to bid the cloud </p><p> statistical modeling of spot instance prices in public cloud environments </p><p> ntributionsWe can gain a basic statistical understanding of Amazon's prevailing spot prices by studying the twomonth history made available by Amazon [[#b13]]. Though these statistics alone are sufficient for the user to deduce a bid price, they also give us some insights into how the provider sets the spot prices. B. (i.e., the job's "interruptibility") and the spot prices offered by the provider. Complicating this tradeoff is the fact that user jobs can have long runtimes spanning many changes in the spot price [#b13][15]. Users then face two key challenges 1) Users must predict the spot prices in order to optimize their bids for a given job, not only in the next time slot but. type"bibr" target"b24"[26], but auctionspecific works on both provider and user actions are limited to statistical studies of historical spot prices [[#b13]].Game theoretic pricing. Spot pricing is a distributed solution to the problem of allocating cloud resources to users, which can be treated as a game bet. instance is lower than the cost of running the job on an ondemand instance, and the second constraint ensures that the job is sufficiently interruptible. We use p to denote the optimal bid price to [#b13](15).We now observe that the expected running time in (13) decreases with the bid price, while the expected spot price. llowing us to solve for the optimal bid price p  Proposition 5. If the probability density function of the spot price monotonically decreases, i.e., F  (p) is concave, the optimal bid price solving [#b13](15) is p   1 t k t r  1 ,(16)where  1 () is the inverse function offormula xmlid"formul. irst constraint ensures that the cost is lower than that of running the job on an ondemand instance. Comparing (19) to bidding for a single persistent request in [#b13](15), we see that (19) can be solved similarly to [#b13](15) in Proposition 5.By compari. ibr" target"b17"(19) to bidding for a single persistent request in [#b13](15), we see that (19) can be solved similarly to [#b13](15) in Proposition 5.By comparing the costs for multiple bids and for a single bid at the optimal bid prices, we find that when the overhead time is suffic. ic property of F  (p). Thus, the minimum of the feasible set is the larger one of  and F 1  1  t k ts .Proof of Proposition 5.Proof. By taking the firstorder derivative of (p) in [#b13](15)  3), F  (p) is concave and F  (p) pf  (p)  0. We then have g(p)p  0. Thus, g(p) monotonically increases with </p>
<p> How to bid the cloud </p><p> market-oriented cloud computing: vision, hype, and reality for delivering it services as computing utilities </p><p> ref type"bibr" target"b20"22,33], most have taken user demands as a given input. Yet user demand can be partially controlled by cloud providers' pricing [#b5][6]. The majority of today's pricing plans for cloud resources are variants on usagebased pricing, in which users pay a static perunit price (per workload or per. reto distribution isf  ()    min  1 , for    min ,where  min    2  1 is derived from the monotonic relation between  (t) and (t) in [#b5](6).Exponential distribution. The PDF of an exponential distribution isf  ()  1  e  1   , for   0.We s.  (   (t)) (t).(21)Solving the system of equations ( 2) and ( 21) yields [#b5](6).We then prove that ( 6) is a sufficient condition for L(t  1)  L(t). From (4), we can derive L(t  1)  L.   1 1(t)  0, where (a) and (b) are obtained by respectively substituting (2) and[#b5](6). Thus, L(t  1)  L(t).Proof of Proposition 4.Proof. By taking the firstorder derivative of  so (p) in the objective of (10), we have so (p)p  ts (F(p)) </p>
<p> How to bid the cloud </p><p> mechanism design for online real-time scheduling </p><p> ave studied the problem of designing online auctions to ensure truthful user bids [[#b27]], including improvements to Amazon's spot pricing [35]. However, in cloud scenarios, user valuations for the instance in a </p>
<p> How to bid the cloud </p><p> beyond poisson: modeling inter-arrival time of requests in a datacenter </p><p> but for tractable analysis we take N continuous in our model. This observation is consistent with the findings in[#b16][18]. Thus, we can expect the cumulative distribution functions to have a knee, as was observed in[1]. note xmlns"h </p>
<p> How to bid the cloud </p><p> pricing in infrastructure clouds-an analytical and empirical examination </p><p> ]. The majority of today's pricing plans for cloud resources are variants on usagebased pricing, in which users pay a static perunit price (per workload or per hour) to access cloud resources [#b19][21]. Usagebased pricing can affect overall demand levels, but does not even out shortterm fluctuations [13]. To manage thes </p>
<p> How to bid the cloud </p><p> pricing wifi at starbucks: issues in online mechanism design </p><p> determined by their valuations of the auctioned resource. Indeed, many works have studied the problem of designing online auctions to ensure truthful user bids [[#b9]], including improvements to Amazon's spot pricing  </p>
<p> How to bid the cloud </p><p> managing cost, performance, and reliability tradeoffs for energy-aware server provisioning </p><p> ls that induce i.i.d. spot prices at the equilibrium. However, empirical studies have found temporal correlation in cloud workloads, possibly inducing positive temporal correlation in the spot prices [#b10][12]. In fact, a study of the spot prices in 2010 shows the presence of limited autocorrelation for consecutive time slots [1]. </p>
<p> How to bid the cloud </p><p> market-oriented cloud computing: vision, hype, and reality for delivering it services as computing utilities </p><p> ref type"bibr" target"b20"22,33], most have taken user demands as a given input. Yet user demand can be partially controlled by cloud providers' pricing [#b5][6]. The majority of today's pricing plans for cloud resources are variants on usagebased pricing, in which users pay a static perunit price (per workload or per. reto distribution isf  ()    min  1 , for    min ,where  min    2  1 is derived from the monotonic relation between  (t) and (t) in [#b5](6).Exponential distribution. The PDF of an exponential distribution isf  ()  1  e  1   , for   0.We s.  (   (t)) (t).(21)Solving the system of equations ( 2) and ( 21) yields [#b5](6).We then prove that ( 6) is a sufficient condition for L(t  1)  L(t). From (4), we can derive L(t  1)  L.   1 1(t)  0, where (a) and (b) are obtained by respectively substituting (2) and[#b5](6). Thus, L(t  1)  L(t).Proof of Proposition 4.Proof. By taking the firstorder derivative of  so (p) in the objective of (10), we have so (p)p  ts (F(p)) </p>
<p> How to bid the cloud </p><p> pricing wifi at starbucks: issues in online mechanism design </p><p> determined by their valuations of the auctioned resource. Indeed, many works have studied the problem of designing online auctions to ensure truthful user bids [[#b9]], including improvements to Amazon's spot pricing  </p>
<p> How to bid the cloud </p><p> smart grid -the new and improved power grid: a survey </p><p> e number of instancetime slots required to complete the job. This dependence differentiates our work from other auctions for computing or utility resources, e.g., auctions for smart grid electricity [#b7][9], secondary spectrum access [16], grid computing [19], or Internet data ref type"bibr.  t k , and a spot instance is feasible at any price.The optimal bid price. We can now multiply the expected running time (13) with the expected spot price [#b7](9) to find that the cost of a job with a persistent request is  sp (p)  T F  (p)E(    p). The user's optimal bid price then solves the optimization problem </p>
<p> How to bid the cloud </p><p> smart grid -the new and improved power grid: a survey </p><p> e number of instancetime slots required to complete the job. This dependence differentiates our work from other auctions for computing or utility resources, e.g., auctions for smart grid electricity [#b7][9], secondary spectrum access [16], grid computing [19], or Internet data ref type"bibr.  t k , and a spot instance is feasible at any price.The optimal bid price. We can now multiply the expected running time (13) with the expected spot price [#b7](9) to find that the cost of a job with a persistent request is  sp (p)  T F  (p)E(    p). The user's optimal bid price then solves the optimization problem </p>
<p> How to bid the cloud </p><p> a game theoretic formulation of the service provisioning problem in cloud systems </p><p> solution to the problem of allocating cloud resources to users, which can be treated as a game between users. Some works have considered the Nash equilibrium of such a pricing game in cloud scenarios [#b2][], although they do not consider optimal bids in a resource auction. More generall. an upper bound on the Lyapunov drift (5)Proposition 1. Suppose (t) follows a distribution with expected value  and variance , and suppose that the spot prices  (t) are chosen according to [#b2](3). Then the conditional expectation of the Lyapunov drift is upper bounded E (t)  L(t)  (  ) 2 (2)  2  L(t), where </p>
<p> How to bid the cloud </p><p> bounds on average delays and queue size averages and variances in input-queued cell-based switches </p><p> en ( 1) is used to compute the spot price, the queuing system is stable in the sense that the timeaveraged queue size at any time t is uniformly bounded [#b21][23]. In fact, the number of requests can ultimately reach an equilibriumProposition 2. The queue sizes of consecutive time slots are in equilibrium, i.e., </p>
<p> How to bid the cloud </p><p> fault-tolerant workflow scheduling using spot instances on clouds </p><p> User bidding strategies for cloud auctions are much less studied than provider strategies. While some works have shown that users can reduce their costs by using spot rather than ondemand instances [#b26][], they only consider heuristic bidding strategies for singleinstance jobs.In general, auction frameworks assume </p>
<p> How to bid the cloud </p><p> when cloud meets ebay: towards effective pricing for cloud computing </p><p> e"bibr" target"b4"[], including improvements to Amazon's spot pricing [#b33][35]. However, in cloud scenarios, user valuations for the instance in a given time slot depend on (unknown) future spot prices. While users may know their valuati </p>
<p> How to bid the cloud </p><p> deconstructing amazon ec2 spot instance pricing </p><p> head n"1.2"Research Challenges and ContributionsWe can gain a basic statistical understanding of Amazon's prevailing spot prices by studying the twomonth history made available by Amazon [#b0][]. Though these statistics alone are sufficient for the user to deduce a bid price, they also give us some insights into h. r cloud services are considered in [26], but auctionspecific works on both provider and user actions are limited to statistical studies of historical spot prices [#b0][].Game theoretic pricing. Spot pricing is a distributed solution to the problem of allocating cloud resources to us. " target"b8"[] in fact, some studies have suggested that Amazon does not use revenuemaximizing spot prices [#b0][1]. Thus, we also include a capacity utilization term  log (1  N (t)), which increases with N (t). This term models the fact that the provider incurs a machine o. ss (t) is nonPoisson. 6 Furthermore, the shape of the PDFs across different instance types is consistent, though the spot prices are different, agreeing with [#b0][1]'s findings.We next estimate the spot price PDF with ( 6) and (7) by assuming Pareto and exponential distrib. used instead, we note that users' job runtimes generally exceed one time slot, requiring predictions far in advance. Since the spot prices' autocorrelation drops off rapidly with a longer    lag time [#b0][1], such predictions are likely to be difficult. We discuss this point further in Section 8.In this section, we first consider onetime requests (Section 5.. temporal correlation in the spot prices [12]. In fact, a study of the spot prices in 2010 shows the presence of limited autocorrelation for consecutive time slots [#b0][1]. Incorporating these correlations into users' spot price predictions may improve their bidding strategies and outcomes this correlation would likely reduce the. lid"foot_3"This observation is consistent with the findings in[18]. Thus, we can expect the cumulative distribution functions to have a knee, as was observed in[#b0][1].   7  As noted in Section 1, the bidding strategies do not explicitly dep </p>
<p> How to bid the cloud </p><p> on competitive provisioning of cloud services </p><p> 38]. We construct a similar model but relate it to empirical bid prices and use it to develop bidding strategies for users. Joint userprovider interactions for cloud services are considered in [#b24][26], but auctionspecific works on both provider and user actions are limited to statistical studies of historical spot prices [1, </p>
<p> How to bid the cloud </p><p> exploring bidding strategies for market-based scheduling </p><p> me slots [20]. Users' optimal bidding strategies in such auctions can be quite complex, particularly if multiple users try to optimize their bids at the same time [#b34][36]. We assume in this paper that users' bid optimizations do not significantly affect the distribution of the spot prices, and discuss the consequences of relaxi </p>
<p> How to bid the cloud </p><p> dynamic resource provisioning in cloud computing: a randomized auction approach </p><p> Unlike most works on spot pricing, which consider only the provider's viewpoint [[#b36]], we aim to develop both a reasonable model for how the provider sets the spot prices and optimal bidding strategies for the user. We do not seek to design the. provider's revenue [] or social welfare [[#b36]]. We construct a similar model but relate it to empirical bid prices and use it to develop bidding strategies for users. Joint userprovider interactions for clo. spot price (t), regardless of the bid (s)he placed. 3 Other objectives, such as clearing the market, are also possible [[#b36]] in fact, some studies have suggested that Amazon does not use revenuemaximizing spot prices ref type"bibr" target". ntaining users' qualityofservice. We could more explicitly account for user satisfaction by taking the social welfare to be the provider's objective function [[#b36]]. While our current formulation matches well with the observed spot prices, including other factors in the provider's spot price optimization problem may shed m </p>
<p> How to bid the cloud </p><p> cost-optimal scheduling in hybrid iaas clouds for deadline constrained workloads </p><p> s have considered the operational problem of scheduling jobs within a datacenter [[#b31]], most have taken user demands as a given input. Yet user demand can be partially controlled by cloud providers' pricing [6]. onsidered resource allocation in the cloud from a purely operational perspective [[#b31]]. Others incorporate pricing considerations, e.g., dynamically allocating cloud resources, so as to maximize the provider's revenue ref type"bibr" target"b8 </p>
<p> How to bid the cloud </p><p> on combinatorial auction and lagrangean relaxation for distributed resource scheduling </p><p> 32], although they do not consider optimal bids in a resource auction. More generally, auctions have been proposed as a solution to generic distributed allocation games over multiple time slots [#b18][20]. Users' optimal bidding strategies in such auctions can be quite complex, particularly if multiple users try to optimize their bids at the same time ref type. e master node and slave nodes respectively, and F m  () and F v  () denote the spot prices' cumulative distribution functions for the master and slave node instance types. The first constraint in [#b18](20) ensures that the master node runs longer than any of the slave nodes (cf. ( 8) and ( ref type"formula" target </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> integrating topics and syntax </p><p> mation in the form of distributional constraints over the generated responses. We propose two constraints that help generate more content rich responses that are based on a model of syntax and topics [#b12](Griffiths et al., 2005) and semantic similarity (Arora et al., 2016). We evaluate our approach against a variety of competitiv. s the distribution over topics and syntax in the response to match that found in the user's input. To estimate these distributions, we leverage the unsupervised model of topics and syntax proposed by [#b12]Griffiths and Steyvers (2005). The second constraint encourages generated responses to be semantically similar to the user's input semantic similarity is measured </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> bayesian inference with posterior regularization and applications to infinite latent svms </p><p> to the decoding objective, is related to prior work on posterior regularization (Mann and McCallum, 2008Ganchev et al., 2010[#b45]Zhu et al., 2014). Posterior regularization introduces similar distributional constraints on expectations computed over unlabeled data using a model's parameters. </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> deal or no deal? end-to-end learning of negotiation dialogues </p><p> further extended with adversarial learning (Li et al., 2017) that rewards generated conversations that are indistinguishable from real conversations in the data. [#b16]Lewis et. al. (2017) applied reinforcement learning with dialogue rollouts to generate replies that maximize expected reward, while learning to generate responses </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> elizaa computer program for the study of natural language communication between man and machine </p><p> ents primarily fall into two categories task oriented dialogue systems (Williams et al., 2013Wen et al., 2015) and chatbots [#b38](Weizenbaum, 1966), although there have been some efforts to integrate the two (Dodge et al., 2015ref type"bibr" target"b4 </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> unsupervised modeling of twitter conversations </p><p> iven chatbots (Ritter et al., 2011) explored the use of phrasebased Statistical Machine Translation (SMT) on large numbers of conversations gathered from Twitter [#b27](Ritter et al., 2010). Subsequent progress on the use of neural networks in machine translation inspired the use of SequencetoSequence (Seq2Seq) models for data </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> deepak ramachandran, and alan black </p><p> us improves plausibility. Related WorkConversational agents primarily fall into two categories task oriented dialogue systems [#b41](Williams et al., 2013Wen et al., 2015) and chatbots (Weizenbaum, 1966), although there </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> generalized expectation criteria for semi-supervised learning of conditional random fields </p><p> fLi et al., 2016a). Our approach, which incorporates distributional constraints into the decoding objective, is related to prior work on posterior regularization [#b24](Mann and McCallum, 2008Ganchev et al., 2010Zhu et al., 2014). Posterior regularization </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> sequence to sequence learning with neural networks </p><p> g significantly more content. Neural Conversation GenerationAs a starting point for our approach we leverage the Seq2Seq model [#b34](Sutskever et al., 2014Bahdanau et al., 2014) which has been used as a basis for a broad range of recent work on neural conver </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> semantically conditioned lstm-based natural language generation for spoken dialogue systems </p><p> eic.orgns1.0"Related WorkConversational agents primarily fall into two categories task oriented dialogue systems (Williams et al., 2013[#b39]Wen et al., 2015) and chatbots (Weizenbaum, 1966), although there have been some efforts to integrate the two ref type"bibr" </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> learning conversational systems that interleave task and non-task content </p><p> ., 2015) and chatbots (Weizenbaum, 1966), although there have been some efforts to integrate the two (Dodge et al., 2015[#b43]Yu et al., 2017). Some of the earliest work on datadriven chatbots (Ritter et al., 2011) explored the use of phrasebased Sta </p>
<p>  Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints.Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints </p><p> generating high-quality and informative conversation responses with sequence-to-sequence models </p><p> range of recent work on neural conversation (Kannan et al., 2016Li et al., 2016aSerban et al., 2016[#b31]Shao et al., 2017). This model consists of two parts, an encoder and a decoder both of which are typically stacked LSTM layers. The encoder reads the input sequenc. onal data with separately trained models of topics and semantic similarity that can drive content selection.There are numerous examples of related work on improving neural conversation models. [#b31]Shao et. al. (2017) introduced a stochastic approach to beam search that does segmentbysegment reranking to promote diversity. Zha </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> facenet: a uni ed embedding for face recognition and clustering </p><p>  T max0,  (y i , y i )   (y i , y i )  m.(3)Instead of projecting to a single point, triplet loss enables documents with the same identity to reside on a manifold [#b28][20], and at the same time maintain a distance from other documents. The architecture of global metric learning with triplet loss is shown in Figure ref type"fig </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> integrated network analysis platform for proteinprotein interactions </p><p> ords between enterprise databases with di erent schema [4], aligning proteinprotein interaction networks to transfer biological knowledge across di erent species [#b38][30], constructing canonicalized knowledge base based on facts extracted from texts [6], and identifying users across multiple </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> a discriminative hierarchical model for fast coreference at large scale </p><p> arn an endtoend model that takes a set of document embeddings as input and directly predict the number of clusters.There is also a thread of research [[#b37]] solving this problem in a hierarchical tree model instead of making pairwise comparisons using clustering. For example, Wick et al. ref type"bibr" target"b. r" target"b29"[[#b37]] solving this problem in a hierarchical tree model instead of making pairwise comparisons using clustering. For example, Wick et al. [#b37][29] build a discriminative hierarchical factor graph model for coreference, and the hierarchical model can also address the scalability issue. Furthermore, human </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> collective entity resolution in relational data </p><p> ture management and people search engine.The problem of disambiguating who is who is referred to as name disambiguation, also named as entity resolution [[#b12]], web appearance disambiguation [], name identi cation [16],. broader viewpoint, and has been extensively studied for decades by di erent communities. It has many real applications, for example, matching records between enterprise databases with di erent schema [#b12][4], aligning proteinprotein interaction networks to transfer biological knowledge across di erent species [30], constructing </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> two supervised learning approaches for name disambiguation in author citations </p><p> nore the second. The stateoftheart solutions for name disambiguation problem can be divided into two categories featurebased and linkagebased.Featurebased methods. Featurebased methods [#b16][] leverage supervised learning method to. CAN to cluster documents. Yoshida et al. [32] propose a twostage clustering method to learn better feature representation via the rst clustering step. Han et al. [#b16][8] present supervised disambiguation methods based on SVM and Nave Bayes. Moreover, Louppe et al. [17] use a classi er to le </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> integrated network analysis platform for proteinprotein interactions </p><p> ords between enterprise databases with di erent schema [4], aligning proteinprotein interaction networks to transfer biological knowledge across di erent species [#b38][30], constructing canonicalized knowledge base based on facts extracted from texts [6], and identifying users across multiple </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> collective entity resolution in relational data </p><p> ture management and people search engine.The problem of disambiguating who is who is referred to as name disambiguation, also named as entity resolution [[#b12]], web appearance disambiguation [], name identi cation [16],. broader viewpoint, and has been extensively studied for decades by di erent communities. It has many real applications, for example, matching records between enterprise databases with di erent schema [#b12][4], aligning proteinprotein interaction networks to transfer biological knowledge across di erent species [30], constructing </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> e cient name disambiguation for large-scale databases </p><p> on scale. RELATED WORKName disambiguation is usually viewed as a clustering problem [ [#b18]]. As many other clustering tasks, there. lutions for name disambiguation problem can be divided into two categories featurebased and linkagebased.Featurebased methods. Featurebased methods [[#b18]] leverage supervised learning method to learn a pairwise distance function betwe. arget"b30"22,32] leverage supervised learning method to learn a pairwise distance function between documents based on their feature vectors. Huang et al. [#b18][10] rst use blocking [22] technique to group candidate documents with similar names together. Then it learns distance between </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> name disambiguation in anonymized graphs using network embedding </p><p> aluate the proposed framework on realworld large data. Our experiments show that the proposed solution achieves significantly better performance than several stateoftheart methods including GHOST [#b41][33], Zhang et al. [#b41][33], and Louppe et al. [17] (735 in terms of F1score). The automa. Our experiments show that the proposed solution achieves significantly better performance than several stateoftheart methods including GHOST [#b41][33], Zhang et al. [#b41][33], and Louppe et al. [17] (735 in terms of F1score). The automatically estimated number of persons by our proposed mode. clustering results. Tang et al. [23] employ Hidden Markov Random Fields to model node features and edge features in a uni ed probabilistic framework. Zhang et al. [#b41][33] solve this problem by learning graph embedding from three constructed graphs based on document similarity and coauthor relationship.Our method proposed. formance of our proposed approach, we compare it against three stateoftheart name disambiguation methods. For a fair comparison, the number of clusters is set to the true value.Zhang et al. [#b41][33] This method constructs three local graphs for a candidate set based on coauthors and document similarity. A graph embedding is learned for each candidate set </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> integrated network analysis platform for proteinprotein interactions </p><p> ords between enterprise databases with di erent schema [4], aligning proteinprotein interaction networks to transfer biological knowledge across di erent species [#b38][30], constructing canonicalized knowledge base based on facts extracted from texts [6], and identifying users across multiple </p>
<p> Name Disambiguation in AMiner: Clustering, Maintenance, and Human in the Loop </p><p> swoosh: a generic approach to entity resolution </p><p> ic applications such as scienti c literature management and people search engine.The problem of disambiguating who is who is referred to as name disambiguation, also named as entity resolution [#b11][], web appearance disambiguation [], name identi cation r </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> sequence to sequencevideo to text </p><p> type"bibr"2013), subsampling on a fixed number of input frames (Yao et al. 2015) and extracting the last hidden state of recurrent visual feature encoder [#b20](Venugopalan et al. 2015).Those feature encoding methods mentioned above are only based on visual cues. However, videos contain the visual modality and the. .   Basic Video Caption FrameworkOur basic video caption framework is extended from S2VT (sequence to sequence video to text) model [#b20](Venugopalan et al. 2015) and M 3 (multimodal memory modeling) model (Wang et al. 2016), which is shown in Figure ref type"f </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> show and tell: a neural image caption generator </p><p> 4Yao et al. 2015Pan et al. 2016a2016b), which take inspiration from image caption [#b21](Vinyals et al. 2015Donahue et al. 2015).We argue that these video caption methods only rely on visual information whil </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> generating naturallanguage video descriptions using text-mined knowledge </p><p> s.The first category is templatebased methods. They first identified the semantic attributes hidden in videos and then derived a sentence structure based on some predefined sentence templates [#b6](Krishnamoorthy et al. 2013Thomason et al. 2014). Then, probabilistic graphical model was utilized to collect the most relevan </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> rethinking the inception architecture for computer vision </p><p>  </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> msr-vtt: a large video description dataset for bridging video and language </p><p> al. 20152016), recurrent neural networks (RNN) (Hochreiter and Schmidhuber 1997) and large paired video language description datasets [#b25](Xu et al. 2016), video caption has achieved promising successes.Most video caption frameworks can be simply splitted into a encoder stage and a decoder sta. ize the Microsoft ResearchVideo to Text Dataset (MSRVTT) and Microsoft Video Description Dataset (MSVD) (Chen and Dolan 2011). Their split method can be found in [#b25](Xu et al. 2016) and (Yao et al. 2015) respectively. In addition, gradients are clipped into range [] </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> jointly modeling embedding and translation to bridge video and language </p><p> nto specific provided sentences (Venugopalan et al. 2014Yao et al. 2015Pan et al. 2016a[#b9]2016b), which take inspiration from image caption (Vinyals et al. 2015Donahue et al. 2015) </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> collecting highly parallel data for paraphrase evaluation </p><p> is the number of sampled framesclips.To validate the performance of our model, we utilize the Microsoft ResearchVideo to Text Dataset (MSRVTT) and Microsoft Video Description Dataset (MSVD) [#b1](Chen and Dolan 2011). Their split method can be found in (Xu et al. 2016) and (Yao et al. 2015) </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> going deeper with convolutions </p><p> as humanrobot interaction, video retrieval. Recently, benefiting from extraordinary abilities of convolutional neural networks (CNN) (Simonyan and Zisserman 2014[#b16]Szegedy et al. 20152016), recurrent neural networks (RNN) (Hochreiter and Schmidhuber 1997) and large p </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> going deeper with convolutions </p><p> as humanrobot interaction, video retrieval. Recently, benefiting from extraordinary abilities of convolutional neural networks (CNN) (Simonyan and Zisserman 2014[#b16]Szegedy et al. 20152016), recurrent neural networks (RNN) (Hochreiter and Schmidhuber 1997) and large p </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> integrating language and vision to generate natural language descriptions of videos in the wild </p><p> t identified the semantic attributes hidden in videos and then derived a sentence structure based on some predefined sentence templates (Krishnamoorthy et al. 2013[#b18]Thomason et al. 2014). Then, probabilistic graphical model was utilized to collect the most relevant contents in videos to generate the corresponding sentence. Alt </p>
<p> integrating both visual and audio cues for enhanced video caption </p><p> video2text: learning to annotate video content </p><p> by these models seemed to be grammatically correct, they were lack of richness and flexibility.The second category treat video caption as a retrieval problem. They tagged videos with metadata [#b0](Aradhye, Toderici, and Yagnik 2009) and then clustered videos and captions based on these tags. Although the generated sentences were more naturally compared to th </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> alleviating overfitting for polysemous words for word representation estimation using lexicons </p><p> features or local semantic features alone are inadequate to represent the text comprehensively. Some ensemble approaches [8][9][#b9][10] fused different text features and achieved promising results, but they are still limited because of the overlap between different features which leads to low t </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> thumbs up? sentiment classification using machine learning techniques </p><p> thm for higher accuracy are the main challenges [1]. Some conventional machine learning models are simple but have yield strong baselines. For example, Pang et al. [#b1][2] proposed a SVM categorization model based on ngram approach and achieved good performance. Wang et al. [3] developed the NB </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> newsweeder: learning to filter netnews </p><p> t is part of Amazon's electronic product review data. Similar to the IMDB data, it only has two categories with the same number of documents. The 20Newsgroup3  [#b14][15] data set is a standard database for machine learning evaluation, we chose the version which including 18,828 documents. The AGref type"foot" target"foot_5 </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> character-level convolutional networks for text classification </p><p> bibr" target"b14"[15] data set is a standard database for machine learning evaluation, we chose the version which including 18,828 documents. The AG4  [#b15][16] dataset is a collection of more than 1 million news articles, and we choose the 4 largest classes from this corpus. The Yelp. "bibr" target"b15"[16] dataset is a collection of more than 1 million news articles, and we choose the 4 largest classes from this corpus. The Yelp5  [#b15][16] reviews dataset is obtained from the Yelp Dataset Challenge in 2015, and include two classification task, the predicting full number of starts or polarity lab. lic tasks, proving it can effectively extract features of the text and improve the accuracy of text categorization. How good the learnt representations are for language modeling is a crucial question [#b15][16]. In the future, we intend to apply these semisupervised learning and transfer learning to our model.figure xmlns"httpwww.teic.orgns1.0" xml </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> newsweeder: learning to filter netnews </p><p> t is part of Amazon's electronic product review data. Similar to the IMDB data, it only has two categories with the same number of documents. The 20Newsgroup3  [#b14][15] data set is a standard database for machine learning evaluation, we chose the version which including 18,828 documents. The AGref type"foot" target"foot_5 </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> glove: global vectors for word representation </p><p> selection approach to get different implementations of our model, as shown in Table 2. Noted that the word vector input to GRU is initialized with the Glove 6 [#b16][17] word vector matrix, others are all initialized with uniform distribution. We can see clearly that, for the implementations of ngram  Global average pooling, </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> combining multimodal features with hierarchical classifier fusion for emotion recognition in the wild </p><p> research attention in recent years. Due to the characteristics of text structure, how to extract text features more effectively and optimize the algorithm for higher accuracy are the main challenges [#b0][1]. Some conventional machine learning models are simple but have yield strong baselines. For example, Pang et al. [2] proposed. httpwww.teic.orgns1.0"Decision Level Fusion ApproachOur model utilizes decisionlevel fusion to concatenate the complementary information of different kinds of features [#b0][1]. The decision vector [x     x k  x k ] represents the corpus from GRU, and the decision vector[ x  1 ,  , x  n1 , x  </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> character-level convolutional networks for text classification </p><p> bibr" target"b14"[15] data set is a standard database for machine learning evaluation, we chose the version which including 18,828 documents. The AG4  [#b15][16] dataset is a collection of more than 1 million news articles, and we choose the 4 largest classes from this corpus. The Yelp. "bibr" target"b15"[16] dataset is a collection of more than 1 million news articles, and we choose the 4 largest classes from this corpus. The Yelp5  [#b15][16] reviews dataset is obtained from the Yelp Dataset Challenge in 2015, and include two classification task, the predicting full number of starts or polarity lab. lic tasks, proving it can effectively extract features of the text and improve the accuracy of text categorization. How good the learnt representations are for language modeling is a crucial question [#b15][16]. In the future, we intend to apply these semisupervised learning and transfer learning to our model.figure xmlns"httpwww.teic.orgns1.0" xml </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> learning word vectors for sentiment analysis </p><p> tasets including ontology classification, sentiment analysis, and text categorization. Table 1 is a summary. The IMDB1  [#b12][13] data set consists of numerous film movie reviews. It is commonly used for emotional categorization. The ELEC2  ref ty </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> learning word vectors for sentiment analysis </p><p> tasets including ontology classification, sentiment analysis, and text categorization. Table 1 is a summary. The IMDB1  [#b12][13] data set consists of numerous film movie reviews. It is commonly used for emotional categorization. The ELEC2  ref ty </p>
<p> Multimodal Fusion with Global and Local Features for Text Classification </p><p> learning word vectors for sentiment analysis </p><p> tasets including ontology classification, sentiment analysis, and text categorization. Table 1 is a summary. The IMDB1  [#b12][13] data set consists of numerous film movie reviews. It is commonly used for emotional categorization. The ELEC2  ref ty </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> freebase: a collaboratively created graph database for structuring human knowledge </p><p>       IntroductionKnowledge bases (KBs), such as Freebase [#b1](Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> random walk inference and learning in a large scale knowledge base </p><p> tempt to mitigate the problems of this knowledge sparsity.In this work we examine one method for performing knowledge base completion that is currently in use the Path Ranking Algorithm (PRA) [#b14](Lao et al., 2011Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing. joined on intermediate nodes to get a larger set of paths that connect the source and target nodes. Once connectivity statistics have been computed in this way, k path types are selected as features. [#b14]Lao et al. (2011) use measures of the precision and recall of each feature in this selection, while Gardner et al. (2014) simpl. d obviously be used here instead of random walks, and indeed Lao's original work did use a more exhaustive search. However, when moving to the larger graphs corresponding to the NELL and Freebase KBs,[#b14]Lao (2011) (and all future work) switched to using random walks, because the graph was too large. note xmlns"httpwww.teic.orgns1.0" place"foot" </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> effective blending of two and threeway interactions for modeling multi-relational data </p><p> ., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014[#b7]GarcaDurn et al., 2014Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge b </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> combining vector space embeddings with symbolic logical inference over open-domain text </p><p> ref. PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference [#b10](Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any l </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> knowledge vault: a web-scale approach to probabilistic knowledge fusion </p><p> ty.In this work we examine one method for performing knowledge base completion that is currently in use the Path Ranking Algorithm (PRA) (Lao et al., 2011[#b6]Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The met. text corpus (Gardner et al., 2013Gardner et al., 2014), and using PRA in a broader context as part of Google's Knowledge Vault [#b6](Dong et al., 2014). An interesting piece of work that combines embedding methods with graphbased methods is that of Neelakantan et </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> knowledge graph embedding by translating on hyperplanes </p><p> "b25"(Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014GarcaDurn et al., 2014[#b29]Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in th </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> typed tensor decomposition of knowledge bases for relation extraction </p><p> ed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms [#b4](Chang et al., 2014GarcaDurn et al., 2014Wang et al., 2014). These methods perform wel </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> multi-instance multi-label learning for relation extraction </p><p> s easily seen in the line of work known as distantlysupervised relation extraction (Mintz et al., 2009Hoffmann et al., 2011[#b27]Surdeanu et al., 2012) these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> multi-instance multi-label learning for relation extraction </p><p> s easily seen in the line of work known as distantlysupervised relation extraction (Mintz et al., 2009Hoffmann et al., 2011[#b27]Surdeanu et al., 2012) these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> knowledge vault: a web-scale approach to probabilistic knowledge fusion </p><p> ty.In this work we examine one method for performing knowledge base completion that is currently in use the Path Ranking Algorithm (PRA) (Lao et al., 2011[#b6]Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The met. text corpus (Gardner et al., 2013Gardner et al., 2014), and using PRA in a broader context as part of Google's Knowledge Vault [#b6](Dong et al., 2014). An interesting piece of work that combines embedding methods with graphbased methods is that of Neelakantan et </p>
<p> Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction </p><p> distant supervision for relation extraction without labeled data </p><p> for knowledge base completion, but typical KB completion methods do not make predictions on single sentences. This is easily seen in the line of work known as distantlysupervised relation extraction [#b18](Mintz et al., 2009Hoffmann et al., 2011Surdeanu et al., 2012) these models use the re </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> deep-dive analysis of the data analytics workload in cloudsuite </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] rable to the Google services [23].We provide insight into the root causes of relatively low IPC using the Topdown Microarchitecture Analysis Method (TMAM) [#b62][63] to categorize processor pipelines' execution stalls, as reported in Fig. 7. TMAM exposes architectural bottlenecks de. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] enchmark suites for cloud services. Most notably, CloudSuite [21] comprises both latencysensitive and throughputoriented scaleout cloud workloads. Yasin et al. [#b62][63] perform a microarchitectural characterization of several CloudSuite workloads. However, our findings on production services differ from those of academic clou. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] te workloads. However, our findings on production services differ from those of academic cloud benchmark suite studies [[#b62]]. For example, unlike these benchmark suites, our microservices have large L2 an </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> bubble-up: increasing utilization in modern warehouse scale computers via sensible co-locations </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] yriad knobs to create customized microservicespecific soft SKUs. Other works reduce coscheduled job interference [109][110][#b110][111][112][113][114] or schedule them in a machi </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> unfair data centers for fun and profit </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] , wherein a complex application is decomposed into distributed microservices [7][8][9][#b9][10] that each provide specialized functionality [11], such as HTTP connection termination, keyvalue serving ref type"bibr" </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> a reconfigurable fabric for accelerating large-scale datacenter services </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] [92] show that L2 caches encompass such workloads' working set, leaving memory bandwidth underutilized. Microsoft's Catapult accelerates search ranking via FPGAs [#b92][93]. DCBench studies latencysensitive cloud data analytics [94]. Studying a single service class can restrict the generality </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> quantifying the cost of context switch </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] itch counts reported by Linux's time utility. We then estimate upper and lower context switch penalty bounds using switching latencies reported by prior works [[#b52]].Cache1 and Cache2 incur context switches far more frequently than other microservices, and may spend as much as 18 of CPU time in switching. These freq </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> the architectural implications of cloud microservices </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] er differ markedly from those of SPEC CPU20062017 [], academic cloud workloads [[#b21]], and even some of Google's major services [].Such diversity might suggest a. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] ral characterization of several CloudSuite workloads. However, our findings on production services differ from those of academic cloud benchmark suite studies [[#b21]]. For example, unlike these benchmark su </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> fawn: a fast array of wimpy nodes </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] Earlier work [87] also discusses microarchitecture for Google search. Some works [88][89][#b89][90] characterize lowpower cores for search engines like Nutch and Bing. Trancoso et al. [91] analyze the AltaVista search en </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> ?tune: auto-tuned threading for oldi microservices </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] ef type"bibr" target"b6"[7][8][9][10] that each provide specialized functionality [#b10][11], such as HTTP connection termination, keyvalue serving [12], protocol routing [13,. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] t, Web, Feed2, and Ads1 emit requests to other microservices and hence their queries spend considerable time blocked. These can benefit from architecturalOS features that support greater concurrency [#b10][], fast thread switching, and better IO performance [50,ref type"bibr" target" </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> tao: facebook's distributed data store for the social graph </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] nality disaggregation across microservices has yielded enormous diversity in system and CPU architectural requirements, as shown in Fig. 1. For example, caching microservices [#b15][16] require intensive IO and microsecondscale response latency and frequent OS context switches can comprise 18 of CPU time. In contrast, a Feed ref type"bibr. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] targeting criteria to Ads1. Ads1 then ranks the returned ads.Cache1 and Cache2. Cache is a large distributedmemory object caching service (like, e.g., [[#b15]]) that reduces throughput requirements of various backing stores. Cache1 and Cac. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] ces can likely benefit from optimizations for dense computation, such as SIMD instructions.Prior work has reported that keyvalue stores, like Cache1 and Cache2, are typically memory intensive [#b15][16]. However,  we note that Cache requires substantial arithmetic and control flow instructions for parsing requests and marshalling or unmarshalling data their. [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] gain relative to execution on only two physical cores. The grey line indicates ideal linear scaling. ?SKU scales Web (Skylake) to its maximum core count (18 cores) and Web (Broadwell) to its maximum [#b15](16). We exclude Ads1 from Fig. 15 since its load balancing design precludes ?SKU from meeting QoS  constraints with fewe </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> increasing tlb reach by exploiting clustering in page translations </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] ent huge pages) and hardware (e.g., [69][70][71][72][#b72][73][74][75]) paging optimizations.2.4.5 Memory bandwidth utilization. We inspect </p>
<p> softsku: optimizing server architectures for microservice diversity @scale </p><p> memory system characterization of commercial workloads </p><p> [pos is CCS CONCEPTS Computer systems organization ? Cloud computing] like Nutch and Bing. Trancoso et al. [91] analyze the AltaVista search engine's memory behavior and find it similar to decision support workloads Barroso et al. [#b91][92] show that L2 caches encompass such workloads' working set, leaving memory bandwidth underutilized. Microsoft's Catapult accelerates search ranking via FPGAs </p>
<p> critics critiquing criticality in mobile apps </p><p> focusing processor policies via critical-path prediction </p><p> s one for memory which issues prefetches for critical loads [18] and another for ALU resources in instruction scheduling [4], [#b31][32], [33]. These proposals identify highfanout loads to mark them as critical to issue prefetch ref type"bibr" target"b1. . These proposals identify highfanout loads to mark them as critical to issue prefetch [18] and prioritize the critical instructions for ALU resource allocations [#b31][32], [33]. These techniques have shown significant benefits for server workloads. The highfanout based optimization has also. arget"b32"[33] This platform implements the prioritization hardware for the backend resources proposed in [33], using the tracking hardware proposed in [#b31][32], which requires 1.5KB SRAM for maintaining the tokens. ? AllHW This consists of hardwares for both front and backends, i.e., 4?icacheEFetchPerfectBrBacke </p>
<p> critics critiquing criticality in mobile apps </p><p> criticality-based optimizations for efficient load processing </p><p> f [13], predicting the result of the instruction [14] [17], issuing prefetch requests [#b17][18], etc. However, the impact of these optimizations has not been studied to date for mobile workloads, and that is one important void this paper intends to fill.. i.e., they are often dependent on each other with possibly one or more noncritical instructions coming into the dependence chain between them. For instance, we show that one such recent optimization [#b17][18], which prioritizes critical loads, does very well for SPEC workloads (as in prior works), but provides a measly 0.7 speedup for a wide spectrum of mobile app. ioritizing CPU resources [26] [28], caches [8], [9], [#b17][18], memory requests [11], predicting instruction results [14], ref type"bibr" target. t"b10"[11], predicting instruction results [14], [29] [31], issuing prefetches [#b17][18], etc. Until now, these optimizations have been primarily proposed and evaluated for serverdesktop workloads and not for mobile appsplatforms. Without loss i. generality, we have taken two representative, wellstudied and wellproven criticality optimizations in prioritizing two important resources one for memory which issues prefetches for critical loads [#b17][18] and another for ALU resources in instruction scheduling [4], [32], ref type"bibr" t. br" target"b3"[4], [32], [33]. These proposals identify highfanout loads to mark them as critical to issue prefetch [#b17][18] and prioritize the critical instructions for ALU resource allocations [32], [33]. Th. e techniques have shown significant benefits for server workloads. The highfanout based optimization has also been shown to outperform the latency based ways of identifying and exploiting criticality [#b17][18], [34]. We next evaluate the usefulness of both these criticality optimizations (depicted as bars) in mobile apps and comp. t ALU resource scheduling are both quite significant for SPEC.int (15 from prefetching, 9 from prioritizing) and SPEC.float (34 from prefetching, 25 from prioritizing), reaffirming prior results [#b17][18], [33]. Interestingly, the gains from these two optimizations are a relatively measly 0.7 from prefetching and 5 from pr. ook into the future as well. Traditional criticality based optimizations [9], [11], [12], [#b17][18] have targeted one critical instruction at a time, rather than groups or chains. D. What do these inst. e"bibr" target"b19"[20], [59] Memory2way 32KB icache, 64KB dcache, 2 cycle hit latency 8way 2MB L2 with System CLPT prefetcher (1024?7bits entries) [#b17][18]   Data Processing call), and the 3bit argument with it to denote that the next l  1 instructions would be 16bit format to inform the decoder accordingly. F. or those identified using techniques such as critical load optimizations [9], [11], [12], [#b17][18], [79] or even backend optimizations for critical instructions such as [5], ref type. get"b79"[80] [82]. However, such techniques require fairly extensive hardware to identify these chains, and optimizing for them, e.g. techniques such as [#b17][18], [76], [77] require 16KB SRAM, and [79] incurs </p>
<p> critics critiquing criticality in mobile apps </p><p> dynamic prediction of critical path instructions </p><p> s for server workloads. The highfanout based optimization has also been shown to outperform the latency based ways of identifying and exploiting criticality [18], [#b33][34]. We next evaluate the usefulness of both these criticality optimizations (depicted as bars) in mobile apps and compare the mean speedup obtained from employin </p>
<p> critics critiquing criticality in mobile apps </p><p> improving memory scheduling via processor-side load criticality information </p><p> urces [4] [7], caches [8] [10], memory request queues [#b10][11] [13], predicting the result of the instruction [14] ref type"bibr" target"b16". ] [28], caches [8], [9], [18], memory requests [#b10][11], predicting instruction results [14], [29] [31]ref. critical instructions (chainssequences) together for possible optimizations, i.e., look into the future as well. Traditional criticality based optimizations [9], [#b10][11], [12], [18] have targeted one critical instruction at a time, rather than groups or. on latencies, slack, and execution graph representations, as well as (ii) optimizing for those identified using techniques such as critical load optimizations [9], [#b10][11], [12], [18], [79] or even backend optimizations </p>
<p> critics critiquing criticality in mobile apps </p><p> a large, fast instruction window for tolerating cache misses </p><p> ritIC addresses both (i) F.StallForI which the above 3 address and (ii) F.StallForRD, which is somewhat addressed by prior criticality optimizations such as [5], [#b5][6], [14], [16], [25], ref type"bibr" target"b30". 2], [18], [79] or even backend optimizations for critical instructions such as [5], [#b5][6], [14], [16], [24], ref type"bibr" target"b24" </p>
<p> critics critiquing criticality in mobile apps </p><p> the non-critical buffer: using load latency tolerance to improve data cache efficiency </p><p> ticality based optimizations have been proposed and studied for highend workloads prioritizing CPU resources [4] [7], caches [#b7][8] [10], memory request queues [11] [13], predictin. tion as critical are by using thresholds for (i) execution latency of an instruction (a long latency instruction implies instructions depending on it have to be delayed, thus making it more critical) [#b7][8], [9], [26] and (ii) number of dependent instructions (referred to as fanout in this pap. pDifferent optimizations can be employed upon fetching a critical instruction prioritizing CPU resources [26] [28], caches [#b7][8], [9], [18], memory requests [11], predicting instr. 13 cycles.2) How to find them? There are two broad strategies for identifying CritICs (a) using hardware predictor tables as used in many prior works [4], [#b7][8], [12], [24] andor (b) using software profiledriven compilation. As explained, we wou </p>
<p> critics critiquing criticality in mobile apps </p><p> a criticality-aware dvfs runtime utility for optimizing power efficiency of multithreaded applications </p><p> ns can be employed. Over the years, numerous criticality based optimizations have been proposed and studied for highend workloads prioritizing CPU resources [4] [#b6][7], caches [8] [10], memory request queues [11] ref </p>
<p> critics critiquing criticality in mobile apps </p><p> race-to-sleep + content caching + display caching: a recipe for energy-efficient video streaming on handhelds </p><p>  </p>
<p> critics critiquing criticality in mobile apps </p><p> enhanced code compression for embedded risc processors </p><p> at we would like to optimize, in the 16bit format (Fig. 6(d)). Even though past studies [51], [52], [#b54][55] report that the 16bit format produces ? 1.6? more instructions to execute (and causes slowdown) because (i) it cannot have predicated executions, and (ii) it. tion of a CritIC sequence, that we would like to optimize, in the 16bit format (Fig.6(d)). Even though past studies[51],[52],[#b54][55] report that the 16bit format produces ? 1.6? more instructions to execute (and causes slowdown) because (i) it cannot have predicated executions, and (ii) it </p>
<p> critics critiquing criticality in mobile apps </p><p> quantifying instruction criticality </p><p> urces are constrained, priority has to be given to "critical instructions" [4], [9], [12], [#b23][24] [26]. In this work, we use a simple definition of criticality, similar to those in some prior works ref type"bibr" tar. g CritICs (a) using hardware predictor tables as used in many prior works [4], [8], [12], [#b23][24] andor (b) using software profiledriven compilation. As explained, we would like to minimize hardware requirements as much as possible, especially since mobi. Prior work has revolved around both (i) identifying critical instructions [4], [9], [12], [#b23][24] [26] using metrics such as fanout, tautness, execution latencies, slack, and execution graph representations, as well as. r critical instructions such as [5], [6], [14], [16], [#b23][24], [25], [31], [75] ref type"bibr" target"b7 </p>
<p> critics critiquing criticality in mobile apps </p><p> proram: dynamic prefetcher for oblivious ram </p><p>  </p>
<p> critics critiquing criticality in mobile apps </p><p> dynamic speculative precomputation </p><p> target"b8"[9], [18], memory requests [11], predicting instruction results [14], [#b28][29] [31], issuing prefetches [18], etc. Until now, these optimizations have been primar </p>
<p> critics critiquing criticality in mobile apps </p><p> kill the program counter: reconstructing program behavior in the processor cache hierarchy </p><p> nal Hardware Fetch OptimizationsOne may note that numerous prior hardware enhancements proposed to address the Fetch stage problems, including larger and more intelligently managed icaches [#b62][63] [65], better branch predictors [66] [69], and. t there can be considerable rewards in targeting this stage. Fetch stage bottlenecks have been extensively addressed in high end processors through numerous techniques smart icache management (e.g. [#b62][63] [65], [97] [99]) prefetching (e.g. ref type </p>
<p> critics critiquing criticality in mobile apps </p><p> checkpoint processing and recovery: towards scalable large instruction window processors </p><p>  </p>
<p> critics critiquing criticality in mobile apps </p><p> kill the program counter: reconstructing program behavior in the processor cache hierarchy </p><p> nal Hardware Fetch OptimizationsOne may note that numerous prior hardware enhancements proposed to address the Fetch stage problems, including larger and more intelligently managed icaches [#b62][63] [65], better branch predictors [66] [69], and. t there can be considerable rewards in targeting this stage. Fetch stage bottlenecks have been extensively addressed in high end processors through numerous techniques smart icache management (e.g. [#b62][63] [65], [97] [99]) prefetching (e.g. ref type </p>
<p> critics critiquing criticality in mobile apps </p><p> a large, fast instruction window for tolerating cache misses </p><p> ritIC addresses both (i) F.StallForI which the above 3 address and (ii) F.StallForRD, which is somewhat addressed by prior criticality optimizations such as [5], [#b5][6], [14], [16], [25], ref type"bibr" target"b30". 2], [18], [79] or even backend optimizations for critical instructions such as [5], [#b5][6], [14], [16], [24], ref type"bibr" target"b24" </p>
<p> critics critiquing criticality in mobile apps </p><p> a scalable application-specific processor synthesis methodology </p><p> ely prevalent across several apps as was the case in solutions such as [42], [43], [53], [#b53][54]. However, Fig. 5b shows that the number of unique CritIC sequences (opcodeoperands of all constituent instructions) is large even E </p>
<p> critics critiquing criticality in mobile apps </p><p> balanced scheduling: instruction scheduling when memory latency is uncertain </p><p>  </p>
<p> critics critiquing criticality in mobile apps </p><p> replay: a hardware framework for dynamic optimization </p><p> or mobile apps which have high user interactivity. Conveniently, common cases of user inputs are readily provided for many of these apps in standard formats [47], [#b47][48], that we avail for our approach. ? Ability to track long ICs and their spread Software based approaches are often criticized because of their restricted scop </p>
<p> critics critiquing criticality in mobile apps </p><p> critical path analysis of the trips architecture </p><p> ediction in the entire execution. Since CritIC addresses both (i) F.StallForI which the above 3 address and (ii) F.StallForRD, which is somewhat addressed by prior criticality optimizations such as [#b4][5], [6], [14], [16], [. , [12], [18], [79] or even backend optimizations for critical instructions such as [#b4][5], [6], [14], [16], [ </p>
<p> critics critiquing criticality in mobile apps </p><p> efetch: optimizing instruction fetch for event-driven web applications </p><p> are unitsqueues) in the fetch and decode stages. ? 4?icache Though unreasonable, we compare with a hardware that has 4? the icache capacity (128KB vs. 32KB) to reduce instruction misses. ? EFetch [#b70][71] We implemented a recently proposed instruction prefetcher [#b70][71] that is specifically useful for userevent driven applica. hardware that has 4? the icache capacity (128KB vs. 32KB) to reduce instruction misses. ? EFetch [#b70][71] We implemented a recently proposed instruction prefetcher [#b70][71] that is specifically useful for userevent driven applications, as in our mobile apps. This prefetcher [#b70][71] tracks histor. implemented a recently proposed instruction prefetcher [#b70][71] that is specifically useful for userevent driven applications, as in our mobile apps. This prefetcher [#b70][71] tracks history of userevent call stack, and uses it to predict the next functions and prefetch its instructions. It needs a 39KB lookup table for maintaining </p>
<p> critics critiquing criticality in mobile apps </p><p> automatic design of domain-specific instructions for low-power processors </p><p> C sequences are somewhat limited, i.e., there are a few common sequences which are widely prevalent across several apps as was the case in solutions such as [42], [#b42][43], [53], [54]. However, Fig. 5b shows that the number of uniq </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> connecting the edges: a universal, mobile-centric, and opportunistic communications architecture </p><p> ic.orgns1.0"INTRODUCTIONThe massive proliferation of personal computing devices is opening up new humancentered designs that blur the boundaries between humans and machines [#b0][1]. Now, the frontier for research on data management is related to the socalled edge computation and communication, consisting of an architecture of one or more. ata in the industrial IoT environment. Edge computing is expected to support not only the evergrowing number of users and devices but also a diverse set of new applications and services. The work in [#b0][1] introduced a system that can pervasively operate in any networking environment and allows for the development of innovative applications by pushing services nea </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> task offloading for mobile edge computing in software defined ultra-dense network </p><p> maintaining the QoS for various applications. However, a large number of migrations among edge devices and cloud servers leads to congestion in the underlying networks. Hence, to handle this problem, [#b6][7] presented an SDNbased edgecloud interplay to handle the streaming of big data in the industrial IoT environment. Edge computing is expected to support not onl </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> speech emotion recognition using deep convolutional neural network and discriminant temporal pyramid matching </p><p> cial emotion recognition and using the deep neural network VGG. For the medium resolution, we analyze the facial expression (VGG [20]) and speech emotion (AlexNet [#b18][19]) simultaneously and carry out the simple decision fusion. For high resolution, we use the strong computing resources, provide the multimodal emotion recogniti </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> when collaboration hugs intelligence: content delivery over ultra-dense networks </p><p> hat an unauthorized person cannot access the data, providing secure data sharing between the device and the edge cloud, and safe data storage on the edge cloud [10][#b10][11][12].However, the above research on edge computing mostly focused on solving the communication problems by leveragi </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> incentivising resource sharing in edge computing applications </p><p> y and privacy in edge computing, there is an increasing realization that edge devices, which are closer to the user, can play an important part in supporting latencyand privacysensitive applications [#b7][]. Therefore, the security challenges relate to the protection of device data, such that an unauthorized person cannot acces </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> enabling cognitive smart cities using big data and machine learning: approaches and challenges </p><p> such as machine learning and data analytics within the framework of smartcity applications, such as smart transportation, smart parking, and smart environment, to address the challenges of big data. [#b13][14] also explored how deep reinforcement learning and its shift toward semisupervision can handle the cognitive side of smartcity services. The work in ref type </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> task offloading for mobile edge computing in software defined ultra-dense network </p><p> maintaining the QoS for various applications. However, a large number of migrations among edge devices and cloud servers leads to congestion in the underlying networks. Hence, to handle this problem, [#b6][7] presented an SDNbased edgecloud interplay to handle the streaming of big data in the industrial IoT environment. Edge computing is expected to support not onl </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> speech emotion recognition using deep convolutional neural network and discriminant temporal pyramid matching </p><p> cial emotion recognition and using the deep neural network VGG. For the medium resolution, we analyze the facial expression (VGG [20]) and speech emotion (AlexNet [#b18][19]) simultaneously and carry out the simple decision fusion. For high resolution, we use the strong computing resources, provide the multimodal emotion recogniti </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> edge computing: vision and challenges </p><p> ata storage and processing to reduce the retrieval time and have more control over the data with respect to cloudbased services, and to consume fewer resources and less energy to reduce the workload [#b1][].The edge computing paradigm has multiple advantages. First, the edge node can reduce the traffic load of backhaul b. that time. For a sequence of batch requests X  x 1 , x 2 , . . . , x N , the goal of the service migration is to determine S 1 , S 2 , . . . , S N to maximize the system reward defined by Equation [#b1](2).Qlearning is one of the most popular Reinforcement Learning [23] (RL) methods that is applied in many research area </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> edge computing: vision and challenges </p><p> ata storage and processing to reduce the retrieval time and have more control over the data with respect to cloudbased services, and to consume fewer resources and less energy to reduce the workload [#b1][].The edge computing paradigm has multiple advantages. First, the edge node can reduce the traffic load of backhaul b. that time. For a sequence of batch requests X  x 1 , x 2 , . . . , x N , the goal of the service migration is to determine S 1 , S 2 , . . . , S N to maximize the system reward defined by Equation [#b1](2).Qlearning is one of the most popular Reinforcement Learning [23] (RL) methods that is applied in many research area </p>
<p> a dynamic service migration mechanism in edge cognitive computing </p><p> integrated networking, caching, and computing for connected vehicles: a deep reinforcement learning approach </p><p> o designed a novel offloading strategy to optimize the performance of IoT deeplearning applications with edge computing since the existing edge nodes have limited processing capability. The works in [#b16][17] and [18] proposed a novel deep reinforcement learning approach to solve the resource allocation problems in terms of netw </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> chinese ner using lattice lstm </p><p> with some word boundaries, which suggests that words in character sequence can provide rich boundary information for characterbased model. To integrate words information into characterbased model, [#b40]Zhang and Yang (2018) propose a latticestructured LSTM model to encode a sequence of input characters as well as all potential words that match a lexicon. Their m. (2018) apply adversarial transfer learning framework to integrate the taskshared word boundary information into Chinese NER task. Another way to obtain word boundary information is proposed by [#b40](Zhang and Yang, 2018), using a lattice LSTM to integrate word information into characterbased model, which is similar to what is proposed in Where "ltPADgt". rds assigned to i th character in forward WCLSTM, which are a set of character subsequences c b,i , where b lt i and c b,i matches a word in lexicon D. The lexicon D is the same as the one used in [#b40](Zhang and Yang, 2018), which is built by using automatically segmented large raw text. Similarly, we use  ws i to denote the words for i th character in backwar. hen et al., 2015Yang et al., 2017), we concatenate each x c i with x   ws i to utilize word information. And this is quite different from the way used in [#b40](Zhang and Yang, 2018), since they use extra shortcut paths to integrate word information into the hidden layer of LSTM. By concatenating, there is no shortcut pat. g max y i O i,y i  T y i1 ,y i(14)Given N manually labeled data (s j , y j ) N j1 , we minimize the sentencelevel negative loglikelihood loss to train the model  [#b40](Zhang and Yang, 2018).L   j log(p(y j s j ))(15)For OntoNotes, we use the same training, developme. lready been split, and we don't change them. We summarize the datasets in Table 1. Implementation Details. We utilize the character and word embeddings used in [#b40](Zhang and Yang, 2018), both of which are pretrained on Chinese GigaWord using word2vec model. Following [#b40](Zhang and Yang, 2018)r. s. We utilize the character and word embeddings used in [#b40](Zhang and Yang, 2018), both of which are pretrained on Chinese GigaWord using word2vec model. Following [#b40](Zhang and Yang, 2018), we use the word embedding dictionary as Lexicon D in our model. For characters and words that do not appear in the pretrained embeddings, w. ot_2"3 . When training the model, character embeddings and word embeddings are updated along with other parameters.For hyperparameter configurations, we mostly refer to the settings in [#b40](Zhang and Yang, 2018). We set both character embedding size and word embedding size to 50. The dimensionality of each unidirectional multiinput LSTM hidden state. eddings.The first two rows in the second block show the performance of the lattice model and characterbased model. The character baseline denotes the original characterbased BiLSTMCRF model. [#b40]Zhang and Yang (2018) propose a lattice LSTM to exploit word information in character sequence, giving the F1 score of 73.88. Compared with the character baseline. 41"Zhou et al. (2013) 91.86 88.75 90.28 Dong et al. (2016) 91.28 90.62 90.95 Cao et al. (2018) 91.73 89.58 90.64 Lattice [#b40](Zhang and Yang, 2018)   approach to integrating word information is more reasonable than lattice model. M. d word embeddings.Resume. Table 5 shows the results on Chinese Resume dataset. Consistent with the previous results, our models outperform lattice model [#b40](Zhang and Yang, 2018). The above experimental results strongly verify that our method to utilize word information is more effective than the lattice model.. ns1.0"EfficiencyTo further explore the efficiency of our model, we conduct some comparative experiments on training time and convergence speed. The lattice model proposed in [#b40](Zhang and Yang, 2018) is our principal comparison object, since it also utilizes the word information in character sequence. Our model is an extension of the char. labelResults on Weibo NER are the most common methods[#b40]Zhang and Yang, 2018) 94.81 94.11 94.46 Character baseline 93.26 93.44 93.35 WCLSTM  shortest 94.97 94.91 94.94 WCLSTM  longest 95.27 95.15 95.21 WCLSTM  ave </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> combining discrete and neural features for sequence labeling </p><p> The first block in Table 2 are the results of wordbased models (Wang et al., 2013Che et al., 2013[#b34]Yang et al., 2016). By using goldstandard segmentation and external labeled data, all of them achieve good performance. But the only resource used in our model ar </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> named entity recognition for question answering </p><p> luding Information Retrieval (Virga and Khudanpur, 2003), Relationship Extraction (Miwa and Bansal, 2016), Question Answering [#b23](Moll et al., 2006). The main task of NER is to identify named entities such as person, location, organization, etc. in given text. Various methods have been prop </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> named entity recognition for question answering </p><p> luding Information Retrieval (Virga and Khudanpur, 2003), Relationship Extraction (Miwa and Bansal, 2016), Question Answering [#b23](Moll et al., 2006). The main task of NER is to identify named entities such as person, location, organization, etc. in given text. Various methods have been prop </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> natural language processing (almost) from scratch </p><p> ref propose one of the first wordbased models for NER, with feature constructed from orthographic features, dictionaries and lexicons (Yadav and Bethard, 2018). [#b6]Collobert et al. (2011) replace the handcrafted features with word embeddings. Huang et al. (2015) propose a BiLSTMCRF model </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> word segmentation and named entity recognition for sighan bakeoff3 </p><p> ement in F1 score, which proves the effectiveness of our way to integrating word information. Compared with lattice model, all of our models achieve better results, which shows that our Models P R F1 [#b39]Zhang et al. (2006) 92.20 90.18 91.18 Zhou et al. (2013) 91.86 88.75 90.28 Dong et al. (2016)r. ation is more reasonable than lattice model. MSRA.Table 3 shows the results on MSRA dataset. [#b39]Zhang et al. (2006) and Zhou et al. (2013) use the statistical model with rich handcrafted features. ref type"bibr" target </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> end-to-end sequence labeling via bi-directional lstm-cnns-crf </p><p> et al. (2011) replace the handcrafted features with word embeddings. Huang et al. (2015) propose a BiLSTMCRF model for NER and achieves good performance. [#b21]Ma and Hovy (2016) and Chiu and Nichols (2016) use CNN to capture spelling characteristics and L </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> named entity recognition with bilingual constraints </p><p> t"b40"(Zhang and Yang, 2018).L   j log(p(y j s j ))(15)For OntoNotes, we use the same training, development and test splits as [#b1](Che et al., 2013). For other datasets which have already been split, and we don't change them. We summarize the datasets in Table ref type"table" target"tab_0". a sequence of character without any segmentation.The first block in Table 2 are the results of wordbased models (Wang et al., 2013[#b1]Che et al., 2013Yang et al., 2016). By using goldstandard segmentation and external labeled data, all of them achieve good pe </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> end-to-end relation extraction using lstms on sequences and tree structures </p><p> ionName Entity Recognition(NER) is a basic task of many NLP systems including Information Retrieval (Virga and Khudanpur, 2003), Relationship Extraction [#b22](Miwa and Bansal, 2016), Question Answering (Moll et al., 2006). The main task of NER is to identify named entities such as p </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> adversarial transfer learning for chinese named entity recognition with selfattention mechanism </p><p> 17Zhang et al., 2018), Peng and Dredze (2016) first proposed to jointly train Chinese NER with Chinese word segmentation(CWS) task. [#b0]Cao et al. (2018) apply adversarial transfer learning framework to integrate the taskshared word boundary information into Chinese NER task. Another way to obtain. t"b39"Zhang et al. (2006) 92.20 90.18 91.18 Zhou et al. (2013) 91.86 88.75 90.28 Dong et al. (2016) 91.28 90.62 90.95 [#b0]Cao et al. (2018) 91.73 89.58 90.64 Lattice (Zhang and Yang, 2018)   approach to integrating word information is more reasonabl. target"b41"Zhou et al. (2013) use the statistical model with rich handcrafted features. Dong et al. (2016) exploit radical features in Chinese character. [#b0]Cao et al. (2018) joint train Chinese NER task with Chinese word segmentation, in which adversarial learning and selfattention mechanism are applied for better perf. We can see that WCLSTM model with longest word first strategy achieves new stateoftheart performance. Multitask learning (Peng andDredze, 2015, 2016[#b0]Cao et al., 2018) and semisupervised learning (Sun and He, 2017He and Sun, 2017)   for W </p>
<p> An Encoding Strategy Based Word-Character LSTM for Chinese NER </p><p> combining discrete and neural features for sequence labeling </p><p> The first block in Table 2 are the results of wordbased models (Wang et al., 2013Che et al., 2013[#b34]Yang et al., 2016). By using goldstandard segmentation and external labeled data, all of them achieve good performance. But the only resource used in our model ar </p>
<p> higher-order network representation learning </p><p> biological network comparison using graphlet degree distribution </p><p> or learning such higherorder embeddings based on network motifs. The term motif is used generally and may refer to graphlets or orbits (graphlet automorphisms) [[#b5]]. The HONE framework expresses a general family of embedding methods based on a set of motifbased matrices and their powers. In this work, we investigate HONE va. have only one hyperparameter, namely, the number of steps K which is selected automatically via a grid search over K ? 1, 2, 3, 4 using 10 of the labeled data. We use all 24 node connected orbits [#b5][6] and set D ?  16 for the local motif embeddings. All methods use logistic regression (LR) with an L2 penalty. The model is selected using 10fold crossvalidati </p>
<p> higher-order network representation learning </p><p> role discovery in networks </p><p> ch as hubs, starcenters, staredge nodes, nearcliques or nodes that act as bridges to different regions of the graph. Intuitively, two nodes belong to the same role if they are structurally similar [#b7][8]. Many network representation learning methods (including randomwalk based methods such as node2vec [4]) seek to capture the notion of structural similarity (ro. al similarity (roles) [8] by defining node similarity locally based on neighborhood properties andor proximity (e.g., near one another in the graph). However, such methods are insufficient for roles [#b7][8] as they fail to capture the higherorder connectivity patterns of a node. For instance, instead of representing hub nodes in a similar fashion, methods using ra </p>
<p> higher-order network representation learning </p><p> the network data repository with interactive graph analytics and visualization </p><p> egression (LR) with an L2 penalty. The model is selected using 10fold crossvalidation on 10 of the labeled data. Experiments are repeated for 10 random seed initializations. Data was obtained from [#b6][7].We evaluate the HONE variants for link prediction. Given a partially observed graph G with a fraction of missing edges, the link prediction task is to pr </p>
<p> higher-order network representation learning </p><p> leveraging social media networks for classification </p><p>  </p>
<p> higher-order network representation learning </p><p> leveraging social media networks for classification </p><p>  </p>
<p> higher-order network representation learning </p><p> deepwalk: online learning of social representations </p><p> erform a grid search over p, q ? 0.25, 0.5, 1, 2, 4 as mentioned in [4]. All other hyperparameters for node2vec [4], DeepWalk [#b4][5], and LINE [9] correspond to those mentioned in [4]. In contrast, the HONE variants have </p>
<p> higher-order network representation learning </p><p> deepwalk: online learning of social representations </p><p> erform a grid search over p, q ? 0.25, 0.5, 1, 2, 4 as mentioned in [4]. All other hyperparameters for node2vec [4], DeepWalk [#b4][5], and LINE [9] correspond to those mentioned in [4]. In contrast, the HONE variants have </p>
<p> higher-order network representation learning </p><p> deepwalk: online learning of social representations </p><p> erform a grid search over p, q ? 0.25, 0.5, 1, 2, 4 as mentioned in [4]. All other hyperparameters for node2vec [4], DeepWalk [#b4][5], and LINE [9] correspond to those mentioned in [4]. In contrast, the HONE variants have </p>
<p> higher-order network representation learning </p><p> grarep: learning graph representations with global structural information </p><p>  </p>
<p> higher-order network representation learning </p><p> deepwalk: online learning of social representations </p><p> erform a grid search over p, q ? 0.25, 0.5, 1, 2, 4 as mentioned in [4]. All other hyperparameters for node2vec [4], DeepWalk [#b4][5], and LINE [9] correspond to those mentioned in [4]. In contrast, the HONE variants have </p>
<p> higher-order network representation learning </p><p> deepwalk: online learning of social representations </p><p> erform a grid search over p, q ? 0.25, 0.5, 1, 2, 4 as mentioned in [4]. All other hyperparameters for node2vec [4], DeepWalk [#b4][5], and LINE [9] correspond to those mentioned in [4]. In contrast, the HONE variants have </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> learning a hierarchical embedding model for personalized product search </p><p> at the longterm user preference is stable yet in fact, it changes over time slightly and slowly []. Recently, Ai et al. [#b0][1] have presented a personalized product search method, which falls into the second category. They modeled the longterm user preference through a latent space via. nce, the user's personal preference Attentive Long ShortTerm Preference Modeling for Personalized Product Search 195 for products is also critical to persuade users to purchase. Recently, Ai et al. [#b0][1] proposed a personalized product search model and took into consideration the users' preference. They highlighted the fact that the purchasing behavior can be hi. product is to use a producer's name, a brand or a set of terms that describe the category of the product as the query in retrieval. Based on this observation and following the strategy of References [#b0][], for each product a user purchased, we extracted the corresponding search query from the categories to which the product. two categories (1) traditional methods based on bagofwords representations, such as Query Likelihood Model [69] and Extended Query Likelihood with User Models [#b0][1] and (2) representation learning approaches based on latent space modeling, such as Latent Semantic Entity [59] and Hierarch. 0"[1] and (2) representation learning approaches based on latent space modeling, such as Latent Semantic Entity [59] and Hierarchical Embedding Model (HEM) [#b0][1]. It is worth noting that the recently proposed HEM is the stateoftheart method for personalized product search. We introduced these models in the following.. ested different values from 2,000 to 10,000 with a step size of 4,000. Extended Query Likelihood with User Models (UQL). This model is first introduced to the personalized product search by Ai et al. [#b0][1]. Specifically, let U be the set of the most frequent words 11 of reviews submitted by the user u, and then the likelihoo.  and for the ngram window size n, we tuned it exponentially2 i  2 ? i ? 4.Hierarchical Embedding Model (HEM). This model (HEM) proposed in Reference [#b0][1] is the stateoftheart approach for the personalized product search. It extends LSE [59] by adding the element of user pre </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> neupl: attention-based semantic matching and pair-linking for entity disambiguation </p><p> pe"bibr" target"b66"67], machine translation [2] and information retrieval [[#b46]]. A survey on the attention mechanism on those domain is out of the scope of this article. Here we only focus on the att </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> applying collaborative filtering techniques to movie search for better ranking and browsing </p><p> d ALSTP model yields better performance as compared to several stateoftheart methods. It is worth mentioning that our model is applicable to many other scenarios, such as personalized movie search [#b44][45] and academic article search [57].In summary, our main contributions of this article are threefold? We pres </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> deeprank: a new deep architecture for relevance ranking in information retrieval </p><p> o model three key factors of relevance matching. Nevertheless, the proposed model failed to explicitly model the relevance generation process and capture the important IR characteristics. Pang et al. [#b41][42] extended the method in Reference [22] to better capture the intrinsic relevance and simulate the human judgment process. </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> learning latent vector spaces for product search </p><p> e frequently and drastically.Traditional approaches to product search [17][18][19][#b58]59] often employ simple matching between the queries and products without harnessing the user's specific attributes. They hardly characterize the user specificity,. f by using representation learning techniques (e.g., word2vec []). Gysel et al. [#b58][59] introduced a latent semantic entity model to learn the distributed representations of words and entities (i.e., products) to solve the semantic mismatching pr. ct search model and took into consideration the users' preference. They highlighted the fact that the purchasing behavior can be highly personal in online shopping and extended the model in Reference [#b58][59] by mapping the user into the same latent space with the query and product. Concurrently, there is another work [23] aimin. brand or a set of terms that describe the category of the product as the query in retrieval. Based on this observation and following the strategy of References [[#b58]], for each product a user purchased, we extracted the corresponding search query from the categories to which the product belongs. The extraction of the textual.  and Extended Query Likelihood with User Models [1] and (2) representation learning approaches based on latent space modeling, such as Latent Semantic Entity [#b58][59] and Hierarchical Embedding Model (HEM) [1]. It is worth noting that the recently proposed HEM is the stateoftheart meth. U in the search. We searched ? in [ ] with a step size of 0.2. When ?  1, it becomes the same as the QL method. Latent Semantic Entity (LSE). This method is specially designed for product search [#b58][59]. It maps words and products into the same latent space and learns a mapping function f LS E between them byf LS E (s)  tanh. Hierarchical Embedding Model (HEM). This model (HEM) proposed in Reference [1] is the stateoftheart approach for the personalized product search. It extends LSE [#b58][59] by adding the element of user preference to the product search. Similar to UQL, HEM also uses a coefficient to control the weight between the query model q an </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> mining long-term search history to improve search accuracy </p><p> ding purchased products.Attentive Long ShortTerm Preference Modeling for Personalized Product Search 193 search model. Methods in the second category [[#b55]] model the longterm user preference based on user's complete browsing behaviors, yet they suffer from two limitations. First, they do not fully exploit user's. licit feedback.Longterm profilebased approaches model the longterm user preference based on the user's overall search logs. Approaches in References [[#b55]] apply a probabilistic statistical language modeling technique to discover the relevant context of the current query from the search history. Richardson et al. </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> deep collaborative filtering via marginalized denoising auto-encoder </p><p> product search. In fact, deep learning has been successfully applied in recommender systems to model the user preference [[#b34]]. In particular, the attention mechanism is usually adopted in these systems to model the user's preference more accurately. Attention mechanisms have shown its </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> image-based recommendations on styles and substitutes </p><p> eviews, respectively. Besides, we selected four categories with different sizes Phones, Toys, Clothing, and Electronics. Following the strategy in References [[#b37]], we extracted the users' product purchasing behaviors based on their reviews, i.e., the products they reviewed are the ones they purchased. Our model uses the </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> distributed representations of sentences and documents </p><p> ll rate (detailed in Section 3.2.3). The main notations used in this article are summarized in Table 1.Query and Product Representation. The PVDM model [#b29][30] is adopted for the latent vector representation learning of queries and products. PVDM is an unsupervised method to learn the continuous distributed vector r </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> probabilistic models for personalizing web search </p><p> analyzing the immediate contexts and implicit feedback.Longterm profilebased approaches model the longterm user preference based on the user's overall search logs. Approaches in References [#b53][] apply a probabilistic statistical language modeling technique to discover the relevant context of the current query fr </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> attentive collaborative filtering: multimedia recommendation with item-and component-level attention </p><p> ef, visual question answering [], machine translation [2] and information retrieval [#b4][]. A survey on the attention mechanism on. del to the sessionbased recommendation. They explored a hybrid encoder with an attention mechanism to model user's sequential behaviors and capture their emphases in the current session. Chen et al. [#b4][5] proposed a twolevel attention mechanism (i.e., itemand componentlevel) for the multimedia recommendation. Based on this, a userbased collaborative filtering </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> attentive collaborative filtering: multimedia recommendation with item-and component-level attention </p><p> ef, visual question answering [], machine translation [2] and information retrieval [#b4][]. A survey on the attention mechanism on. del to the sessionbased recommendation. They explored a hybrid encoder with an attention mechanism to model user's sequential behaviors and capture their emphases in the current session. Chen et al. [#b4][5] proposed a twolevel attention mechanism (i.e., itemand componentlevel) for the multimedia recommendation. Based on this, a userbased collaborative filtering </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> attentional factorization machines: learning the weight of feature interactions via attention networks </p><p> ne translation [2] and information retrieval [[#b63]]. A survey on the attention mechanism on those domain is out of the scope of this article. Here we only focus on the attention mechanism on user preference mode. mmendation. Based on this, a userbased collaborative filtering approach to modeling user preference on both the itemlevel and componentlevel is seamlessly applied on implicit feedback. Xiao et al. [#b63][64] improved Factorization Machine (FM) by discriminating the importance of different feature interactions.In this article, we apply deep learning techniqu </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> understanding the difficulty of training deep feedforward neural networks </p><p> eported the final results on the testing set based on the optimal parameter settings.Parameter Settings. In the training procedure of ALSTP, the parameters are initialized by the xavier method [#b19][20] and then optimized with the standard Stochastic Gradient Descent (SGD) with the momentum value 0.9. The layers of GRU is fixed to 1, the learning rate is tune </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> learning about the world through long-term query logs </p><p> 56] apply a probabilistic statistical language modeling technique to discover the relevant context of the current query from the search history. Richardson et al. [#b48][49] analyzed the longterm query logs to learn more about the user behavior. Matthijs et al. [36] adopted NLP techniques, suc </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> start from scratch: towards automatically identifying, modeling, and naming visual attributes </p><p> nd obtain better fusion features, we refer to Deep Neural Networks (DNNs), which introduces multilayer of nonlinear interactions and has been proven to be very effective in the feature fusion tasks [#b69][70]. Specifically, the fully connected layers arec 1  ? (W 1 c  b 1 ), c 2  ? (W 2 c 1  b 2 ), . . . . . . , c L  ? (W L c L </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> using argumentation to retrieve articles with similar citations: an inquiry into improving related articles search in the medline digital library </p><p> ftheart methods. It is worth mentioning that our model is applicable to many other scenarios, such as personalized movie search [45] and academic article search [#b56][57].In summary, our main contributions of this article are threefold? We present a neural network model for personalized product search by jointly </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> ask, attend and answer: exploring question-guided spatial attention for visual question answering </p><p> ly. Attention mechanisms have shown its efficiency in various tasks such as image captioning [], visual question answering [#b64][], machine translation [2] and information retrieval [ </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> a session based personalized search using an ontological user profile </p><p> e is the most related subdirection to our work, and it can be roughly divided into two categories shortterm sessionbased 2 and longterm profilebased web search. Approaches in the first category [#b14][] capture the shortterm user preference from search sessions. Nevertheless, dif. pe"bibr" target"b54"[55] used temporal closeness and probabilistic similarities between queries to determine the duration of a session Daoud et al. [[#b14]] leveraged a predefined ontology of semantic concepts to construct the shortterm user profile methods in References [58, </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> stacked attention networks for image question answering </p><p> fficiency in various tasks such as image captioning [], visual question answering [[#b66]], machine translation [2] and information retrieval [5,34 </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> aspect-aware latent factor model: rating prediction with ratings and reviews </p><p> ine review platforms in recent years, researchers have attempted to extract information from reviews to represent products [[#b9]] by using representation learning techniques (e.g., word2vec [32,33,ref type"bibr" ta </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> a session-based search engine </p><p> to two categories shortterm sessionbased 2 and longterm profilebased web search. Approaches in the first category [[#b54]] capture the shortterm user preference from search sessions. Nevertheless, different from the web search whereby a session often contains plenty of queries and. defined as a session. It involves two important problems, namely, how to determine the duration of a session and how to learn the user preference in a session. To solve these problems, Sriram et al. [#b54][55] used temporal closeness and probabilistic similarities between queries to determine the duration of a session Daoud et al. [14 </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> a neural click model for web search </p><p> 1"[42] extended the method in Reference [22] to better capture the intrinsic relevance and simulate the human judgment process. In addition, Borisov et al. [#b3][4] introduced a neural click model to better understand the user browsing behaviour for the web search.Deep Learning in Recommendation. However, the aforeme </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> a study of smoothing methods for language models applied to information retrieval </p><p> STP model with a logistic regression based method and different retrieval approaches from two categories (1) traditional methods based on bagofwords representations, such as Query Likelihood Model [#b68][69] and Extended Query Likelihood with User Models [1] and (2) representation learning approaches based on latent space modeli. method is a language modeling approach. It first estimates a language model for each document, and then ranks the documents by the likelihood of generating the query according to the estimated model [#b68][69]. Formally, given a query Q, the retrieval score of a document D is defined asP QL (Q D)  w ?Q lo? t f w, D  ?P (w C) D </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> convolutional neural network architectures for matching natural language sentences </p><p> get"b52"[53] introduced a convolutional neural network (CNN) to capture the finegrained contextual structures of entities (queries and documents). Other semantic matching methods like ARC1 [#b26][27], ARC2 [#b26][27], MatchSRNN [60], and MatchPyramid [41,. neural network (CNN) to capture the finegrained contextual structures of entities (queries and documents). Other semantic matching methods like ARC1 [#b26][27], ARC2 [#b26][27], MatchSRNN [60], and MatchPyramid [] also </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> ask, attend and answer: exploring question-guided spatial attention for visual question answering </p><p> ly. Attention mechanisms have shown its efficiency in various tasks such as image captioning [], visual question answering [#b64][], machine translation [2] and information retrieval [ </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> a study on the impact of product images on user clicks for online shopping </p><p> ch click prediction and purchase prediction tasks. In view of clicks providing a strong signal of a user's interest in an item, the methods in the first line [[#b20]] focus on the click prediction of ecomm. e, Yu et al. [68] proposed a Latent Dirichlet Allocation (LDA) based method for diversified product search. Approaches in [[#b20]] analyze the impact of images on user clicks. Recently, a challenge track named "Personalized ECommerce Search Challenge" was sponsored by CIKM Cup 2016 to pro </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> ask, attend and answer: exploring question-guided spatial attention for visual question answering </p><p> ly. Attention mechanisms have shown its efficiency in various tasks such as image captioning [], visual question answering [#b64][], machine translation [2] and information retrieval [ </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> learning deep structured semantic models for web search using clickthrough data </p><p> queries and products. The basic idea under this category is that they first process the text of both the queries and documents, and then build the interaction between them. For example, Huang et al. [#b27][28] leveraged a deep neural network (DNN) to project the queries and documents into a common lowdimensional space, and then calculate the relevance of each docum </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> image-based recommendations on styles and substitutes </p><p> eviews, respectively. Besides, we selected four categories with different sizes Phones, Toys, Clothing, and Electronics. Following the strategy in References [[#b37]], we extracted the users' product purchasing behaviors based on their reviews, i.e., the products they reviewed are the ones they purchased. Our model uses the </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> multi-modal preference modeling for product search </p><p> e shopping and extended the model in Reference [59] by mapping the user into the same latent space with the query and product. Concurrently, there is another work [#b22][23] aiming to combine the visual preference and textual preference for product search. Nevertheless, they both ignored the shortterm user preference and assumed </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> emphasizing temporal-based user profile modeling in the context of session search </p><p> r work, and it can be roughly divided into two categories shortterm sessionbased 2 and longterm profilebased web search. Approaches in the first category [[#b28]] capture the shortterm user preference from search sessions. Nevertheless, different from the web search whereby a sess. o sparse to train a good personalized 1 httpswww.amazon.com. 2 A session comprises a set of previous interactions containing past submitted queries and clicked records within a specific time limit [#b28][29]. 3 Pairs of queries and the corresponding purchased products.Attentive Long ShortTerm Preference Modeling for Personalized Product Search 193 search </p>
<p> attentive long short-term preference modeling for personalized product search </p><p> match-srnn: modeling the recursive matching structure with spatial rnn </p><p> xtual structures of entities (queries and documents). Other semantic matching methods like ARC1 [27], ARC2 [27], MatchSRNN [#b59][60], and MatchPyramid [] also share the similar idea. Guo et al. ref type"bibr" t </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> sequence transduction with recurrent neural networks </p><p> ding the neural transducer [11], the recurrent neural aligner (RNA) [12], and the recurrent neural network transducer (RNNT) [#b12][]. In particular, these architectures allow the output to be decoded as soon as the first input is encoded, without intr. r example, in our previous work [15] we evaluated a number of endtoend models including attentionbased models [7] and RNNT [#b12][] trained on 12,500 hours of transcribed training data although endtoend approaches were found to be comparable to a. ion. A concluding summary and acknowledgements are in Section 7 and Section 8. RNNTRANSDUCERThe RNNT was proposed by Graves [#b12][13] as an extension to the connectionist temporal classification (CTC) [17] approach for sequence labeling tasks where the al. dent of previous output labels y t   y j x, for t lt j.The RNNT model, depicted in Figure 1, consists of an encoder (referred to as the transcription network in [#b12][13]), a prediction network and a joint network as described in [15], the RNNT model can be compared to other encoderdecode. , h dec u )(6)We use the same form for f joint as described in [14]. The entire network is trained jointly to optimize the RNNT loss [#b12][13], which marginalizes over all alignments of target labels with blanks as in CTC, and is computed using dynamic programming.During each step of inference. label is a blank or nonblank. Inference is terminated when blank is output at the last frame, T .During inference, the most likely label sequence is computed using beam search as described in [#b12][13], with a minor alteration which was found to make the algorithm less computationally intensive without degrading performance we skip summation over prefixes i. [13], with a minor alteration which was found to make the algorithm less computationally intensive without degrading performance we skip summation over prefixes in pref(y) (see Algorithm 1 in [#b12][13]), unless multiple hypotheses are identical.Note that unlike other streaming encoderdecoder architectures such as RNA [1 </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> multi-accent speech recognition with hierarchical grapheme based models </p><p> ies' of CTC losses at various depths in the encoder network. With hierarchicalCTC the encoder networks are trained with multiple simultaneous CTC losses which was beneficial for grapheme recognition [#b21][22]. After pretraining all CTC losses and additional weights associated with generating softmax probabilities are discarded. For the wordpiece models which have </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> speech recognition with deep recurrent neural networks </p><p> r" target"b10"[11], the recurrent neural aligner (RNA) [12], and the recurrent neural network transducer (RNNT) [[#b13]]. In particular, these architectures allow the output to be decoded as soon as the first input is encoded, without introducing additional latency incurred when. "bibr" target"b14"[15] we evaluated a number of endtoend models including attentionbased models [7] and RNNT [[#b13]] trained on 12,500 hours of transcribed training data although endtoend approaches were found to be comparable to a stateoftheart contextdependent phone. ther the blank symbol or one of the output targets).z t,u  f joint (h enc t , h dec u )(6)We use the same form for f joint as described in [#b13][14]. The entire network is trained jointly to optimize the RNNT loss [13], which marginalizes over all alignments of target. twork parameters from pretrained models. It has been previously shown that initializing RNNT encoder parameters from a model trained with the CTC loss is beneficial for the phoneme recognition task [#b13][14]. We experimented with initializing encoder networks from models trained with the CTC loss and with initializing LSTM layer parameters in prediction networks f </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> continuous speech recognition </p><p> for conditional models that directly predict P (x), the likelihood is typically replaced with a scaled likelihood obtained by dividing the posterior with the prior, P (), in socalled hybrid models [#b0][1]. Deep recurrent neural networks with long shortterm memory (LSTM) cells [2] have recently been shown to be ideal for this t </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> graphemeto-phoneme conversion using long short-term memory recurrent neural networks </p><p> ibr" target"b4"5]. The pronunciation model, P (W ), is typically built from pronunciation dictionaries curated by expert human linguists, with backoff to a graphemetophoneme (G2P) model [#b5][6] for out of dictionary words. Finally, an Ngram model trained on text data may be used as a language model, P (W ).Recently, there has been considerable </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> multi-accent speech recognition with hierarchical grapheme based models </p><p> ies' of CTC losses at various depths in the encoder network. With hierarchicalCTC the encoder networks are trained with multiple simultaneous CTC losses which was beneficial for grapheme recognition [#b21][22]. After pretraining all CTC losses and additional weights associated with generating softmax probabilities are discarded. For the wordpiece models which have </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> graphemeto-phoneme conversion using long short-term memory recurrent neural networks </p><p> ibr" target"b4"5]. The pronunciation model, P (W ), is typically built from pronunciation dictionaries curated by expert human linguists, with backoff to a graphemetophoneme (G2P) model [#b5][6] for out of dictionary words. Finally, an Ngram model trained on text data may be used as a language model, P (W ).Recently, there has been considerable </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> optimizing expected word error rate via sampling for speech recognition </p><p> ed with sequence discriminative training as described in [5] and further improved with wordlevel editbased minimum Bayes risk (EMBR) proposed recently by Shannon [#b22][23]. Acoustic models are trained on a set of 22 million handtranscribed anonymized utterances extracted from Google US English voice traffic, which corresponds </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> an online sequence-to-sequence model using partial conditioning </p><p> decoded and thus these models cannot be used for realtime streaming speech recognition. Several streaming encoderdecoder architectures have been proposed previously, including the neural transducer [#b10][11], the recurrent neural aligner (RNA) [12], and the recurrent neural network transducer (RNNT) ref type"bibr" target"b. target"b12"[13]), unless multiple hypotheses are identical.Note that unlike other streaming encoderdecoder architectures such as RNA [12] and NT [#b10][11], the prediction network is not conditioned on the encoder output. This allows for the the pretraining of the decoder as a RNN language model on textonly dat </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> long shortterm memory based recurrent neural network architectures for large vocabulary speech recognition </p><p> ep recurrent neural networks with long shortterm memory (LSTM) cells [2] have recently been shown to be ideal for this task [[#b3]]. The pronunciation model, P (W ), is typically built from pronunciation dictionaries curated by expert human linguists, w </p>
<p> exploring architectures, data and units for streaming end-to-end speech recognition with rnn-transducer </p><p> long short-term memory </p><p> od obtained by dividing the posterior with the prior, P (), in socalled hybrid models [1]. Deep recurrent neural networks with long shortterm memory (LSTM) cells [#b1][2] have recently been shown to be ideal for this task [] </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> graph kernels </p><p> idze et al., 2009) takes hours to count graphlets on relatively small biological networks (i.e., few hundredsthousands of nodesedges) and uses such counts as features for graph classification [#b37](Vishwanathan, Schraudolph, Kondor and Borgwardt, 2010). Previous work showed that graphlet counting is computationally intensive since the number of possible ksu. s features for improving community detection (Schaeffer, 2007), role discovery (Rossi and Ahmed, 2015b), graph classification [#b37](Vishwanathan et al., 2010), and relational learning (Getoor and Taskar, 2007).We test the scalability of our proposed a. ype"bibr" target"b36"(Ugander, Backstrom and Kleinberg, 2013). Moreover, a variety of graph kernels have been proposed in machine learning (e.g., graphlet, subtree, and random walk kernels) [#b37](Vishwanathan et al., 2010Costa and De Grave, 2010Shervashidze et al., 2009) to bridge t. on counting all graphlets. However, a general limitation of most graph kernels (including the graphlet kernel) is that they scale poorly to large graphs with more than few hundredsthousands of nodes [#b37](Vishwanathan et al., 2010). Thus, our fast algorithms would speedup the computations of these methods and their related applications in graph modeling, similarity. be the function of protein graphs). We test our approach on protein graphs (Damp D collection of 1178 protein graphs) and chemical compound graphs (MUTAG collection of 188 chemical compound graphs) [#b37](Vishwanathan et al., 2010). We extract the graphlet features using Algorithm 2. Then, we learn a model using SVM (RBF kernel), and we use 10fold validation for e </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> motifs in evolving cooperative networks look like protein structure networks </p><p> ef to name a few. More recently, there has been an increased interest in exploring the role of graphlet analysis in computer networking (Feldman and Shavitt, 2008[#b12]Hales and Arteconi, 2008Becchetti, Boldi, Castillo and Gionis, 2008) (e.g., for web spam detection, analysis of peertopeer p </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> network motifs: simple building blocks of complex networks </p><p> d networks into small subgraph patterns of size k nodes. These patterns are called graphlets (Pr?ulj, Corneil and Jurisica, 2004). Graphlets (also known as motifs [#b25](Milo, ShenOrr, Itzkovitz, Kashtan, Chklovskii and Alon, 2002)) are defined as subgraph patterns recurring in realworld networks at frequencies that are statisti. Graphlets, Scalability, amp ApplicationsFrom social science to biology, graphlets have found numerous applications and were used as the building blocks of network analysis [#b25](Milo et al., 2002). In social science, graphlet analysis (typically known as ksubgraph census) is widely adopted in sociometric studies ref type"bibr" target". tpwww.teic.orgns1.0"BackgroundGraphlets are subgraph patterns recurring in realworld networks at frequencies that are significantly higher than those in random networks [#b25](Milo et al., 2002 g4 8 4node2star 0.33 2 1.0 1.00 0 1 2 2 1 2 g4 9 4node2edge 0.33 1 1.0 1.00 0 1 2 1 0 2 g4 10 4node1e. pg2 2 2nodeindependent 0.00 0 0.0 0.00 0 0 1 ? 0 2 Pr?ulj et al., 2004). Previous work showed that graphlets can be used to define universal classes of networks [#b25](Milo et al., 2002). Moreover, graphlets are at the heart and foundation of many network analysis tasks (e.g., network classification, network alignment, etc.) re </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> rage-a rapid graphlet enumerator for large networks </p><p> h experimentally on 300 networks from a variety of domains, such as biological, social, and technological domains. We compare our approach to the stateoftheart exact counting methods such as RAGE [#b21](Marcus and Shavitt, 2012), FANMOD (Wernicke and Rasche, 2006), and Orca (Ho?evar and Dem?ar, 2. (Marcus and Shavitt, 2012), FANMOD (Wernicke and Rasche, 2006), and Orca (Ho?evar and Dem?ar, 2014). We found that RAGE [#b21](Marcus and Shavitt, 2012) took 2400 seconds to count graphlets on a small 26k node graph, whereas our proposed method is 460x faster, taking only 0.01 seconds. We. o an edge and S max ? ?, as we show in Lemma 9 and 10. This is more efficient than O(V .? 3 ) given by (Shervashidze et al., 2009), and O(?.EE 2 ) given by [#b21](Marcus and Shavitt, 2012).  ExperimentsWe proceed by first demonstrating how fast our al. 2 takes only 15 seconds, and for large web graphs with nearly 8M edges, Algorithm 2 takes only 25 seconds. We compare the empirical runtime of Algorithm 2 to the stateoftheart baseline method RAGE [#b21](Marcus and Shavitt, 2012). For social and facebook networks, we observed that Algorithm 2 is on average 460x faster than RAGE. For all other networks, we observed </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> network motifs: simple building blocks of complex networks </p><p> d networks into small subgraph patterns of size k nodes. These patterns are called graphlets (Pr?ulj, Corneil and Jurisica, 2004). Graphlets (also known as motifs [#b25](Milo, ShenOrr, Itzkovitz, Kashtan, Chklovskii and Alon, 2002)) are defined as subgraph patterns recurring in realworld networks at frequencies that are statisti. Graphlets, Scalability, amp ApplicationsFrom social science to biology, graphlets have found numerous applications and were used as the building blocks of network analysis [#b25](Milo et al., 2002). In social science, graphlet analysis (typically known as ksubgraph census) is widely adopted in sociometric studies ref type"bibr" target". tpwww.teic.orgns1.0"BackgroundGraphlets are subgraph patterns recurring in realworld networks at frequencies that are significantly higher than those in random networks [#b25](Milo et al., 2002 g4 8 4node2star 0.33 2 1.0 1.00 0 1 2 2 1 2 g4 9 4node2edge 0.33 1 1.0 1.00 0 1 2 1 0 2 g4 10 4node1e. pg2 2 2nodeindependent 0.00 0 0.0 0.00 0 0 1 ? 0 2 Pr?ulj et al., 2004). Previous work showed that graphlets can be used to define universal classes of networks [#b25](Milo et al., 2002). Moreover, graphlets are at the heart and foundation of many network analysis tasks (e.g., network classification, network alignment, etc.) re </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> triad count statistics </p><p> rry significant information about the local network structure in a variety of domains (Holland and Leinhardt, 1976Faust, 2010[#b6]Frank, 1988). This is in contrast to global topological properties (e.g., diameter, degree distribution), where networks with similarexact global topological prope. l., 2002). In social science, graphlet analysis (typically known as ksubgraph census) is widely adopted in sociometric studies (Holland and Leinhardt, 1976[#b6]Frank, 1988). Much of the work in this vein focused on analyzing triadic tendencies as important structural features of social networks (e.g., transitivity or triad </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> collective dynamics of small-world networks </p><p> full graphlet decomposition).Figure 9 uses the interactive graphlet mining tool for realtime exploration of the brain neural network from C. Elegans [#b38](Watts and Strogatz, 1998). Additionally, the tool is also useful for exploring many other types of networks, e.g., a terrorist relationship network is shown in Fi </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> small graphs are reconstructible </p><p> et"b11"(Gross et al., 2013), states that an undirected graph G can be uniquely determined up to an isomorphism, from the set of all possible vertexdeleted subgraphs of G (i.e., G v  v?V ) [#b22](McKay, 1997). Verification of this conjecture for all possible graphs up to 6 vertices was carried by Kelly (Kelly, 1957), an. ref. Verification of this conjecture for all possible graphs up to 6 vertices was carried by Kelly (Kelly, 1957), and later was extended to up to 11 vertices by [#b22]McKay (McKay, 1997). Clearly, if two graphs are isomorphic (i.e., G ?  G ), then their graphlet frequencies would be the same (i.e., f k (G)  f k (G )), but the </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> finding and counting small induced subgraphs efficiently </p><p> g and machine learning tasks that would benefit from our approach. Much of the previous work focused on counting certain types of graphlets (e.g., only connected graphlets such as cliques and cycles) [#b18](Kloks, Kratsch and M?ller, 2000Wernicke and Rasche, 2006Ho?evar and Dem?ar, 2014). How </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> modeling interactome: scale-free or geometric? </p><p> n of networks is a widely used approach in network analysis to factorize the complex structure of realworld networks into small subgraph patterns of size k nodes. These patterns are called graphlets [#b27](Pr?ulj, Corneil and Jurisica, 2004). Graphlets (also known as motifs (Milo, ShenOrr, Itzkovitz, Kashtan, Chklovskii and Alon, 2002. ations as the basis for various social network theories (e.g., social balance, strength of weak ties, stability of ties, or trust (Granovetter, 1983)). In biology [#b27](Pr?ulj et al., 2004Milenkoviae and Pr?ulj, 2008), graphlets were widely used for protein function prediction ref type"bibr. 4 3nodeindependent 0.00 0 0.00 0.00 0 0 1 ? 0 3(k  2)Graphlets g2 1 edge 1.00 1 1.0 1.00 0 1 2 1 0 1g2 2 2nodeindependent 0.00 0 0.0 0.00 0 0 1 ? 0 2 [#b27]Pr?ulj et al., 2004). Previous work showed that graphlets can be used to define universal classes of networks (Milo et al., 2002)r. ks (Milo et al., 2002). Moreover, graphlets are at the heart and foundation of many network analysis tasks (e.g., network classification, network alignment, etc.) [#b27](Pr?ulj et al., 2004Milenkoviae and Pr?ulj, 2008Hayes, Sun and Pr?ulj, 2013). In this p. FD (i.e., graphlet frequency distribution) score pictorially in Figure 6 for all California schools. The GFD score is simply the normalized frequencies of graphlets of size k [#b27](Pr?ulj et al., 2004). In our case, we use k  4. The figure shows Caltech noticeably different than others, consistent with the results in ref type"bibr" target </p>
<p> graphlet decompsition: framework, algorithms, and applications </p><p> a congruence theorem for trees </p><p> ble vertexdeleted subgraphs of G (i.e., G v  v?V ) (McKay, 1997). Verification of this conjecture for all possible graphs up to 6 vertices was carried by Kelly [#b17](Kelly, 1957), and later was extended to up to 11 vertices by McKay (McKay, 1997). Clearly, if two graphs are isomorphic (i.e. </p>
<p> neural graph collaborative filtering </p><p> spectral collaborative filtering </p><p> [pos is CCS CONCEPTS] ghorder connectivities. Here we discuss existing recommendation methods that also employ graph convolution operations [[#b41]]. GCMC [29] applies the graph convolution network (GCN) [18] on useritem graph, howe. [pos is CCS CONCEPTS] raph convolution layers on itemitem graph for Pinterest image recommendation. As such, the CF effect is captured on the level of item relations, rather than the collective user behaviors. SpectralCF [#b41][42] proposes a spectral convolution operation to discover all possible connectivity between users and items in the spectral domain. Through the eigendecompositio. [pos is CCS CONCEPTS] nsidered. Hence one graph convolution layer, where the hidden dimension is set as the embedding size, is used as suggested in [29].We also tried SpectralCF [#b41][42] but found that the eigendecomposition leads to high time cost and resource cost, especially when the number of users and items is large. Hence, although it a </p>
<p> neural graph collaborative filtering </p><p> collaborative deep learning for recommender systems </p><p> [pos is CCS CONCEPTS] er product [20] collaborative deep learning extends the MF embedding function by integrating the deep representations learned from rich side information of items [#b29][30] neural collaborative filtering models replace the MF interaction function of inner product with nonlinear neural networks [14]. [pos is CCS CONCEPTS] roduct between them to predict an interaction. To enhance the embedding function, much effort has been devoted to incorporate side information like item content [[#b29]], social relations [33], item relations [36], user reviews ref type"bibr" target"b </p>
<p> neural graph collaborative filtering </p><p> bpr: bayesian personalized ranking from implicit feedback </p><p> [pos is CCS CONCEPTS] mbedding function with the descriptive features only (e.g., ID and attributes), without considering the useritem interactions which are only used to define the objective function for model training [#b25][]. As a result, when the embeddings are insufficient in capturing CF, the methods have to rely on the interaction functi. [pos is CCS CONCEPTS] Embedding LayerFollowing mainstream recommender models [[#b25]], we describe a user u (an item i) with an embedding vector e u  R d (e i  R d ), where d denotes the embedding size. This can be seen as building a parameter. [pos is CCS CONCEPTS] [14], are left to explore in the future work. OptimizationTo learn model parameters, we optimize the pairwise BPR loss [#b25][26], which has been intensively used in recommender systems [].It considers th. [pos is CCS CONCEPTS] 31"32] parameterize users and items by vectorized representations and reconstruct useritem interaction data based on model parameters. For example, MF [[#b25]] projects the ID of each user and item as an embedding vector, and conducts inner product between them to predict an interaction. To enhance the embedding funct. [pos is CCS CONCEPTS] test set. Baselines.To demonstrate the effectiveness, we compare our proposed NGCF with the following methods MF [#b25][26] This is matrix factorization optimized by the Bayesian personalized ranking (BPR) loss, which exploits the useritem direct interactions only as the target v </p>
<p> neural graph collaborative filtering </p><p> explainable reasoning over knowledge graphs for recommendation </p><p> [pos is CCS CONCEPTS] b32"[33], item relations [36], user reviews [3], and external knowledge graph [[#b33]]. While inner product can force user and item embeddings of an observed interaction close to each other, its linearity makes it insufficient to reveal the compl </p>
<p> neural graph collaborative filtering </p><p> graph convolutional matrix completion </p><p> [pos is CCS CONCEPTS] l information for propagation, and d  is the transformation size. Distinct from conventional graph convolution networks [[#b28]] that consider the contribution of e i only, here we additionally encode the interaction between e i and e u into the me. [pos is CCS CONCEPTS] ong representation ability, they usually suffer from overfitting. Dropout is an effective solution to prevent neural networks from overfitting. Following the prior work on graph convolutional network [#b28][29], we propose to adopt two dropout techniques in NGCF message dropout and node dropout. Message dropout randomly drops out the outgoing messages. Specifically,. [pos is CCS CONCEPTS] "formula_3"3)), we make NGCF effective in exploiting the CF signal in highorder connectivities. Here we discuss existing recommendation methods that also employ graph convolution operations [#b28][]. GCMC [#b28][29] applies the graph convolution. [pos is CCS CONCEPTS] g recommendation methods that also employ graph convolution operations [#b28][]. GCMC [#b28][29] applies the graph convolution network (GCN) [18] on useritem graph, however it only employs one convolutional layer to e. [pos is CCS CONCEPTS] m interaction graph. Especially, we employ two graph convolution layers as suggested in [41], and the hidden dimension is set equal to the embedding size.  GCMC [#b28][29] This model adopts GCN [18] encoder to generate the representations for users and items, where only the firstorder neigh. [pos is CCS CONCEPTS] entations for users and items, where only the firstorder neighbors are considered. Hence one graph convolution layer, where the hidden dimension is set as the embedding size, is used as suggested in [#b28][29].We also tried SpectralCF [42] but found that the eigendecomposition leads to high time cost and resource cost, es. [pos is CCS CONCEPTS] pectively. This emphasizes the significance of layeraggregation mechanism, which is consistent with [37].4.4.3 Effect of Dropout. Following the prior work [#b28][29], we employ node dropout and message dropout techniques to prevent NGCF from overfitting. Figure 5 plots the effect of. [pos is CCS CONCEPTS] t against not only the influence of particular   edges, but also the effect of nodes. Hence, node dropout is more effective than message dropout, which is consistent with the findings of prior effort [#b28][29]. We believe this is an interesting finding, which means that node dropout can be an effective strategy to address overfitting of graph neural networks.   </p>
<p> neural graph collaborative filtering </p><p> matrix factorization techniques for recommender systems </p><p> [pos is CCS CONCEPTS] hich reconstructs historical interactions based on the embeddings. For example, matrix factorization (MF) directly embeds useritem ID as an vector and models useritem interaction with inner product [#b19][20] collaborative deep learning extends the MF embedding function by integrating the deep representations learned from rich side information of items ref type". [pos is CCS CONCEPTS] b13"14,32] parameterize users and items by vectorized representations and reconstruct useritem interaction data based on model parameters. For example, MF [#b19][] projects the ID of each user and item as an embedding vector, and conducts inner product between them to predict an in </p>
<p> neural graph collaborative filtering </p><p> deep item-based collaborative filtering for top-n recommendation </p><p> [pos is CCS CONCEPTS] s"httpwww.teic.orgns1.0"2.2.1Firstorder Propagation. Intuitively, the interacted items provide direct evidence on a user's preference [[#b37]] analogously, the users that consume an item can be treated as the item's features and used to measure the collaborative similarity of two items. We build upon </p>
<p> neural graph collaborative filtering </p><p> convolutional neural networks on graphs with fast localized spectral filtering </p><p> [pos is CCS CONCEPTS] pwhere W 1 , W 2  R d  d are the trainable weight matrices to distill useful information for propagation, and d  is the transformation size. Distinct from conventional graph convolution networks [#b3][] that consider the contribution of e i on </p>
<p> neural graph collaborative filtering </p><p> collaborative memory network for recommendation systems </p><p> riments on three public benchmarks, demonstrating significant improvements over several stateoftheart models like HOPRec [39] and Collaborative Memory Network [#b4][5]. Further analysis verifies the importance of embedding propagation for learning better user and item representations, justifying the rationality and effectivene. t relevant with this work. Here we highlight the differences with our NGCF. Modelbased CF MethodsModern recommender systems [#b4][] parameterize users and items by vectorized representations and reconstruct user. ation of user and item embeddings to capture their nonlinear feature interactions. Especially, we employ twolayered plain architecture, where the dimension of each hidden layer keeps the same.  CMN [#b4][5] It is a stateoftheart memorybased model, where the user representation attentively combines the memory slots of neighboring users via the memory layers. No </p>
<p> neural graph collaborative filtering </p><p> modeling user exposure in recommendation </p><p> [pos is CCS CONCEPTS] cessible and vary in terms of domain, size, and sparsity. We summarize the statistics of three datasets in Table 1.Gowalla This is the checkin dataset [#b20][21] obtained from Gowalla, where users share their locations by checkingin. To ensure the quality of the dataset, we use the 10core setting ref type"bibr" tar </p>
<p> neural graph collaborative filtering </p><p> neural factorization machines for sparse predictive analytics </p><p> [pos is CCS CONCEPTS] ufficient to reveal the complex and nonlinear relationships between users and items []. Towards this end, recent efforts [#b10][] focus on exploiting deep learning tech. [pos is CCS CONCEPTS] d items is large. Hence, although it achieved promising performance in small datasets, we did not select it for comparison. For fair comparison, all methods optimize the BPR loss as shown in Equation [#b10](11). Parameter Settings.We implement our NGCF model in Tensorflow. The embedding size </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> semi-supervised classification with graph convolutional networks </p><p> long to the knowledge graph. Following this intuition, we develop an encoder model for entities in the relational graph and apply it to both tasks.Our entity classification model, similarly to [#b16]Kipf and Welling (2017), uses softmax classifiers at each node in the graph. The classifiers take node representations supplied by a relational graph convolutional. onal graph convolutional networksOur model is primarily motivated as an extension of GCNs that operate on local graph neighborhoods (Duvenaud et al. 2015[#b16]Kipf and Welling 2017) to largescale relational data. These and related methods such as graph neural networks (Scarselli et al. 200. of incoming edges. g m (, ) is typically chosen to be a (messagespecific) neural networklike function or simply a linear transformation g m (h i , h j )  W h j with a weight matrix W such as in [#b16]Kipf and Welling (2017). This type of transformation has been shown to be very effective at accumulating and encoding features from local, structured neighborhoods. ctured neighborhoods, and has led to significant improvements in areas such as graph classification (Duvenaud et al. 2015) and graphbased semisupervised learning [#b16](Kipf and Welling 2017).Motivated by these architectures, we define the following simple propagation model for calculating the forwardpass update of an ent. resentation, we map this onehot vector to a dense representation through a single linear transformation. While we only consider such a featureless approach in this work, we note that it was shown in [#b16]Kipf and Welling (2017) that it is possible for this class of models to make use of predefined feature vectors (e.g. a bagofwords description of a document assoc. on GCNs (Bruna et al. 2014Duvenaud et al. 2015Defferrard, Bresson, and Vandergheynst 2016[#b16]Kipf and Welling 2017) for largescale and highly multirelational data, characteristic of realistic knowledge bases.Early work in this area includes the gr </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> question answering over freebase with multi-column convolutional neural networks </p><p> efSeyler, Yahya, and Berberich 2015Hixon, Clark, and Hajishirzi 2015Bordes et al. 2015[#b7]Dong et al. 2015) and information retrieval (Kotov and Zhai 2012Dalton, Dietz, and Allan 2014 </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> convolutional networks on graphs for learning molecular fingerprints </p><p> v xmlns"httpwww.teic.orgns1.0"Relational graph convolutional networksOur model is primarily motivated as an extension of GCNs that operate on local graph neighborhoods [#b8](Duvenaud et al. 2015Kipf and Welling 2017) to largescale relational data. These and related methods such as graph neural net. formation has been shown to be very effective at accumulating and encoding features from local, structured neighborhoods, and has led to significant improvements in areas such as graph classification [#b8](Duvenaud et al. 2015) and graphbased semisupervised learning (Kipf and Welling 2017).Motivated by these architectures. closely related to a number of works in the area of neural networks on graphs. It is primarily motivated as an adaption of previous work on GCNs (Bruna et al. 2014[#b8]Duvenaud et al. 2015Defferrard, Bresson, and Vandergheynst 2016Kipf and Welling 2017) for </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> neural message passing for quantum chemistry </p><p> and related methods such as graph neural networks (Scarselli et al. 2009) can be understood as special cases of a simple differentiable messagepassing framework [#b10](Gilmer et al. 2017)h (l1) i   mMi g m (h (l) i , h (l) j ) ,(1)where hformula xmlid"formul. as recently received considerable attention. We can roughly classify previous work into (1) methods creating auxiliary triples, which are then added to the learning objective of a factorization model [#b10](Guu, Miller, and Liang 2015GarciaDuran, Bordes, and Usunier 2015) (2) approaches using paths (or walks) as features when pr. ef type"bibr" target"b21"(Pham et al. 2017), both of which utilize gating mechanisms to facilitate optimization. RGCNs can further be seen as a subclass of message passing neural networks [#b10](Gilmer et al. 2017), which encompass a number of previous neural models for graphs, including GCNs, under a differentiable message passing interpretation.di. (e.g. born in inv). Note that this represents a simplification of the message passing neural network proposed in[#b10](Gilmer et al. 2017) that suffices to include the aforementioned models as special cases. note xmlns"httpwww.teic.orgns1.0" place"foot" n"3" xm </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> typed tensor decomposition of knowledge bases for relation extraction </p><p> een proposed and studied in the context of SRL, including both (bi)linear and nonlinear ones (e.g., (Bordes et al. 2013Socher et al. 2013[#b3]Chang et al. 2014Nickel, Rosasco, and Poggio 2015Trouillon et al. 2016)). Many of these approaches can </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> learning knowledge graphs for question answering through conversational dialog </p><p> including question answering (Yao and Van Durme 2014Bao et al. 2014Seyler, Yahya, and Berberich 2015[#b13]Hixon, Clark, and Hajishirzi 2015Bordes et al. 2015Dong et al. 2015) and information retr </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> esdrank: connecting query and documents through external semi-structured data </p><p> type"bibr" target"b7"Dong et al. 2015) and information retrieval (Kotov and Zhai 2012Dalton, Dietz, and Allan 2014[#b29]Xiong and Callan 2015b[#b29]2015a). Even the largest knowledge bases (e.g. DBPedia, Wikidata or Yago), despite enormous effort inve. ation retrieval (Kotov and Zhai 2012Dalton, Dietz, and Allan 2014[#b29]Xiong and Callan 2015b[#b29]2015a). Even the largest knowledge bases (e.g. DBPedia, Wikidata or Yago), despite enormous effort invested in their maintenance, are incomplete, and the lack of c </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> neural message passing for quantum chemistry </p><p> and related methods such as graph neural networks (Scarselli et al. 2009) can be understood as special cases of a simple differentiable messagepassing framework [#b10](Gilmer et al. 2017)h (l1) i   mMi g m (h (l) i , h (l) j ) ,(1)where hformula xmlid"formul. as recently received considerable attention. We can roughly classify previous work into (1) methods creating auxiliary triples, which are then added to the learning objective of a factorization model [#b10](Guu, Miller, and Liang 2015GarciaDuran, Bordes, and Usunier 2015) (2) approaches using paths (or walks) as features when pr. ef type"bibr" target"b21"(Pham et al. 2017), both of which utilize gating mechanisms to facilitate optimization. RGCNs can further be seen as a subclass of message passing neural networks [#b10](Gilmer et al. 2017), which encompass a number of previous neural models for graphs, including GCNs, under a differentiable message passing interpretation.di. (e.g. born in inv). Note that this represents a simplification of the message passing neural network proposed in[#b10](Gilmer et al. 2017) that suffices to include the aforementioned models as special cases. note xmlns"httpwww.teic.orgns1.0" place"foot" n"3" xm </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> typed tensor decomposition of knowledge bases for relation extraction </p><p> een proposed and studied in the context of SRL, including both (bi)linear and nonlinear ones (e.g., (Bordes et al. 2013Socher et al. 2013[#b3]Chang et al. 2014Nickel, Rosasco, and Poggio 2015Trouillon et al. 2016)). Many of these approaches can </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> question answering over freebase with multi-column convolutional neural networks </p><p> efSeyler, Yahya, and Berberich 2015Hixon, Clark, and Hajishirzi 2015Bordes et al. 2015[#b7]Dong et al. 2015) and information retrieval (Kotov and Zhai 2012Dalton, Dietz, and Allan 2014 </p>
<p> Modeling Relational Data with Graph Convolutional Networks </p><p> typed tensor decomposition of knowledge bases for relation extraction </p><p> een proposed and studied in the context of SRL, including both (bi)linear and nonlinear ones (e.g., (Bordes et al. 2013Socher et al. 2013[#b3]Chang et al. 2014Nickel, Rosasco, and Poggio 2015Trouillon et al. 2016)). Many of these approaches can </p>
<p> counterminer: mining big performance data from hardware counters </p><p> server engineering insights for large-scale online services </p><p> get"b15"[15] [18], compiler optimization [19] [21], architecture optimization [#b22][22], and many more. A number of programable performance measurement tools have therefore been developed, including PAPI [23],. employ hardware counters and other tools to analyze how largescale online services use resources in data centers and then they provide several insights for server architecture design in data centers [#b22][22]. Chen et al. leveraged hardwareevent sampling to generate edge profiles to perform feedbackdirected optimization for application runtime performance ref ty </p>
<p> counterminer: mining big performance data from hardware counters </p><p> user-level scheduling on numa multicore systems under linux </p><p> about the performance of computer systems. Therefore, performance counter based analysis is applied in a wide range of applications, including task scheduling [5], [#b6][6], workload characterization [7] [14], performance optimization of applications ref typ. ef type"bibr" target"b5"[5]. Blagodurov et al. developed a user level scheduling algorithm for NUMA multicore systems under Linux by analyzing information from hardware performance counters [#b6][6]. By observing the CPI (Cycle Per Instruction) collected from hardware counters, Zhang et al. proposed a CPU performance isolation strategy for shared compute cl </p>
<p> counterminer: mining big performance data from hardware counters </p><p> deep-dive analysis of the data analytics workload in cloudsuite </p><p> roup of scaleout workloads and released the CloudSuite [9]. Later on, Yasin et al. performed a deep characterization by using hardware counters for the CloudSuite [#b11][11], [12]. Jia et al. use performance counters to characterize data analysis workloads in datacenters ref type"bibr" target </p>
<p> counterminer: mining big performance data from hardware counters </p><p> computationally efficient multiplexing of events on hardware counters </p><p> of events, using MLPX and handling its measurement errors are mandatory. Prior work shows that the errors cannot be effectively avoided during the sampling [33], [#b34][34].Second, it becomes more difficult to extract insights of performance behavior. The events of server processors in a cloud computing platform can genera. a cleaner, which improves the counter data quality by replacing outliers and filling in missing values after the sampling of MLPX, which is complementary to [33], [#b34][34] 2) importance ranker, which iteratively quantifies, ranks, and prunes events based on their importance with respect to performance 3) interaction ranker, wh. t errors occur with MLPX because information may be lost when the event does not happen during a sampled interval [30], [33], [#b34][34] but happens during a unsampled interval. Mathur et al. [38] reported that higher than 50 of errors were observed when t. LPX generally exacerbates the problem, as shown in Figure 3. These errors, however, are difficult to be removed by event scheduling [33], [#b34][34] and estimation algorithms [38]during the sampling procedure. This motivates us to reduce them by data cleaning techniques. collected from hardware counters. It reduces the measurement errors of MLPX by leveraging data cleaning techniques rather than traditional event scheduling [33], [#b34][34] and estimation algorithms [38]. CounterMiner is complementary to [#b34][34] [33] ref type. t scheduling [33], [#b34][34] and estimation algorithms [38]. CounterMiner is complementary to [#b34][34] [33] [38] because CounterMiner does that after (not during) the sampling. Moreover, it quantifies the importance of event. rement errors caused by MLPX have been observed for nearly two decades [29] [31], [33], [#b34][34], [38], [54] [56] and several approaches were p. [31].Recently, Lim et al. propose a scheduling algorithm that schedules n events on m counters (n gt m) (vs. the traditional roundrobin algorithm) to improve the measurement accuracy [#b34][34]. The key idea is to monitor the most recent three values of an event for determining whether another event should be scheduled to monitor on a counter. If the </p>
<p> counterminer: mining big performance data from hardware counters </p><p> mpx: software for multiplexing hardware performance counters in multithreaded programs </p><p> 0"I. INTRODUCTIONModern processors typically provide 48 hardware counters to measure hundreds of crucial events such as cache and TLB misses [1] [#b4][4]. These events can generally reveal root causes and key insights about the performance of computer systems. Therefore, performance counter based analysis is appl. tion of execution to be counted on hardware counters and extrapolating the full behavior of each event from its samples. However, MLPX incurs large measurement errors due to timesharing and sampling [#b4][4], [30] [32].In cloud computing era, this problem is exaggerated for two reasons. han that of the available hardware counters of a processor.Multiplexing (MLPX) is developed to improve the measurement efficiency by letting multiple events timeshare a single hardware counter [#b4][4], [38]. In MLPX, events are scheduled to be sampled during a fraction of execution. Based on the samples, the full behavior </p>
<p> counterminer: mining big performance data from hardware counters </p><p> fractalmrc: online cache miss rate curve prediction on commodity systems </p><p> te curves which can be used for online optimizations [16]. He et al. proposed to leverage fractals to approximate the L2 miss rate curves with much lower overhead [#b17][17]. Based on hardware counters, Blagodurov et al. proposed an algorithm to manage the contention of NUMA multicore systems [18]r </p>
<p> counterminer: mining big performance data from hardware counters </p><p> a top-down method for performance analysis and counters architecture </p><p> e CloudSuite [9]. Later on, Yasin et al. performed a deep characterization by using hardware counters for the CloudSuite [11], [#b12][12]. Jia et al. use performance counters to characterize data analysis workloads in datacenters [8]. Wang et al. characterized </p>
<p> counterminer: mining big performance data from hardware counters </p><p> an introduction to kernel and nearest-neighbor nonparametric regression </p><p> vent is only 0.01 which is very close to zero, and even the actual value is not zero, the error would not be high.For the nonezero value category, we employ KNN (KNearest Neighbor) algorithm [#b43][43] to fill in missing values. For example, a series of data for ICACHE.MISSES is as followsX 1 , X 2 , X 3 , X 4 , X 5 , 0, X 7 </p>
<p> counterminer: mining big performance data from hardware counters </p><p> an introduction to kernel and nearest-neighbor nonparametric regression </p><p> vent is only 0.01 which is very close to zero, and even the actual value is not zero, the error would not be high.For the nonezero value category, we employ KNN (KNearest Neighbor) algorithm [#b43][43] to fill in missing values. For example, a series of data for ICACHE.MISSES is as followsX 1 , X 2 , X 3 , X 4 , X 5 , 0, X 7 </p>
<p> counterminer: mining big performance data from hardware counters </p><p> using dynamic time warping to find pattern in time series </p><p> same length. In order to compute the distance (difference) between two time series, we must "wrap" the time axis of one (or both) sequences to achieve a better alignment. Dynamic time wrapping (DTW) [#b40][40] is a technique for efficiently achieving this wrapping. It employs a dynamic programming approach to align one time series to one another so that the distance </p>
<p> counterminer: mining big performance data from hardware counters </p><p> bigdatabench: a big data benchmark suite from internet services </p><p> Jia et al. use performance counters to characterize data analysis workloads in datacenters [8]. Wang et al. characterized big data workloads for internet services [#b10][10]. Xiong et al. employed performance counters to characterize the big data analysis in city transportation industry and they proposed a transportation big data </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> temporal ensembling for semi-supervised learning </p><p> consistency regularization enforces that an unlabeled example x should be classified the same as Augment(x), an augmentation of itself.In the simplest case, for unlabeled points x, prior work [#b24][] adds the loss termp model (y  Augment(x) )  p model (y  Augment(x) ) 2 2 .labe. el (y  b,k  )(6)in algorithm 1, line 7. Using data augmentation to obtain an artificial target for an unlabeled example is common in consistency regularization methods [#b24][].Algorithm 1 MixMatch takes a batch of labeled data X and a batch of unl. f type"bibr" target"b4"[5]) because, unlike the crossentropy, it is bounded and less sensitive to incorrect predictions. For this reason, it is often used as the unlabeled data loss in SSL [#b24][] as well as a measure of predictive uncertainty [26]. We do not propagate gradient. r" target"b43"44] as well as a measure of predictive uncertainty [26]. We do not propagate gradients through computing the guessed labels, as is standard [#b24][]  div xmlns"httpwww.tei. p Baseline MethodsAs baselines, we consider the four methods considered in [35] (Model [#b24][], Mean Teacher [44], Virtual Adversarial Training [ </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> semi-supervised learning by entropy minimization </p><p> unlabeled data and encourages the model to generalize better to unseen data. In much recent work, this loss term falls into one of three classes (discussed further in Section 2) entropy minimization [#b17][]which encourages the model to output confident predictions on unlabeled data consistency regularizationwhich encoura. gh highdensity regions of the marginal data distribution.One way to enforce this is to require that the classifier output lowentropy predictions on unlabeled data. This is done explicitly in [#b17][18] with a loss term which minimizes the entropy of p model (y  x ) for unlabeled data x. This form of entropy minimization was combined with VAT in ref type </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> regularization with stochastic transformations and perturbations for deep semi-supervised learning </p><p> an unlabeled example x should be classified the same as Augment(x), an augmentation of itself.In the simplest case, for unlabeled points x, prior work [[#b39]] adds the loss termp model (y  Augment(x) )  p model (y  Augment(x) ) 2 2 .(1)Note that Augme. ulain algorithm 1, line 7. Using data augmentation to obtain an artificial target for an unlabeled example is common in consistency regularization methods [[#b39]].Algorithm 1 MixMatch takes a batch of labeled data X and a batch of unlabeled data U and produces a collection X. ns1.0"Baseline MethodsAs baselines, we consider the four methods considered in [35] (Model [[#b39]], Mean Teacher [44], Virtual Adversarial Training [31], and PseudoLabel ref type"bi </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> semi-supervised learning using gaussian fields and harmonic functions </p><p> that we do not discuss here (e.g., "transductive" models [], graphbased methods [#b48][], generative modeling [3,ref type"bibr" tar. r" target"b22"23,38,34,42], etc.). More comprehensive overviews are provided in [#b48][]. In the following, we will refer to a generic model p model (y  x ) which produces a distribution over class labels y </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> an analysis of single-layer networks in unsupervised feature learning </p><p> valuate the effectiveness of MixMatch on four standard benchmark datasets CIFAR10 and CIFAR100 [24], SVHN [32], and STL10 [#b7][8]. Standard practice for evaluating semisupervised learning on the first three datasets is to treat most of the dataset as unlabeled and use a small portion as l </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> transductive inference for text classification using support vector machines </p><p> Match builds on there is a wide literature on SSL techniques that we do not discuss here (e.g., "transductive" models [[#b20]], graphbased methods [], generative modeli </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> mean teachers are better role models: weight-averaged consistency targets improve semi-supervised deep learning results </p><p> ) 2 2 .(1)Note that Augment(x) is a stochastic transformation, so the two terms in eq. ( 1) are not identical. "Mean Teacher" [#b43][44] replaces one of the terms in eq. ( 1) with the output of the model using an exponential moving average of model. a augmentation to obtain an artificial target for an unlabeled example is common in consistency regularization methods [[#b43]].Algorithm 1 MixMatch takes a batch of labeled data X and a batch of unlabeled data U and produces a collection X  (resp. U  ) of processed labeled exa. ause, unlike the crossentropy, it is bounded and less sensitive to incorrect predictions. For this reason, it is often used as the unlabeled data loss in SSL [[#b43]] as well as a measure of predictive uncertainty [26]. We do not propagate gradients through computing the guessed labels, a. easure of predictive uncertainty [26]. We do not propagate gradients through computing the guessed labels, as is standard [[#b43]]  Hyperparamete. e found that   0.75 and  U  100 are good starting points for tuning. In all experiments, we linearly ramp up  U to its maximum value over the first 16,000 steps of training as is common practice [#b43][44]. ExperimentsWe test the effectiveness of MixMatch on standard SSL benchmarks (section. aselines, we consider the four methods considered in [35] (Model [], Mean Teacher [#b43][44], Virtual Adversarial Training [31], and PseudoLabel [28]) which are described in se. ver 4.5 higher than MixMatch considering that 4.17 is the error limit obtained on our model with fully supervised learning. In addition, at 4000 labels the nextbestperforming method (Mean Teacher [#b43][44]) obtains an error rate of 10.36, which suggests that MixMatch can achieve similar performance with only 116 as many labels. We believe that the most interes. most interesting comparisons are with very few labeled data points since it reveals the method's sample efficiency which is central to SSL. CIFAR10 and CIFAR100 with a larger model Some prior work [#b43][] has also considered the use of a larger, 26 millionparameter model. Our base model, as used in ref type"bibr" target. eneral, MixMatch matches or outperforms the best results from [2], though we note that the comparison still remains problematic due to the fact that the model from [#b43][]   3 Comparison of error rates for SVHN and SVHNExtra for MixMatch. The last column ("All") con. e relatively constant (and better than all other methods) across all amounts of labeled data. Surprisingly, after additional tuning we were able to obtain extremely good performance from Mean Teacher [#b43][44], though its error rate was consistently slightly higher than MixMatch's.Note that SVHN has two training sets train and extra. In fullysupervised lear. t of removing or  removing temperature sharpening (i.e. setting T  1) using an exponential moving average (EMA) of model parameters when producing guessed labels, as is done by Mean Teacher [#b43][44]  performing MixUp between labeled examples only, unlabeled examples only, and without mixing across labeled and unlabeled examples using Interpolatio </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> using deep belief nets to learn covariance kernels for gaussian processes </p><p> get"b48"[], generative modeling [3,27,[#b40]41,9,17,23,38,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> the importance of encoding versus training with sparse coding and vector quantization </p><p> rget"b3"4,29], generative modeling [3,27,41,[#b8]9,17,23,38,34,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> the importance of encoding versus training with sparse coding and vector quantization </p><p> rget"b3"4,29], generative modeling [3,27,41,[#b8]9,17,23,38,34,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> laplacian eigenmaps and spectral techniques for embedding and clustering </p><p> f type"bibr" target"b20"21], graphbased methods [], generative modeling [#b2][3,27,41,9,17,re </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> using deep belief nets to learn covariance kernels for gaussian processes </p><p> get"b48"[], generative modeling [3,27,[#b40]41,9,17,23,38,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> deep learning with differential privacy </p><p> ref. Each training data access constitutes a potential privacy leakage, encoded as the pair of the input and its label. Hence, approaches for deep learning from private training data, such as DPSGD [#b0][1] and PATE [36], benefit from accessing as few labeled private training points as possible when computing updates to the mode </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> reading digits in natural images with unsupervised feature learning </p><p> n"4.2"SemiSupervised LearningFirst, we evaluate the effectiveness of MixMatch on four standard benchmark datasets CIFAR10 and CIFAR100 [24], SVHN [#b31][32], and STL10 [8]. Standard practice for evaluating semisupervised learning on the first three datasets is to treat most of </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> simple and scalable predictive uncertainty estimation using deep ensembles </p><p> s. For this reason, it is often used as the unlabeled data loss in SSL [] as well as a measure of predictive uncertainty [#b25][26]. We do not propagate gradients through computing the guessed labels, as is standard [25,44 </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> keeping neural networks simple by minimizing the description length of the weights </p><p> dRegularization refers to the general approach of imposing a constraint on a model to make it harder to memorize the training data and therefore hopefully make it generalize better to unseen data [#b18][19]. We use weight decay which penalizes the L 2 norm of the model parameters []. W </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> learning by transduction </p><p> r SSL. We focus mainly on those which are currently stateoftheart and that MixMatch builds on there is a wide literature on SSL techniques that we do not discuss here (e.g., "transductive" models [#b13][], graphbased methods [49,ref type"bibr" </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> calibrating noise to sensitivity in private data analysis </p><p> ed technical definition of privacy) if adding, modifying, or removing any of its training samples is guaranteed not to result in a statistically significant difference in the model parameters learned [#b12][13]. For this reason, learning with differential privacy is, in practice, a form of regularization [33]. Each training data a </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> semisupervised learning with ladder networks </p><p> . In practice, semisupervised learning methods with many hyperparameters can be problematic because crossvalidation is difficult with small validation sets [[#b38]]. However, we find in practice that most of MixMatch's hyperparameters can be fixed and do not need to be tuned on a per </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> verification of forecasts expressed in terms of probability </p><p> uesses. Loss FunctionGiven our processed batches X  and U  , we use the standard semisupervised loss shown in eqs. (3) to [#b4](5). Equation ( 5) combines the typical crossentropy loss between labels and model predictions from X  with the squared L 2 loss on pred. een labels and model predictions from X  with the squared L 2 loss on predictions and guessed labels from U  . We use this L 2 loss in eq. ( 4) (the multiclass Brier score [#b4][5]) because, unlike the crossentropy, it is bounded and less sensitive to incorrect predictions. For this reason, it is often used as the unlabeled data loss in S </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> principled hybrids of generative and discriminative models </p><p> graphbased methods [], generative modeling [3,[#b26]27,41,9,17,23,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> deep, big, simple neural nets for handwritten digit recognition </p><p> fected. For example, in image classification, it is common to elastically deform or add noise to an input image, which can dramatically change the pixel content of an image without altering its label [#b6][]. Roughly speaking, this can artificially expand the size of a training set by gen </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> virtual adversarial training: a regularization method for supervised and semi-supervised learning </p><p> stable target and was found empirically to significantly improve results. A drawback to these approaches is that they use domainspecific data augmentation strategies. "Virtual Adversarial Training" [#b30][31] (VAT) addresses this by instead computing an additive perturbation to apply to the input which maximally changes the output class distribution. MixMatch utili. icitly in [18] with a loss term which minimizes the entropy of p model (y  x ) for unlabeled data x. This form of entropy minimization was combined with VAT in [#b30][31] to obtain stronger results. "PseudoLabel" [28] does entropy minimization implicitly by constructing hard (1hot) labels. pe"bibr" target"b25"[26]. We do not propagate gradients through computing the guessed labels, as is standard [[#b30]]  HyperparametersSince MixMatch combines mult. rget"b34"[35] (Model [], Mean Teacher [44], Virtual Adversarial Training [#b30][31], and PseudoLabel [28]) which are described in section 2. We also use MixUp [47] on. ng on all 50000 samples achieves an error rate of 4.17. Furthermore, MixMatch obtains an error rate of 11.08 with only 250 labels. For comparison, at 250 labels the nextbestperforming method (VAT [#b30][31]) achieves an error rate of 36.03, over 4.5 higher than MixMatch considering that 4.17 is the error limit obtained on our model with fully supervised learnin. formance of PATE, it would also illustrate MixMatch's improved generalization from few canonical exemplars of each class.We compare the accuracyprivacy tradeoff achieved by MixMatch to a VAT [#b30][31] baseline on SVHN.VAT achieved the previous stateoftheart of 91.6 test accuracy for a privacy loss of   4.96 [37] </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> shake-shake regularization </p><p> s for SVHN and SVHNExtra for MixMatch. The last column ("All") contains the fullysupervised performance with all labels in the corresponding training set. sophisticated "shakeshake" regularization [#b14][15]. For this model, we used a weight decay of 0.0008. We used  U  75 for CIFAR10 and  U  150 for CIFAR100. div xmlns"httpwww.teic.orgns1. </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> principled hybrids of generative and discriminative models </p><p> graphbased methods [], generative modeling [3,[#b26]27,41,9,17,23,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> deep, big, simple neural nets for handwritten digit recognition </p><p> fected. For example, in image classification, it is common to elastically deform or add noise to an input image, which can dramatically change the pixel content of an image without altering its label [#b6][]. Roughly speaking, this can artificially expand the size of a training set by gen </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> deep learning with differential privacy </p><p> ref. Each training data access constitutes a potential privacy leakage, encoded as the pair of the input and its label. Hence, approaches for deep learning from private training data, such as DPSGD [#b0][1] and PATE [36], benefit from accessing as few labeled private training points as possible when computing updates to the mode </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> shake-shake regularization </p><p> s for SVHN and SVHNExtra for MixMatch. The last column ("All") contains the fullysupervised performance with all labels in the corresponding training set. sophisticated "shakeshake" regularization [#b14][15]. For this model, we used a weight decay of 0.0008. We used  U  75 for CIFAR10 and  U  150 for CIFAR100. div xmlns"httpwww.teic.orgns1. </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> shake-shake regularization </p><p> s for SVHN and SVHNExtra for MixMatch. The last column ("All") contains the fullysupervised performance with all labels in the corresponding training set. sophisticated "shakeshake" regularization [#b14][15]. For this model, we used a weight decay of 0.0008. We used  U  75 for CIFAR10 and  U  150 for CIFAR100. div xmlns"httpwww.teic.orgns1. </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> using deep belief nets to learn covariance kernels for gaussian processes </p><p> get"b48"[], generative modeling [3,27,[#b40]41,9,17,23,38,r </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> an analysis of single-layer networks in unsupervised feature learning </p><p> valuate the effectiveness of MixMatch on four standard benchmark datasets CIFAR10 and CIFAR100 [24], SVHN [32], and STL10 [#b7][8]. Standard practice for evaluating semisupervised learning on the first three datasets is to treat most of the dataset as unlabeled and use a small portion as l </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> realistic evaluation of deep semi-supervised learning algorithms </p><p> o not propagate gradients through computing the guessed labels, as is standard [[#b34]]  HyperparametersSince MixMatch combines multiple mechanisms for leveraging unlabeled. xUp, and the unsupervised loss weight  U . In practice, semisupervised learning methods with many hyperparameters can be problematic because crossvalidation is difficult with small validation sets [#b34][[#b34]]. However, we find in practice that most of MixMatch's hyperparameters can be f. methods with many hyperparameters can be problematic because crossvalidation is difficult with small validation sets [#b34][[#b34]]. However, we find in practice that most of MixMatch's hyperparameters can be fixed and do not need to be tuned on a perexperiment or perdataset basis. Specif. ning in section 4.3. Implementation detailsUnless otherwise noted, in all experiments we use the "Wide ResNet28" model from [#b34][35]. Our implementation of the model and training procedure closely matches that of [#b34][35] (including using 5000 examples to se. ss otherwise noted, in all experiments we use the "Wide ResNet28" model from [#b34][35]. Our implementation of the model and training procedure closely matches that of [#b34][35] (including using 5000 examples to select the hyperparameters), except for the following differences First, instead of decaying the learning rate, we evaluate. ly different distribution than the labeled data.  Baseline MethodsAs baselines, we consider the four methods considered in [#b34][35] (Model [], Mean Teacher [44], Virtual Ad. mples with their corresponding predictions. In accordance with standard usage of MixUp, we use a crossentropy loss between the MixUpgenerated guess label and the model's prediction. As advocated by [#b34][35], we reimplemented each of these methods in the same codebase and applied them to the same model (described in section 4.1) to ensure a fair comparison. We re. odel (described in section 4.1) to ensure a fair comparison. We retuned the hyperparameters for each baseline method, which generally resulted in a marginal accuracy improvement compared to those in [#b34][35], thereby providing a more competitive experimental setting for testing out MixMatch. Result. r model Some prior work [] has also considered the use of a larger, 26 millionparameter model. Our base model, as used in [#b34][35], has only 1.5 million parameters which confounds comparison with these results. For a more reasonable comparison to these results, we measure the effect of in </p>
<p> Mixmatch: A holistic approach to semi-supervised learning </p><p> keeping neural networks simple by minimizing the description length of the weights </p><p> dRegularization refers to the general approach of imposing a constraint on a model to make it harder to memorize the training data and therefore hopefully make it generalize better to unseen data [#b18][19]. We use weight decay which penalizes the L 2 norm of the model parameters []. W </p>
<p> Graph Attention Networks </p><p> semi-supervised classification with graph convolutional networks </p><p> to approximate the filters by means of a Chebyshev expansion of the graph Laplacian, removing the need to compute the eigenvectors of the Laplacian and yielding spatially localized filters. Finally, [#b23]Kipf amp Welling (2017) simplified the previous method by restricting the filters to operate in a 1step neighborhood around each node. However, in all of the af. mber of input features, and V  and E are the numbers of nodes and edges in the graph, respectively. This complexity is on par with the baseline methods such as Graph Convolutional Networks (GCNs) [#b23](Kipf amp Welling, 2017). Applying multihead attention multiplies the storage and parameter requirements by a factor of K, while the individual heads' computati. .0"STATEOFTHEART METHODSTransductive learning For transductive learning tasks, we compare against the same strong baselines and stateoftheart approaches as specified in [#b23]Kipf amp Welling (2017). This includes label propagation (LP) (Zhu et al., 2003), semisupervised embedding (SemiEmb) ref t </p>
<p> Graph Attention Networks </p><p> gated graph sequence neural networks </p><p> n iterative process, which propagates the node states until equilibrium followed by a neural network, which produces an output for each node based on its state. This idea was adopted and improved by [#b24]Li et al. (2016), which propose to use gated recurrent units (Cho et al., 2014) in the propagation step.Nevertheless, th </p>
<p> Graph Attention Networks </p><p> neural machine translation by jointly learning to align and translate </p><p> work). This approach has yielded impressive performance across several largescale inductive benchmarks.Attention mechanisms have become almost a de facto standard in many sequencebased tasks [#b2](Bahdanau et al., 2015Gehring et al., 2016). One of the benefits of attention mechanisms is that they allow for dealing with v. single graph attentional layer, as the sole layer utilized throughout all of the GAT architectures used in our experiments. The particular attentional setup utilized by us closely follows the work of [#b2]Bahdanau et al. (2015)but the framework is agnostic to the particular choice of attention mechanism. The i. in model capacity. Furthermore, analyzing the learned attentional weights may lead to benefits in interpretability, as was the case in the machine translation domain (e.g. the qualitative analysis of [#b2]Bahdanau et al. (2015)).  The attention mechanism is applied in a shared manner to all edges in the graph, and therefore it does not depend on upfront access to th. Additionally, we visualize the relative strengths of the normalized attention coefficients (averaged across all eight attention heads). Properly interpreting these coefficients (as performed by e.g. [#b2]Bahdanau et al. (2015)) will require further domain knowledge about the dataset under study, and is left for future work. div xmlns"httpwww.teic.org </p>
<p> Graph Attention Networks </p><p> diffusion-convolutional neural networks </p><p> cific structure can not be directly applied to a graph with a different structure.On the other hand, we have nonspectral approaches (Duvenaud et al., 2015[#b1]Atwood amp Towsley, 2016Hamilton et al., 2017), which define convolutions directly on the graph, operating on groups of spat. (Duvenaud et al., 2015), using the powers of a transition matrix to define the neighborhood while learning weights for each input channel and neighborhood degree [#b1](Atwood amp Towsley, 2016), or extracting and normalizing neighborhoods containing a fixed number of nodes (Niepert et al., 2016). tching stateoftheart results that highlight the potential of attentionbased models when dealing with arbitrarily structured graphs.It is worth noting that, as Kipf amp Welling (2017) and [#b1]Atwood amp Towsley (2016), our work can also be reformulated as a particular instance of MoNet (Monti et al., 2016). Moreover </p>
<p> Graph Attention Networks </p><p> long short-term memory </p><p> footprint consistent this does not allow it access to the entirety of the neighborhood while performing inference.Moreover, this technique achieved some of its strongest results when an LSTM [#b19](Hochreiter amp Schmidhuber, 1997)based neighborhood aggregator is used. This assumes the existence of a consistent sequential node ordering across neighborhood </p>
<p> Graph Attention Networks </p><p> long short-term memory </p><p> footprint consistent this does not allow it access to the entirety of the neighborhood while performing inference.Moreover, this technique achieved some of its strongest results when an LSTM [#b19](Hochreiter amp Schmidhuber, 1997)based neighborhood aggregator is used. This assumes the existence of a consistent sequential node ordering across neighborhood </p>
<p> Graph Attention Networks </p><p> supervised neural networks for the classification of structures </p><p> rarily structured graphs. Early work used recursive neural networks to process data represented in graph domains as directed acyclic graphs (Frasconi et al., 1998[#b35]Sperduti amp Starita, 1997). Graph Neural Networks (GNNs) were introduced in Gori et al. (2005) and ref type"bibr" target </p>
<p> Graph Attention Networks </p><p> diffusion-convolutional neural networks </p><p> cific structure can not be directly applied to a graph with a different structure.On the other hand, we have nonspectral approaches (Duvenaud et al., 2015[#b1]Atwood amp Towsley, 2016Hamilton et al., 2017), which define convolutions directly on the graph, operating on groups of spat. (Duvenaud et al., 2015), using the powers of a transition matrix to define the neighborhood while learning weights for each input channel and neighborhood degree [#b1](Atwood amp Towsley, 2016), or extracting and normalizing neighborhoods containing a fixed number of nodes (Niepert et al., 2016). tching stateoftheart results that highlight the potential of attentionbased models when dealing with arbitrarily structured graphs.It is worth noting that, as Kipf amp Welling (2017) and [#b1]Atwood amp Towsley (2016), our work can also be reformulated as a particular instance of MoNet (Monti et al., 2016). Moreover </p>
<p> Graph Attention Networks </p><p> manifold regularization: a geometric framework for learning from labeled and unlabeled examples </p><p> agation (LP) (Zhu et al., 2003), semisupervised embedding (SemiEmb) (Weston et al., 2012), manifold regularization (ManiReg) [#b3](Belkin et al., 2006), skipgram based graph embeddings (DeepWalk) (Perozzi et al., 2014), the iterative classification algori. microaveraged F 1 score on the nodes of the two unseen test graphs, averaged after 10 runs, and reuse the metrics already reported in Hamilton et al. (2017) for  [#b3](Belkin et al., 2006) 59.5 60.1 70.7 SemiEmb (Weston et al., 2012) 59.0 59.6 71.7 LP (Zhu </p>
<p> Graph Attention Networks </p><p> neural machine translation by jointly learning to align and translate </p><p> work). This approach has yielded impressive performance across several largescale inductive benchmarks.Attention mechanisms have become almost a de facto standard in many sequencebased tasks [#b2](Bahdanau et al., 2015Gehring et al., 2016). One of the benefits of attention mechanisms is that they allow for dealing with v. single graph attentional layer, as the sole layer utilized throughout all of the GAT architectures used in our experiments. The particular attentional setup utilized by us closely follows the work of [#b2]Bahdanau et al. (2015)but the framework is agnostic to the particular choice of attention mechanism. The i. in model capacity. Furthermore, analyzing the learned attentional weights may lead to benefits in interpretability, as was the case in the machine translation domain (e.g. the qualitative analysis of [#b2]Bahdanau et al. (2015)).  The attention mechanism is applied in a shared manner to all edges in the graph, and therefore it does not depend on upfront access to th. Additionally, we visualize the relative strengths of the normalized attention coefficients (averaged across all eight attention heads). Properly interpreting these coefficients (as performed by e.g. [#b2]Bahdanau et al. (2015)) will require further domain knowledge about the dataset under study, and is left for future work. div xmlns"httpwww.teic.org </p>
<p> Graph Attention Networks </p><p> inductive representation learning on large graphs </p><p> ifferent structure.On the other hand, we have nonspectral approaches (Duvenaud et al., 2015Atwood amp Towsley, 2016[#b16]Hamilton et al., 2017), which define convolutions directly on the graph, operating on groups of spatially close neighbors. One of the challenges of these approache. ref type"bibr" target"b28"Monti et al. (2016) presented mixture model CNNs (MoNet), a spatial approach which provides a unified generalization of CNN architectures to graphs. More recently, [#b16]Hamilton et al. (2017) introduced GraphSAGE, a method for computing node representations in an inductive manner. This technique operates by sampling a fixedsize n. 20 graphs for training, 2 for validation and 2 for testing. Critically, testing graphs remain completely unobserved during training. To construct the graphs, we used the preprocessed data provided by [#b16]Hamilton et al. (2017). The average number of nodes per graph is 2372. Each node has 50 features that are composed of positional gene sets, motif gene sets and imm. ype"bibr" target"b28"Monti et al. (2016).Inductive learning For the inductive learning task, we compare against the four different supervised GraphSAGE inductive methods presented in [#b16]Hamilton et al. (2017). These provide a variety of approaches to aggregating features within a sampled neighborhood GraphSAGEGCN (which extends a graph convoluti. in all three cases).For the inductive task, we report the microaveraged F 1 score on the nodes of the two unseen test graphs, averaged after 10 runs, and reuse the metrics already reported in [#b16]Hamilton et al. (2017) for  (Belkin et al., 2006) 59.5 60.1 70.7 SemiEmb (Weston et al., 2012 </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> on the inclusion properties for multi-level cache hierarchies </p><p> is imperative that processor architects design an efficient and high performing cache hierarchy. One of the key design choices for a multilevel cache hierarchy is whether or not to enforce inclusion [#b4][]. While inclusion greatly simplifies the cache coherence protocol ref type"bibr. "b4"[]. While inclusion greatly simplifies the cache coherence protocol [[#b4]], it limits performance when the size of the largest cache is not significantly larger than the sum of the smaller caches. In such scenarios, CPU architects resor. formance without sacrificing its benefits.The inclusion property requires that the contents of all the smaller caches of a multilevel cache hierarchy be a subset of the lastlevel cache (LLC) [#b4][6]. When a line is evicted from the LLC, inclusion is enforced by removing that line from all the caches in the hierarchy. We refer to cache lines invalidated in t. bibr" target"b27"29]. Unfortunately, noninclusion eliminates the natural snoop filter benefit that an inclusive LLC provides, thus breaking the coherence benefits that come with inclusivity [#b4][6]. While snoop filters [] can be used in addi </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> tradeoffs in two-level on-chip caching </p><p> g cache hierarchy. One of the key design choices for a multilevel cache hierarchy is whether or not to enforce inclusion [[#b15]]. While inclusion greatly simplifies the cache coherence protocol [], it limits perfo. e of the largest cache is not significantly larger than the sum of the smaller caches. In such scenarios, CPU architects resort to noninclusive [27] or exclusive [#b15][17] cache hierarchies. This paper focuses on improving inclusive cache performance without sacrificing its benefits.The inclusion property requires that th </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> adaptive insertion policies for managing shared caches </p><p> o compete for cache resources. We only collect statistics for the first 250 million instructions committed by each application. This methodology is similar to existing work on shared cache management [#b13][]. 5.We compa.  while ECI and QBS improves average performance by 4.5 and 6.5 respectively.There has also been extensive research on managing shared caches in CMPs [[#b13]]. Most of the prior research work focuses on how to efficiently partition the shared lastlevel cache of a CMP. When mult. cache partitioning and do not address the problem of inclusion victims. We compared the TLA policies in the presence of intelligent cache management policies [[#b13]] and find that we achieve similar performance improvements.VII. SUMMARY Inclusive caches are desirable because they simplify cache coherence. However, in </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> improving direct-mapped cache performance by the addition of a fully associative cache and prefetch buffers </p><p> inclusion victims in the context of direct mapped network caches and proposed three solutions to address the problem. The proposed solutions include increasing the cache associativity, a victim cache [#b16][18], or making the LLC noninclusive and using a snoop filter (called a tag cache in the paper) to ease cache coherence. They showed that increasing the network c </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> pipp: promotion/insertion pseudo-partitioning of multi-core shared caches </p><p> on instructions committed by each application. This methodology is similar to existing work on shared cache management [[#b23]]. 5.We compared the performance of the TLA policies on both the weighted speedup and hmeanfa. formance by 4.5 and 6.5 respectively.There has also been extensive research on managing shared caches in CMPs [[#b23]]. Most of the prior research work focuses on how to efficiently partition the shared lastlevel cache of a CMP. When multiple applications compete for the shared </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> piranha: a scalable architecture based on single-chip multiprocessing </p><p>  </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> adaptive insertion policies for managing shared caches </p><p> o compete for cache resources. We only collect statistics for the first 250 million instructions committed by each application. This methodology is similar to existing work on shared cache management [#b13][]. 5.We compa.  while ECI and QBS improves average performance by 4.5 and 6.5 respectively.There has also been extensive research on managing shared caches in CMPs [[#b13]]. Most of the prior research work focuses on how to efficiently partition the shared lastlevel cache of a CMP. When mult. cache partitioning and do not address the problem of inclusion victims. We compared the TLA policies in the presence of intelligent cache management policies [[#b13]] and find that we achieve similar performance improvements.VII. SUMMARY Inclusive caches are desirable because they simplify cache coherence. However, in </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> reducing verification complexity of a multicore coherence protocol using assume/ guarantee </p><p> orce inclusion []. While inclusion greatly simplifies the cache coherence protocol [#b7][], it limits performance when the size of the largest cache is not significantly larger than the sum of the smaller caches.. 23] can be used in addition to the LLC, such structures increase the hardware overhead [29] and verification complexity [#b7][9]. It would be ideal to design a cache hierarchy that reduces (if not eliminates) the frequency of inclusion victims while providing the coherence benefits of inc </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> cmp$im: a pin-based on-the-fly multi-core cache simulator </p><p> voids LLC misses. IV. EXPERIMENTAL METHODOLOGY A. SimulatorWe use CMPim [#b14][16], a Pin [19] based tracedriven x86 simulator for our performance studies. Our baseline system is a 2core CMP. Each core </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> design and implementation of the blue gene/p snoop filter </p><p> fit that an inclusive LLC provides, thus breaking the coherence benefits that come with inclusivity [6]. While snoop filters [[#b20]] can be used in addition to the LLC, such structures increase the hardware overhead [29] </p>
<p> achieving non-inclusive cache performance with inclusive caches: temporal locality aware (tla) cache management policies. </p><p> reducing verification complexity of a multicore coherence protocol using assume/ guarantee </p><p> orce inclusion []. While inclusion greatly simplifies the cache coherence protocol [#b7][], it limits performance when the size of the largest cache is not significantly larger than the sum of the smaller caches.. 23] can be used in addition to the LLC, such structures increase the hardware overhead [29] and verification complexity [#b7][9]. It would be ideal to design a cache hierarchy that reduces (if not eliminates) the frequency of inclusion victims while providing the coherence benefits of inc </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> natural tts synthesis by conditioning wavenet on mel spectrogram predictions </p><p> INTRODUCTIONEndtoend texttospeech (TTS) models which generate speech directly from characters have made rapid progress in recent years, and achieved very high voice quality [#b0][1][2][3]. While the single style TTS, usually neutral speaking style, is approaching the ex. pe"bibr" target"b1"[2][3]. While the single style TTS, usually neutral speaking style, is approaching the extreme quality close to human expert recording [#b0][], the interests in expressive speech synthesis also keep rising. Recently, there also published many promising works in thi. style to represent these prosody related expressions. The latent state plays a pretty similar role as the latent variable does in VAE. Therefore, in this paper we intend to introduce VAE to Tacotron2 [#b0][1], a stateoftheart endtoend speech synthesis model, to learn the latent representation of speaker state in a continuous space, and further to control the spe. ion, z should be first passed through a FC layer to make sure the dimension equal to text encoder state before add operation. The attention module and decoder have the same architecture as Tacotron 2 [#b0][1]. Then, WaveNet [19] vocoder is utilized to reconstruct waveform.The total loss of proposed model is shown in equatio </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> expressive speech synthesis via modeling expressions with variational autoencoder </p><p> at Microsoft STC Asia text generation [9], image generation [] and speech generation [#b11][] tasks. VAE has many merits, such as learning disentangled factors, smoothly interpolating or continuously sampling bet. ith various speaking style, which is very useful for data augmentation. Comprehensive evaluation shows the good performance of this method.We have become aware of recent work by Akuzawa et al. [#b11][12] which combines an autoregressive speech synthesis model with VAE for expressive speech synthesis. The proposed work differs from Akuzawa's as follows 1) thei </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> generative adversarial nets </p><p> [5][6].Deep generative models, such as Variational Autoencoder (VAE) [7] and Generative Adversarial Network (GAN) [#b7][8], are powerful architectures which can learn complicated distribution in an unsupervised manner. Particularly, VAE, which explicitly models latent variables, hav </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> generative adversarial nets </p><p> [5][6].Deep generative models, such as Variational Autoencoder (VAE) [7] and Generative Adversarial Network (GAN) [#b7][8], are powerful architectures which can learn complicated distribution in an unsupervised manner. Particularly, VAE, which explicitly models latent variables, hav </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> autoencoding variational bayes </p><p> nd TTS model [4][5][6].Deep generative models, such as Variational Autoencoder (VAE) [#b6][7] and Generative Adversarial Network (GAN) [8], are powerful architectures which can learn complicated distribution in an unsu. ils of our proposed style transfer model. Variational AutoencoderVariational Autoencoder was first defined by Kingma et al. [#b6][7] which constructs a relationship between unobserved continuous random latent variables z and observed dataset x. The true posterior density p  (zx) is intracta </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> bidirectional recurrent neural networks </p><p> 2.1. Then z is derived by reparameterization trick. The encoder which deals with character inputs consists of three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [#b14][15] LSTM [16] layer using zoneout [17] with probability 0.1. The output text encoder sta </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> generating sentences from a continuous space </p><p> come one of the most popular approaches and achieved significant success on Paper accepted by IEEE ICASSP 2019 Work done during internship at Microsoft STC Asia text generation [#b8][9], image generation [] and speech generation [12,re. "13] tasks. VAE has many merits, such as learning disentangled factors, smoothly interpolating or continuously sampling between latent representations which can obtain interpretable homotopies [#b8][9].Intuitively, in speech generation, the latent state of speaker, such as affect and intent, contributes to the prosody, emotion, or speaking style. For si. convergence speed of KL loss far surpasses that of the reconstruction loss and the KL loss quickly drops to nearly zero and never rises again, which means the encoder doesn't work. Thus, KL annealing [#b8][9] is introduced to our task to solve this problem. That is, during training, add a variable weight to the KL term. The weight is close to zero at the beginning of. Style control Interpolation of latent variablesAs mentioned in [#b8][9], VAE supports smoothly interpolation and continuous sampling between latent representations, which obtains interpretable homotopies. Thus, we did interpolation </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> autoencoding variational bayes </p><p> nd TTS model [4][5][6].Deep generative models, such as Variational Autoencoder (VAE) [#b6][7] and Generative Adversarial Network (GAN) [8], are powerful architectures which can learn complicated distribution in an unsu. ils of our proposed style transfer model. Variational AutoencoderVariational Autoencoder was first defined by Kingma et al. [#b6][7] which constructs a relationship between unobserved continuous random latent variables z and observed dataset x. The true posterior density p  (zx) is intracta </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> towards end-to-end prosody transfer for expressive speech synthesis with tacotron </p><p> , there also published many promising works in this topic, such as transferring prosody and speaking style within or cross speakers based on endtoend TTS model [4][#b4][5][6].Deep generative models, such as Variational Autoencoder (VAE) [7] and Generati </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> wavenet: a generative model for raw audio </p><p> e sure the dimension equal to text encoder state before add operation. The attention module and decoder have the same architecture as Tacotron 2 [1]. Then, WaveNet [#b18][19] vocoder is utilized to reconstruct waveform.The total loss of proposed model is shown in equation (2).formula </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> style tokens: unsupervised style modeling, control and transfer in end-to-end speech synthesis </p><p> ch synthesis also keep rising. Recently, there also published many promising works in this topic, such as transferring prosody and speaking style within or cross speakers based on endtoend TTS model [#b3][4][5][6].Deep generative models, such as Variational Autoencoder (VAE) ref type"bi. the recognition model. Here, we only adopt a recurrent reference encoder followed by two fully connected layers. We use the same architecture and hyperparameters for reference encoder as Wang et al. [#b3][4] which consists of six 2D convolutional layers followed by a GRU layer. The output, which denotes some embedding of the reference audio, is then passed through. used in our experiments. The dataset contains 58453 utterances for training and 200 for test. 80dimensional mel spectrograms were extracted with frame shift 12.5 ms and frame length 50 ms. GST model [#b3][4] with character inputs was used as our baseline model. The hyperparameters are set according to [#b3][4]. As for our proposed mode. acted with frame shift 12.5 ms and frame length 50 ms. GST model [#b3][4] with character inputs was used as our baseline model. The hyperparameters are set according to [#b3][4]. As for our proposed model, the dimension of latent variables is 32. The parameter K mentioned in 2.3 is 100 before 15000 training steps and 400 after the thres </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> style tokens: unsupervised style modeling, control and transfer in end-to-end speech synthesis </p><p> ch synthesis also keep rising. Recently, there also published many promising works in this topic, such as transferring prosody and speaking style within or cross speakers based on endtoend TTS model [#b3][4][5][6].Deep generative models, such as Variational Autoencoder (VAE) ref type"bi. the recognition model. Here, we only adopt a recurrent reference encoder followed by two fully connected layers. We use the same architecture and hyperparameters for reference encoder as Wang et al. [#b3][4] which consists of six 2D convolutional layers followed by a GRU layer. The output, which denotes some embedding of the reference audio, is then passed through. used in our experiments. The dataset contains 58453 utterances for training and 200 for test. 80dimensional mel spectrograms were extracted with frame shift 12.5 ms and frame length 50 ms. GST model [#b3][4] with character inputs was used as our baseline model. The hyperparameters are set according to [#b3][4]. As for our proposed mode. acted with frame shift 12.5 ms and frame length 50 ms. GST model [#b3][4] with character inputs was used as our baseline model. The hyperparameters are set according to [#b3][4]. As for our proposed model, the dimension of latent variables is 32. The parameter K mentioned in 2.3 is 100 before 15000 training steps and 400 after the thres </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> long shortterm memory </p><p> rick. The encoder which deals with character inputs consists of three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [15] LSTM [#b15][16] layer using zoneout [17] with probability 0.1. The output text encoder state is simply added by z and then is consumed by </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> long shortterm memory </p><p> rick. The encoder which deals with character inputs consists of three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [15] LSTM [#b15][16] layer using zoneout [17] with probability 0.1. The output text encoder state is simply added by z and then is consumed by </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> zoneout: regularizing rnns by randomly preserving hidden activations </p><p> f three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [15] LSTM [16] layer using zoneout [#b16][17] with probability 0.1. The output text encoder state is simply added by z and then is consumed by a locationsensitive attention network ref type"bibr" targe </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> zoneout: regularizing rnns by randomly preserving hidden activations </p><p> f three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [15] LSTM [16] layer using zoneout [#b16][17] with probability 0.1. The output text encoder state is simply added by z and then is consumed by a locationsensitive attention network ref type"bibr" targe </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> bidirectional recurrent neural networks </p><p> 2.1. Then z is derived by reparameterization trick. The encoder which deals with character inputs consists of three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [#b14][15] LSTM [16] layer using zoneout [17] with probability 0.1. The output text encoder sta </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> long shortterm memory </p><p> rick. The encoder which deals with character inputs consists of three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [15] LSTM [#b15][16] layer using zoneout [17] with probability 0.1. The output text encoder state is simply added by z and then is consumed by </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> towards end-to-end prosody transfer for expressive speech synthesis with tacotron </p><p> , there also published many promising works in this topic, such as transferring prosody and speaking style within or cross speakers based on endtoend TTS model [4][#b4][5][6].Deep generative models, such as Variational Autoencoder (VAE) [7] and Generati </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> zoneout: regularizing rnns by randomly preserving hidden activations </p><p> f three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [15] LSTM [16] layer using zoneout [#b16][17] with probability 0.1. The output text encoder state is simply added by z and then is consumed by a locationsensitive attention network ref type"bibr" targe </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> generating sentences from a continuous space </p><p> come one of the most popular approaches and achieved significant success on Paper accepted by IEEE ICASSP 2019 Work done during internship at Microsoft STC Asia text generation [#b8][9], image generation [] and speech generation [12,re. "13] tasks. VAE has many merits, such as learning disentangled factors, smoothly interpolating or continuously sampling between latent representations which can obtain interpretable homotopies [#b8][9].Intuitively, in speech generation, the latent state of speaker, such as affect and intent, contributes to the prosody, emotion, or speaking style. For si. convergence speed of KL loss far surpasses that of the reconstruction loss and the KL loss quickly drops to nearly zero and never rises again, which means the encoder doesn't work. Thus, KL annealing [#b8][9] is introduced to our task to solve this problem. That is, during training, add a variable weight to the KL term. The weight is close to zero at the beginning of. Style control Interpolation of latent variablesAs mentioned in [#b8][9], VAE supports smoothly interpolation and continuous sampling between latent representations, which obtains interpretable homotopies. Thus, we did interpolation </p>
<p> learning latent representations for style control and transfer in end-to-end speech synthesis </p><p> bidirectional recurrent neural networks </p><p> 2.1. Then z is derived by reparameterization trick. The encoder which deals with character inputs consists of three 1D convolutional layers with 5 width and 512 channels followed by a bidirectional [#b14][15] LSTM [16] layer using zoneout [17] with probability 0.1. The output text encoder sta </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> improving branch predictors by correlating on data values </p><p> and depth tags, return a prediction Fourway set associativity in the BVIT helps minimize the thrashing that often occurs in directmapped buffers. A 3bit performance counter based on Heil's design [#b16][17] tracks the effectiveness of each entry and is used to select which entry to replace when a new entry is added.If all the values of the required registe. alue prediction is low. ARVI attempts to predict values based on the current state along the data dependence chain. If the generating values are present then ARVI's predictions are near perfect. Heil [#b16][17] proposed another approach that correlates on the differences between branch source operand values. We consider this approach an application using a limited am </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> trading conflict and capacity aliasing in conditional branch predictors </p><p> of branch outcomes to make the prediction. Despite many attempts to improve predictor mechanisms and eliminate aliasing [[#b22]], only small incremental improvements have been realized with these approaches. </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> the optimum pipeline depth for a microprocessor </p><p> re selected because 20cycles matches Intel's Pentium 4 design [13] and higher clock rates will likely continue to increase the number of stages in future designs [#b15][]. We have extended the base simulator to support two levels of branch prediction. In all configurations, the first leve </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> the yags branch prediction scheme </p><p> ef type"bibr" target"b25"[] of branch outcomes to make the prediction. Despite many attempts to improve predictor mechanisms and eliminate aliasing [#b8][], </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> dynamic branch decoupled architecture </p><p> plication [], and decoupled architectures [[#b32]] to name a few. We then investigate in depth how dynamic data dependence information can be exploited to provide another dimension for branch prediction. Our ap. ation. The DDT circuit provides ARVI with more complete data dependence information.Branch decoupled architectures [[#b32]] execute branchrelated instructions on a branch processor and feed the control flow result to the main processor. By executing the few instructions leading to. of these branches all together. In [10], instruction tagging by the compiler was proposed to select the data dependence chains for branches. The dynamic design in [#b32][33] separated the branch execution stream at runtime but a hardware design to discover the data dependence chain was not proposed. Our DDT design could be employ </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> the potential of data value speculation to boost ilp </p><p> id L2, if the two predictions differ then the level 2 prediction is used. For the ARVI predictor, since the L1 hybrid is used to filter easily predicted highly biased branches, a confidence estimator [#b13][14] indicates whether the branch is more difficult to predict and that the ARVI predictor should be used. We explore the performance for pipeline latencies of 20,. " target"b7"[8].Related approaches that include additional information into the branch prediction process involve correlating the actual branch register values with the branch outcome [#b13][14] using a conventional value predictor. The authors of the study acknowledge that the accuracy of value prediction is low. ARVI attempts to predict values based </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> dynamic path-based branch correlation </p><p> ee (D ampE 6F HG I7 CB deep. Forming the register set tagDifferentiating paths to a branch can improve prediction accuracy [#b23][24]. ARVI uses the set of registers from the RSE as a path differentiator. Since a full concatenation of the register IDs is impractical, we have discovered that. rts predication, the DDT would include the predicate register as an explicit data dependence.Most current dynamic branch predictors use some combination of the branch address, path information [#b23][24], and the localglobal history [] of branch outcomes to make the prediction. Des </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> energy-efficient issue logic </p><p> iven by parallelism metrics Bahar and Manne [2] propose gating off pipeline resources based on recent IPC performance in order to save power. Similarly, Folegnani [#b11][12] dynamically adapts the size of the issue queue according to parallelism estimates derived from the Reorder Buffer. Dependence chain information can potentiall </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> the potential of data value speculation to boost ilp </p><p> id L2, if the two predictions differ then the level 2 prediction is used. For the ARVI predictor, since the L1 hybrid is used to filter easily predicted highly biased branches, a confidence estimator [#b13][14] indicates whether the branch is more difficult to predict and that the ARVI predictor should be used. We explore the performance for pipeline latencies of 20,. " target"b7"[8].Related approaches that include additional information into the branch prediction process involve correlating the actual branch register values with the branch outcome [#b13][14] using a conventional value predictor. The authors of the study acknowledge that the accuracy of value prediction is low. ARVI attempts to predict values based </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> power and energy reduction via pipeline balancing </p><p> e main loop will never mispredict the outcome of the branch. In the DDT table, the data dependence chain is immediately available. Optimizations driven by parallelism metrics Bahar and Manne [#b1][2] propose gating off pipeline resources based on recent IPC performance in order to save power. Similarly, Folegnani [12] dyn </p>
<p> dynamic data dependence tracking and its application to branch prediction </p><p> variable length path branch prediction </p><p> dictor mechanisms and eliminate aliasing [[#b30]], only small incremental improvements have been realized with these approaches. There is still a large number of dynamic branches that are mispredicted, e.g., f </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> focusing processor policies via critical-path prediction </p><p> primarily focused on detecting criticality for all instructions within the processor. The generally accepted method of determining the critical path of program execution was proposed by Fields et al. [#b5][5]. A graph of dynamic instructions is constructed, modeling each instruction as three nodes dispatch time, execution time, and commit time. Since an instruction. Fields et al. proposed a method for statically determining the critical path of an application using directed graphs, and proposed a tokenbased hardware mechanism to approximate this in hardware [#b5][5]. Runahead [] and CLEAR [13] both propose mecha </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> criticality-based optimizations for efficient load processing </p><p> riticality to load misses, which are most directly relevant to the memory scheduler. We explore this criticality from two different broad perspectives argued in past work. Based on Subramaniam et al. [#b29][29]Subramaniam et al. proposed a load criticality predictor based on the observation that loads with a larger number of consumer instructions are more likely to. rvation that loads with a larger number of consumer instructions are more likely to be critical to the program's execution, and thus the number of consumers can be used as an indicator of criticality [#b29][29]. They add counters to the ROB to track direct dependencies only, which can be determined when consumers enter the rename stage. The number of consumers is the. s of adding criticality to the FRFCFS scheduler, as proposed in Section 3.2. We evaluate our CBP tables, as well as the Critical Load Prediction Table (CLPT) mechanism proposed by Subramaniam et al. [#b29][29]. As discussed in Section 2, we believe that their method of determining criticality also has the potential to inform the memory scheduler. We reproduce their. LPT predictor targets are largely complementary to the ones that the CBP chooses to optimize, and that CLPT is likely better suited for the cacheoriented optimizations proposed by Subramaniam et al. [#b29][29]. Effect on Load LatencyTo gain some additional insight on where the speedups of the. ] both propose mechanisms to alleviate the effect of blocking the head of the ROB at commit. Subramaniam et al. use the number of direct consumers to gauge the criticality of a load instruction [#b29][29]. These works are described in greater detail in Section 2.One of the first works that examined criticality was by Srinivasan and Lebeck ref type"bibr </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> runahead execution: an alternative to very large instruction windows for out-of-order processors </p><p> (CLPTConsumers), so that the scheduler can prioritize among the L2 misses marked critical. Based on Runahead and CLEAR [[#b18]]Recall that in outoforder processors, once load instructions are issued to memory and their entries are saved in the load queue, these instructions exit the e. lowing execution to continue, albeit "skipping" instructions that are in the load's dependency chain (easily detectable by "poisoning" the destination register) [[#b18]]. After the load completes, the processor systematically rolls back to that point in the program order. The goal is to use Runahead mode to warm up processor an. plication using directed graphs, and proposed a tokenbased hardware mechanism to approximate this in hardware [5]. Runahead [[#b18]] and CLEAR [13] both propose mechanisms to alleviate the effect of blocking the head of the ROB at commit. Subramaniam et a </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> load latency tolerance in dynamically scheduled processors </p><p> ad instruction [29]. These works are described in greater detail in Section 2.One of the first works that examined criticality was by Srinivasan and Lebeck [#b28][28]. They studied the amount of time that each load could be delayed, as well as the loads that must be serviced within a single cycle, to maintain ideal issueco </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> load latency tolerance in dynamically scheduled processors </p><p> ad instruction [29]. These works are described in greater detail in Section 2.One of the first works that examined criticality was by Srinivasan and Lebeck [#b28][28]. They studied the amount of time that each load could be delayed, as well as the loads that must be serviced within a single cycle, to maintain ideal issueco </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> parallel application memory scheduling </p><p> ction behavior inside the processor.Other work in the area of memory scheduling has targeted a variety of applications. Ebrahimi et al. demonstrate a memory scheduler for parallel applications [#b4][4]. Using a combination of hardware and software, the thread holding the critical section lock is inferred by the processor, and its memory requests are prioritize </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> checkpointed early load retirement </p><p> ctually supplied to the memory scheduler (CLPTConsumers), so that the scheduler can prioritize among the L2 misses marked critical. Based on Runahead and CLEAR [[#b13]]Recall that in outoforder processors, once load instructions are issued to memory and their entries are saved in the l. of poisoning it, which allows the hardware to leverage the (correct) execution in the shadow of that load when the prediction is correct, or to still warm up processor and cache structures otherwise [#b13][13]. Checkpoint support is still needed.Targeting these loads to "unclog" the ROB could significantly reduce the processor critical path. Figure ref type. enbased hardware mechanism to approximate this in hardware [5]. Runahead [] and CLEAR [#b13][13] both propose mechanisms to alleviate the effect of blocking the head of the ROB at commit. Subramaniam et al. use the number of direct consumers to gauge the </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> dynamic prediction of critical path instructions </p><p> he MSHRs every cycle, which, for a large number of outstanding loads, can be costly in terms of bandwidth.Tune et al. use a number of statistics to determine whether an instruction is critical [#b31][31], based on a series of profiling observations. They flag an instruction as a candidate for being critical if (a) it is the oldest instruction in the issue que </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> parallel application memory scheduling </p><p> ction behavior inside the processor.Other work in the area of memory scheduling has targeted a variety of applications. Ebrahimi et al. demonstrate a memory scheduler for parallel applications [#b4][4]. Using a combination of hardware and software, the thread holding the critical section lock is inferred by the processor, and its memory requests are prioritize </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> a compiler-directed data prefetching scheme for chip multiprocessors </p><p> ough this seems low compared to published results for sequential applications, prior work has shown that prefetching does not perform well as the number of threads of a parallel application increases [#b25][25]. The prefetcher fails as similar address streams generated by each parallel thread confuse the training agent.Figure ref type"figure" target"fig_6" </p>
<p> improving memory scheduling via processor-side load criticality information </p><p> thread cluster memory scheduling: exploiting differences in memory access behavior </p><p> ur scheduler against AHB [8], MORSEP [], PARBS [17], and TCM [#b12][12]. Naive PredictorLess ImplementationWe first examine the usefulness of sending ROB. teoftheart memory schedulers the adaptive historybased (AHB) scheduler proposed by Hur and Lin [8], the fairnessoriented thread cluster memory (TCM) scheduler [#b12][12], and MORSEP, a selfoptimizing scheduler that targets parallel application performance []. Ta. sed scheduler on multiprogrammed workloads. In this section, we provide our results relative to PARBS [17]. We also show results for the more recent TCM proposal [#b12][12]. Our multiprogrammed workloads are fourapplication bundles (see Section 4). Consequently, in our architecture, we reduce the number of DRAM channels from fou. hted speedup of 6.0 (Figure 12). We see similar speedups for our other ranking criticality predictors (not plotted here).As a comparison, we have also implemented TCM [#b12][12], which attempts to balance system throughput (weighted speedup) with fairness (maximum slowdown). Figure 12 shows that TCM obtains on. "1 Not only does our predictor outperform TCM in terms of throughput, but it also improves on maximum slowdown, decreasing it by 11.6.The apparent discrepancy from previous TCM results [#b12][12] arises from differing workloads and target memory architectures. While the workloads reported for TCM tend to have several memoryintensive programs, our workl. d to have the shortest latency [8].The most relevant to our work are those that focus on scheduling critical threads. Thread cluster memory (TCM) scheduling [#b12][12] classifies threads into either a latencysensitive or bandwidthsensitive cluster. Latencysensitive threads are prioritized over bandwidthsensitive threads, </p>
<p> personalized student stress prediction with deep multitask network </p><p> towards deep learning models for psychological state prediction using smartphone data: challenges and opportunities </p><p> ack of gold standard labels, noisy raw sensor data, heterogeneity in granularity and inter subject variability in behavioural and environmental patterns have stymied predictive modeling of this kind. [#b8](Mikelsons et al., 2018) have tried to predict stress of students in the StudentLife dataset by novel feature engineering of location based features and Neural Netw. p Models LOCATION FEATURE BASED MLPIn the work done by [#b8](Mikelsons et al., 2018), a Multilayer Perceptron (MLP) with 4 fully connected layers was employed to perform stress inference. Each fully connected layer uses the. ibr" target"b7"(Lngkvist et al., 2014)   ResultDue to a heavy imbalance of class labels on a scale of 15, we follow [#b8](Mikelsons et al., 2018), converting the five stress label scale to a scale of three stress labels by defining our classes as below median stress, median stress an.  A.1. Used FeaturesIn all, our data comprises of 23 students, totaling to 1183 data points achieving roughly equal amount of training data in [#b8](Mikelsons et al., 2018). These 1183 data points have the following label distribution 263 below median stress, 511 median stress and 409 above median. Since stude </p>
<p> personalized student stress prediction with deep multitask network </p><p> predicting tomorrow's mood, health, and stress level using personalized multitask learning and domain adaptation </p><p> re personal dynamics of all subjects using one model is demanding, as these dynamics are very distinct and have high intersubject variability. To learn personalized models for each student, we follow [#b3](Jaques et al., 2017) and use a Multitask approach which comprises of a LSTM to model sequence of histograms followed by shared fully connected layers and a MLP for </p>
<p> personalized student stress prediction with deep multitask network </p><p> stress recognition using wearable sensors and mobile phones </p><p> Activity, Conversation, Location, information regarding Mental Health like stress levels and much more through the StudentLife application on android smartphones.Contemporary research such as [#b11](Sano amp Picard, 2013) and (Sano et al., 2015) has leveraged similar type of data from sensors and Machine Learning to pred. ariate features in StudentLife dataset, we select the ones that suggest evidence of these being good predictors of stress in (StultsKolehmainen amp Sinha, 2014[#b11]Sano amp Picard, 2013Trokel et al., 2000Sano et al., 2015) etc.Among the discr </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of work stress on ambulatory blood pressure, heart rate and heart rate variability </p><p> b16"Trokel et al., 2000). With the efforts of researchers at various institutions several technologies for detecting stress has been accomplished. Few use heart rate and heart rate variability [#b17](Vrijkotte et al., 2000), cortisol levels (Dickerson amp Kemenyr, 2004) and skin conductance ( </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of stress on the immune system </p><p> " target"b5"Kario et al., 2003), alterations of the brain causing differences in memory and cognition (SJ et al., 2009), suppression of the immune system [#b6](Khansari et al., 1990), and poor academic performance (Sano et al., 2015Trokel et al., 2000) </p>
<p> personalized student stress prediction with deep multitask network </p><p> a review of unsupervised feature learning and deep learning for time-series modeling </p><p> echniques for modeling timeseries data, variations of RNNs like GRU and LSTM are the most popular, however people have used Autoencoders for compression and reduction of the temporal dimensions. In [#b7](Lngkvist et al., 2014)   ResultDue to a heavy imbalance of class labels on a scale of 15 </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of stress throughout the lifespan on the brain, behaviour and cognition </p><p> ular diseases (Rozanski et al., 1999Kario et al., 2003), alterations of the brain causing differences in memory and cognition [#b14](SJ et al., 2009), suppression of the immune system (Khansari et al., 1990), and poor academic performance ref type"bibr" tar </p>
<p> personalized student stress prediction with deep multitask network </p><p> multi-task and multi-view learning of user state </p><p> ref and use a Multitask approach which comprises of a LSTM to model sequence of histograms followed by shared fully connected layers and a MLP for each student. A similar approach was also taken in [#b4](Kandemir et al., 2014) for the prediction of affect (mood) by learning user specific kernels. As indicated by our experiments detailed in section 4, this approach </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of stress throughout the lifespan on the brain, behaviour and cognition </p><p> ular diseases (Rozanski et al., 1999Kario et al., 2003), alterations of the brain causing differences in memory and cognition [#b14](SJ et al., 2009), suppression of the immune system (Khansari et al., 1990), and poor academic performance ref type"bibr" tar </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of work stress on ambulatory blood pressure, heart rate and heart rate variability </p><p> b16"Trokel et al., 2000). With the efforts of researchers at various institutions several technologies for detecting stress has been accomplished. Few use heart rate and heart rate variability [#b17](Vrijkotte et al., 2000), cortisol levels (Dickerson amp Kemenyr, 2004) and skin conductance ( </p>
<p> personalized student stress prediction with deep multitask network </p><p> multi-task and multi-view learning of user state </p><p> ref and use a Multitask approach which comprises of a LSTM to model sequence of histograms followed by shared fully connected layers and a MLP for each student. A similar approach was also taken in [#b4](Kandemir et al., 2014) for the prediction of affect (mood) by learning user specific kernels. As indicated by our experiments detailed in section 4, this approach </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of work stress on ambulatory blood pressure, heart rate and heart rate variability </p><p> b16"Trokel et al., 2000). With the efforts of researchers at various institutions several technologies for detecting stress has been accomplished. Few use heart rate and heart rate variability [#b17](Vrijkotte et al., 2000), cortisol levels (Dickerson amp Kemenyr, 2004) and skin conductance ( </p>
<p> personalized student stress prediction with deep multitask network </p><p> discriminating stress from cognitive load using a wearable eda device. a publication of the </p><p> rate and heart rate variability (Vrijkotte et al., 2000), cortisol levels (Dickerson amp Kemenyr, 2004) and skin conductance [#b13](Setz et al., 2010). Other techniques do not depend on sensors but simply try to discover the user's stress through selfreporting tools e.g., ref type"bibr" tar </p>
<p> personalized student stress prediction with deep multitask network </p><p> towards accurate non-intrusive recollection of stress levels using mobile sensing and contextual recall </p><p> nd skin conductance (Setz et al., 2010). Other techniques do not depend on sensors but simply try to discover the user's stress through selfreporting tools e.g., [#b9](Rahman et al., 2014) and surveys like the Perceived Stress Scale (Cohen et al., 1983).With the induction of high quality </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of work stress on ambulatory blood pressure, heart rate and heart rate variability </p><p> b16"Trokel et al., 2000). With the efforts of researchers at various institutions several technologies for detecting stress has been accomplished. Few use heart rate and heart rate variability [#b17](Vrijkotte et al., 2000), cortisol levels (Dickerson amp Kemenyr, 2004) and skin conductance ( </p>
<p> personalized student stress prediction with deep multitask network </p><p> the effects of stress on physical activity and exercise </p><p> , surveys and self reported EMAs. Out of the many discrete sequence and covariate features in StudentLife dataset, we select the ones that suggest evidence of these being good predictors of stress in [#b15](StultsKolehmainen amp Sinha, 2014Sano amp Picard, 2013Trokel et al., 2000ref ty </p>
<p> personalized student stress prediction with deep multitask network </p><p> discriminating stress from cognitive load using a wearable eda device. a publication of the </p><p> rate and heart rate variability (Vrijkotte et al., 2000), cortisol levels (Dickerson amp Kemenyr, 2004) and skin conductance [#b13](Setz et al., 2010). Other techniques do not depend on sensors but simply try to discover the user's stress through selfreporting tools e.g., ref type"bibr" tar </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of stress throughout the lifespan on the brain, behaviour and cognition </p><p> ular diseases (Rozanski et al., 1999Kario et al., 2003), alterations of the brain causing differences in memory and cognition [#b14](SJ et al., 2009), suppression of the immune system (Khansari et al., 1990), and poor academic performance ref type"bibr" tar </p>
<p> personalized student stress prediction with deep multitask network </p><p> effects of stress on the immune system </p><p> " target"b5"Kario et al., 2003), alterations of the brain causing differences in memory and cognition (SJ et al., 2009), suppression of the immune system [#b6](Khansari et al., 1990), and poor academic performance (Sano et al., 2015Trokel et al., 2000) </p>
<p> personalized student stress prediction with deep multitask network </p><p> healthrelated variables and academic performance among firstyear college students: implications for sleep and other behaviours </p><p> t al., 2009), suppression of the immune system (Khansari et al., 1990), and poor academic performance (Sano et al., 2015[#b16]Trokel et al., 2000). With the efforts of researchers at various institutions several technologies for detecting stress has been accomplished. Few use heart rate a. at suggest evidence of these being good predictors of stress in (StultsKolehmainen amp Sinha, 2014Sano amp Picard, 2013[#b16]Trokel et al., 2000Sano et al., 2015) etc.Among the discrete sequence data, we use Activity and Audio which are catego </p>
<p> personalized student stress prediction with deep multitask network </p><p> long short-term memory </p><p> in these kinds of datasets. To model the temporal patterns of features like Activity, Audio and Conversation we put the sequences of hourly histograms through an LSTM (Long Shortterm Memory Network) [#b2](Hochreiter amp Schmidhuber, 1997). Then we concatenate the last hidden state with the covariates. This concatenated output is passed through multiple layers of f </p>
<p> personalized student stress prediction with deep multitask network </p><p> acute stressors and cortisol responses: a theoretical integration and synthesis of laboratory research </p><p> titutions several technologies for detecting stress has been accomplished. Few use heart rate and heart rate variability (Vrijkotte et al., 2000), cortisol levels [#b1](Dickerson amp Kemenyr, 2004) and skin conductance (Setz et al., 2010). Other techniques do not depend on sensors but simply </p>
<p> BiNE: Bipartite Network Embedding </p><p> line: large-scale information network embedding </p><p> h explicit and implicit relations of the network. There are some followup works exploiting both 1storder and 2ndorder proximities between vertices to embed homogeneous networks. Specifically, LINE [#b19][20] learns two separated embeddings for 1storder and 2ndorder relations SDNE [21] incorporates both 1storder and 2ndorde. In a bipartite network, edges exist between vertices of two different types, providing an explicit signal on constructing the bipartite network. Similar to the modeling of 1storder proximity in LINE [#b19][20], we model explicit relations by considering the local proximity between two connected vertices. The joint probability between vertices u i and v j is defined. cal proximity between two vertices in the embedding space. The effectiveness and prevalence of word2vec inspire many works [[#b19]] to use inner product to model the interaction between two entities. We follow this setting, and use sigmoid function to transform the interaction value to the. 3  v j S S D V vc C S (v j ) P (v c v j ).(6)Following existing neural embedding methods [[#b19]], we parameterize the conditional probability P(u c u i ) and P(v c v j ) using the inner product kernel with softmax for outputformula xmlid"formula_.  As a homogeneous network embedding method, DeepWalk performs uniform random walks to get a corpus of vertex sequences. Then the word2vec is applied on the corpus to learn vertex embeddings.  LINE [#b19][20] This approach optimizes both the 1storder and 2ndorder proximities in a homogeneous network. We use the LINE(1st2nd) method which has shown the best resul </p>
<p> BiNE: Bipartite Network Embedding </p><p> scalable representation learning for heterogeneous networks </p><p> rtite networks [13].To our knowledge, none of the existing works has paid special attention to embed bipartite networks. While a recent work by Dong et al. [#b13][14] proposed metapath2vec for embedding heterogeneous networks which can also be applied to bipartite networks, we argue that a key limitation is that it treats. s the powerlaw distribution of vertex degrees. Thus, these homogeneous network embedding methods might be suboptimal for learning vertex representations for a bipartite network.Metapath2vec [#b13][14], HNE [27] and EOE [28] are representative vertex embedding methods for heterogeneous. andom walk will start from it. As a result, the vertex importance can be preserved to some extent.  We assign a probability to stop a random walk in each step. In contrast to DeepWalk and other work [#b13][14] that apply a fixed length on the random walk, we allow the generated vertex sequences have a variable length, in order to have a close analogy to the variable. d extends DeepWalk by performing biased random walks to generate the corpus of vertex sequences. The hyperparameters p and q are set to 0.5 which has empirically shown good results.  Metapath2vec [#b13][14] This is the stateoftheart method for embedding heterogeneous networks.The metapath scheme chosen in our experiments are "IUI" (itemuseritem) and "IUI" </p>
<p> BiNE: Bipartite Network Embedding </p><p> neural factorization machines for sparse predictive analytics </p><p> applications. Recent advances in data mining and information retrieval have focused on learning representations from data [4][5][#b5][6][7]. In particular, they embed vertices into a low dimensional space, i.e., representing a vertex as a learnable embedding ve </p>
<p> BiNE: Bipartite Network Embedding </p><p> heterogeneous network embedding via deep architectures </p><p> Thus, these homogeneous network embedding methods might be suboptimal for learning vertex representations for a bipartite network.Metapath2vec [14], HNE [#b26][27] and EOE [28] are representative vertex embedding methods for heterogeneous networks. Although they can be applied to bipa </p>
<p> BiNE: Bipartite Network Embedding </p><p> link prediction for bipartite social networks: the role of structural holes </p><p> headVisualizeUs DBLP Movielens F110 NDCG10 MAP10 MRR10 F110 NDCG10 MAP10 MRR10 F110 NDCG10 MAP10 MRR10 BPR 6.22  The neural networkbased methods outperform the indices proposed in [#b37][38] significantly. This is due to the factors that (1) one index proposed in [#b37][38] only emphasizes one kind of network topolo. 10 BPR 6.22  The neural networkbased methods outperform the indices proposed in [#b37][38] significantly. This is due to the factors that (1) one index proposed in [#b37][38] only emphasizes one kind of network topological structure, rather than the global structure (2) the neural networkbased methods predict the links in a data. type"annex" we randomly sample 60 instances as the training set, evaluating performance on the remaining 40 of testing set. Following the previous work [#b37][38], we employ two metrics, area under the ROC curve (AUCROC) and PrecisonRecall curve (AUCPR), to evaluate the link prediction performance. (2) For the recomm. report the best result between them. (2) To benchmark the link prediction task, we also compare with a set of methods that are specifically designed for the task. We apply several indices proposed in [#b37][38], including Common Neighbors (CN), Jaccard Coefficient (JC), Absent Links (AL), AdamaicAdar (AA), Katz Index (Katz), and Preferential Attachmenthave (PA). (3) </p>
<p> BiNE: Bipartite Network Embedding </p><p> structural deep network embedding </p><p> er proximities between vertices to embed homogeneous networks. Specifically, LINE [20] learns two separated embeddings for 1storder and 2ndorder relations SDNE [#b20][21] incorporates both 1storder and 2ndorder proximities to preserve the network structure and GraRep [22] further extends </p>
<p> BiNE: Bipartite Network Embedding </p><p> structural deep network embedding </p><p> er proximities between vertices to embed homogeneous networks. Specifically, LINE [20] learns two separated embeddings for 1storder and 2ndorder relations SDNE [#b20][21] incorporates both 1storder and 2ndorder proximities to preserve the network structure and GraRep [22] further extends </p>
<p> BiNE: Bipartite Network Embedding </p><p> structural deep network embedding </p><p> er proximities between vertices to embed homogeneous networks. Specifically, LINE [20] learns two separated embeddings for 1storder and 2ndorder relations SDNE [#b20][21] incorporates both 1storder and 2ndorder proximities to preserve the network structure and GraRep [22] further extends </p>
<p> BiNE: Bipartite Network Embedding </p><p> a geometric framework for nonconvex optimization duality using augmented lagrangian functions </p><p> ch can be categorized into two types matrix factorization (MF)based and neural networkbased methods.MFbased methods are either linear [16] or nonlinear [#b16][17] in learning vertex embeddings. The former employs the linear transformations to embed network vertices into a low dimensional embedding space, such as singula. low dimensional latent space by utilizing the nonlinear transformations, e.g., kernel PCA, spectral embedding , marginal fisher analysis (MFA), and manifold learning approaches include LLE and ISOMAP [#b16][17]. Generally speaking, MFbased methods have two main drawbacks (1) they are usually computationally expensive due to the eigendecomposition operations on dat </p>
<p> BiNE: Bipartite Network Embedding </p><p> joint event-partner recommendation in event-based social networks </p><p> xmlns"httpwww.teic.orgns1.0"4.2.3Negative Sampling. The idea of negative sampling is to approximate the costly denominator term of softmax with some sampled negative instances [#b35][36]. Then the learning can be performed by optimizing a pointwise classification loss. For a center vertex u i , highquality negatives should be the vertices th </p>
<p> BiNE: Bipartite Network Embedding </p><p> authoritative sources in a hyperlinked environment </p><p> partite Network ModelingAs a ubiquitous data structure, bipartite networks have been mined for many applications, among which vertex ranking is an active research problem. For example, HITS [#b28][29] learns to rank vertices by capturing some semantic relations within a bipartite network. CoHITS [1] incorporates content. ctively. D U (or D V ) output by Algorithm 1 is the corpus generated from the vertex set U (or V ). The vertex centrality can be measured by many metrics, such as degree centrality, PageRank and HITS [#b28][29], etc., and we use HITS in our experiments.Algorithm 1 WalkGenerator(W , R, maxT , minT , p)Input  weight matrix of the bipartite network W, ve </p>
<p> BiNE: Bipartite Network Embedding </p><p> grarep: learning graph representations with global structural information </p><p> ed embeddings for 1storder and 2ndorder relations SDNE [21] incorporates both 1storder and 2ndorder proximities to preserve the network structure and GraRep [#b21][22] further extends the method to capture higherorder proximities. Besides capturing highorder proximities, there are several proposals to incorporate side info </p>
<p> BiNE: Bipartite Network Embedding </p><p> authoritative sources in a hyperlinked environment </p><p> partite Network ModelingAs a ubiquitous data structure, bipartite networks have been mined for many applications, among which vertex ranking is an active research problem. For example, HITS [#b28][29] learns to rank vertices by capturing some semantic relations within a bipartite network. CoHITS [1] incorporates content. ctively. D U (or D V ) output by Algorithm 1 is the corpus generated from the vertex set U (or V ). The vertex centrality can be measured by many metrics, such as degree centrality, PageRank and HITS [#b28][29], etc., and we use HITS in our experiments.Algorithm 1 WalkGenerator(W , R, maxT , minT , p)Input  weight matrix of the bipartite network W, ve </p>
<p> BiNE: Bipartite Network Embedding </p><p> grarep: learning graph representations with global structural information </p><p> ed embeddings for 1storder and 2ndorder relations SDNE [21] incorporates both 1storder and 2ndorder proximities to preserve the network structure and GraRep [#b21][22] further extends the method to capture higherorder proximities. Besides capturing highorder proximities, there are several proposals to incorporate side info </p>
<p> BiNE: Bipartite Network Embedding </p><p>  </p><p> pTo date, existing works have primarily focused on embedding homogeneous networks where vertices are of the same type [[][#b8][9][10]. Following the pioneering work of DeepWalk [8], these methods typically apply a two. get"b9"[], community information [24], textual content [25], user profiles [#b8][9], location information [26], among others.It is worth pointing out that the above mentioned methods are designed for. d to model auxiliary side information, such as numerical features [42], textual descriptions [43], and among other attributes [#b8][9]. In addition, the bipartite networks in many practical applications are dynamically updated [32]. For example, the preferen </p>
<p> BiNE: Bipartite Network Embedding </p><p> a geometric framework for nonconvex optimization duality using augmented lagrangian functions </p><p> ch can be categorized into two types matrix factorization (MF)based and neural networkbased methods.MFbased methods are either linear [16] or nonlinear [#b16][17] in learning vertex embeddings. The former employs the linear transformations to embed network vertices into a low dimensional embedding space, such as singula. low dimensional latent space by utilizing the nonlinear transformations, e.g., kernel PCA, spectral embedding , marginal fisher analysis (MFA), and manifold learning approaches include LLE and ISOMAP [#b16][17]. Generally speaking, MFbased methods have two main drawbacks (1) they are usually computationally expensive due to the eigendecomposition operations on dat </p>
<p> BiNE: Bipartite Network Embedding </p><p> discrete collaborative filtering </p><p> ), which has been widely investigated in the field of recommender systems and semantic analysis, is the most representative model. And a typical implementation of LFM is based on matrix factorization [#b29][30][31][32]. Recent advances utilize deep learning methods to learn vertex embeddings on </p>
<p> BiNE: Bipartite Network Embedding </p><p> deepwalk: online learning of social representations </p><p> ink prediction, clustering and so on.To date, existing works have primarily focused on embedding homogeneous networks where vertices are of the same type [[#b7][][9][10]. Following the pioneering work of DeepWalk [#b7][8]ref. ref type"bibr" target"b3"[[#b7][][9][10]. Following the pioneering work of DeepWalk [#b7][8], these methods typically apply a twostep solution first performing random walks on the network to obtain a "corpus" of vertices, and then applying word embedd. to the predefined proximity measures for calculating the affinity matrix.Neural networkbased methods are the stateofart vertex representation learning techniques. The pioneer work DeepWalk [#b7][8] and Node2vec [4] extend the idea of Skipgram [11] to model homogeneous network, which. Now we consider how to estimate the local proximity between two vertices in the embedding space. The effectiveness and prevalence of word2vec inspire many works [[#b7]] to use inner product to model the interaction between two entities. We follow this setting, and use sigmoid function to t. convert a network into a corpus of vertex sequences by performing random walks on the network, which has been used in some homogeneous network embedding methods [[#b7]]. However, directly performing random walks on a bipartite network could fail, since there is no stationary distribution of random walks on bipartite networks due. rmula xmlid"formula_12"max imize O 3  v j S S D V vc C S (v j ) P (v c v j ).(6)Following existing neural embedding methods [[#b7]], we parameterize the conditional probability P(u c u i ) and P(v c v j ) using the inner product kernel with softmax fo. learn vertex embeddings and are representative of stateoftheart network embedding methods. For each method, we use the released implementations of the authors for our experiments. DeepWalk [#b7][8] As a homogeneous network embedding method, DeepWalk performs uniform random walks to get a corpus of vertex sequences. Then the word2vec is applied on the corp </p>
<p> BiNE: Bipartite Network Embedding </p><p> community detection in bipartite networks using random walks </p><p> b7"8]. However, directly performing random walks on a bipartite network could fail, since there is no stationary distribution of random walks on bipartite networks due to the periodicity issue [#b33][34]. To address this issue, we consider performing random walks on two homogeneous networks that contain the 2ndorder proximity between vertices of the same type </p>
<p> BiNE: Bipartite Network Embedding </p><p> fism: factored item similarity models for top-n recommender systems </p><p> both datasets, RankALS [39] This method also optimizes the MF model for the ranking task, by towards a different pairwise regressionbased loss.  FISMauc [#b39][40] Distinct to MF, factored item similarity model (FISM) is an itembased collaborative filtering method. We employ the AUCbased objective to optimize FISM for </p>
<p> BiNE: Bipartite Network Embedding </p><p> discrete collaborative filtering </p><p> ), which has been widely investigated in the field of recommender systems and semantic analysis, is the most representative model. And a typical implementation of LFM is based on matrix factorization [#b29][30][31][32]. Recent advances utilize deep learning methods to learn vertex embeddings on </p>
<p> BiNE: Bipartite Network Embedding </p><p> learning query and document relevance from a web-scale click graph </p><p> le, in search engines, queries and webpages form a bipartite network, where the edges can indicate users' click behaviors that provide valuable relevance signal [[#b1]] in another application of recommender systems, users and items form a bipartite network, where the edges can encode users' rating behaviors that contain rich co </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> april: a processor architecture for multiprocessing </p><p> onal units. SMT combines the multipleinstructionissue features of modern superscalars with the latencyhiding ability of multithreaded architectures. Unlike conventional multithreaded architectures [#b0][], which depend on fast context switching to </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> interleaving: a multithreading technique targeting multiprocessors and workstations </p><p> perscalars with the latencyhiding ability of multithreaded architectures. Unlike conventional multithreaded architectures [[#b14]], which depend on fast context switching to share processor execution resources, all hardware contexts in an SMT process </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> an overview of the 21164 axp microprocessor </p><p> ctions per cycle. We assume that all functional units are completely pipelined. Table 1 shows the instruction latencies, which are derived from the Alpha 21164 [#b7][8].We assume a 32entry integer instruction queue (which handles integer instructions and all loadstore operations) and a 32entry floating point queue, not </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> the tera computer system </p><p> nstructionissue features of modern superscalars with the latencyhiding ability of multithreaded architectures. Unlike conventional multithreaded architectures [[#b1]], which depend on fast context switching to share processor execution resources, a. Q clog. Here priority is given to threads with the fewest instructions in decode, rename, and the instruction queues. This achieves three purposes (1) it prevents any one thread from filling the IQ, [#b1](2)   priority to threads that are moving instructions through the IQ most efficiently, and (3) it provides a more even mix of instructions from the available threa. and the Multiscalar project [25] combine multipleissue with multithreading, but assign work onto processors at a coarser level than individual instructions. Tera [#b1][2] combines LIW with finegrain multithreading. SummaryThis paper presents a simultaneous </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> the tera computer system </p><p> nstructionissue features of modern superscalars with the latencyhiding ability of multithreaded architectures. Unlike conventional multithreaded architectures [[#b1]], which depend on fast context switching to share processor execution resources, a. Q clog. Here priority is given to threads with the fewest instructions in decode, rename, and the instruction queues. This achieves three purposes (1) it prevents any one thread from filling the IQ, [#b1](2)   priority to threads that are moving instructions through the IQ most efficiently, and (3) it provides a more even mix of instructions from the available threa. and the Multiscalar project [25] combine multipleissue with multithreading, but assign work onto processors at a coarser level than individual instructions. Tera [#b1][2] combines LIW with finegrain multithreading. SummaryThis paper presents a simultaneous </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> an elementary processor architecture with simultaneous instruction issuing from multiple threads </p><p> on to register file access or instruction scheduling. This paper presents an architecture that realizes much of the potential demonstrated by that work, simulating it in detail.Hirata, et al., [#b12][13] present an architecture for a multithreaded superscalar processor and simulate its performance on a parallel raytracing application. They do not simulate cac </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> fast and accurate instruction fetch and branch prediction </p><p> each other, although they may conflict with other I cache activity (cache fills).Branch prediction is provided by a decoupled branch target buffer (BTB) and pattern history table (PHT) scheme [#b3][4]. We use a 256entry BTB, organized as fourway set associative. The 2K x 2bit PHT is accessed by the XOR of the lower bits of the address and the global history </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> simultaneous multithreading: maximizing on-chip parallelism </p><p> ows simultaneous multithreading to substantially increase throughput, attacking the two major impediments to processor utilization long latencies and limited perthread parallelism. Tullsen, et al., [#b26][27] showed the potential of Proceedings of the 23rd Annual International Symposium on Computer Architecture, Philadelphia, PA, May, 1996 an SMT processor to achie. ally overconservative. MethodologyThe methodology in this paper closely follows the simulation and measurement methodology of [#b26][27]. Our simulator uses emulationbased, instructionlevel simulation, and borrows significantly from MIPSI [22], a MIPSbased. ent combination of the benchmarks.We compile each program with the Multiflow trace scheduling compiler [17], modified to produce Alpha code. In contrast to [#b26][27], we turn off trace scheduling in the compiler for this study, for two reasons. In our measurements, we want to differentiate between useful and useless specul. ction of the time. We also note, however, that the throughput peaks before 8 threads, and the processor utilization, at less than 50 of the 8issue processor, is well short of the potential shown in [#b26][27].We make several conclusions about the potential bottlenecks of this system as we approach 8 threads, aided by Figure ref type"figure" target"fig_3". ds, and (2) making that partition flexible. This is the same approach (although in a more limited fashion here) that simultaneous multithreading uses to improve the throughput of the functional units [#b26][27]. Exploiting Thread Choice in the Fetch UnitThe efficiency of the entire processor i. limiting factor in the number of threads an architecture can support.A number of other architectures have been proposed that exhibit simultaneous multithreading in some form. Tullsen, et al., [#b26][27] demonstrated the potential for simultaneous multithreading, but did not simulate a complete architecture, nor did that paper present a specific solution to re </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> interleaving: a multithreading technique targeting multiprocessors and workstations </p><p> perscalars with the latencyhiding ability of multithreaded architectures. Unlike conventional multithreaded architectures [[#b14]], which depend on fast context switching to share processor execution resources, all hardware contexts in an SMT process </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> fast and accurate instruction fetch and branch prediction </p><p> each other, although they may conflict with other I cache activity (cache fills).Branch prediction is provided by a decoupled branch target buffer (BTB) and pattern history table (PHT) scheme [#b3][4]. We use a 256entry BTB, organized as fourway set associative. The 2K x 2bit PHT is accessed by the XOR of the lower bits of the address and the global history </p>
<p> exploiting choice: instruction fetch and issue on an implementable simultaneous multithreading processor </p><p> increasing superscalar performance through multistreaming </p><p> hreaded superscalar performance, backed up by simulation. Their study models perfect branching, perfect caches and a homogeneous workload (all threads running the same trace). Yamamoto and Nemirovsky [#b27][28] simulate an SMT architecture with separate instruction queues and up to four threads. Gulati and Bagherzadeh [11] model a </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> tensorflow: a system for large-scale machine learning </p><p> "Bergstra et al., 2010Tokui et al., 2015Maclaurin et al., 2015Chen et al., 2015[#b0]Abadi et al., 2016Paszke et al., 2017The Gluon Team, 2017Neubig et al.. mitting compiler optimizations and the exploitation of parallelism, and simplifying deployment, distribution, and code generation (see, e.g., Bergstra et al., 2010[#b0]Abadi et al., 2016). But, because declarative DSLs prevent users from using arbitrary hostlanguage constructs, they have steep learning curves and are not suitable. operations as graph functions. The staging workflow is detailed in 4.1, and the mechanism is described in 4.6. TensorFlow graphs come with their own set of design principles, which are presented in [#b0](Abadi et al., 2016). The following terminology will be used in the sequel a tensor is a multidimensional, typed array, an operation is a primitive, possibly stat. ion. The dataflow graph runtime, which is written in C, automatically partitions subgraphs across devices and parallelizes operations when possible. Readers interested in the runtime should consult [#b0](Abadi et al., 2016).The function decorator supports code generation via XLA (The XLA team, 2017). TensorFlow Eager reli </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> optiml: an implicitly parallel domain-specific language for machine learning </p><p> b7"(DeVito et al., 2013) as another example, OptiML is a Scalaembedded DSL for machine learning with support for staging and code generation but without support for automatic differentiation [#b28](Sujeeth et al., 2011). Outside of DSLs, there are several projects that provide justintime (JIT) compilation for Python, of which Numba ref type"bibr" target </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> optiml: an implicitly parallel domain-specific language for machine learning </p><p> b7"(DeVito et al., 2013) as another example, OptiML is a Scalaembedded DSL for machine learning with support for staging and code generation but without support for automatic differentiation [#b28](Sujeeth et al., 2011). Outside of DSLs, there are several projects that provide justintime (JIT) compilation for Python, of which Numba ref type"bibr" target </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> compilers and staging transformations </p><p> (Rompf amp Odersky, 2010). Multistage programming is related to staging transformations in compilers and partial evaluation in programming languages, for which [#b14](Jrring amp Scherlis, 1986) and (Jones et al., 1993) are classic references, respectively. div xmlns"httpwww </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> flux: elegant machine learning with julia </p><p> br" target"b0"Abadi et al., 2016Paszke et al., 2017The Gluon Team, 2017Neubig et al., 2017[#b10]Innes, 2018Frostig et al., 2018). These software packages in fact more closely resemble domainspecific languages (DSLs) than libraries re </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> flux: elegant machine learning with julia </p><p> br" target"b0"Abadi et al., 2016Paszke et al., 2017The Gluon Team, 2017Neubig et al., 2017[#b10]Innes, 2018Frostig et al., 2018). These software packages in fact more closely resemble domainspecific languages (DSLs) than libraries re </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> building domain-specific embedded languages </p><p> tic differentiation software are often referred to as differentiable programs.DSLs for differentiable programming are usually embedded in a host language (for a reference on embedded DSLs, see [#b9]Hudak, 1996), and they can be roughly classified as either imperative or declarative, in the programming languages sense. Programming in an imperative DSL for diffe </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> chainer: a next-generation open source framework for deep learning </p><p> similar structure they provide suites of primitive operations and functions to automatically differentiate compositions thereof (see, e.g., Bergstra et al., 2010[#b32]Tokui et al., 2015Maclaurin et al., 2015Chen et al., 2015. on returning concrete numerical data. While imperative DSLs provide a natural programming paradigm, when embedded in an interpreted language like Pythonwhich is the case for popular DSLs like Chainer [#b32](Tokui et al., 2015) and PyTorch (Paszke et al., 2017)performance is bottlenecked on the interpreter and serialization of mod. entiation (Baydin et al., 2018), with a few changes to better support partially staged computation. Our implementation is similar to the implementations of Chainer [#b32](Tokui et al., 2015), Autograd (Maclaurin et al., 2015), and PyTorch (Paszke et al., 2017)ref </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> generalizing hamiltonian monte carlo with neural networks </p><p> ent an accompanying TensorFlow benchmark for this reason. L2HMC.In Figure 4 we show performance of an L2HMC [#b18](Levy et al., 2018)  Eager, TensorFlow Eager with function, and TensorFlow on synthetic data running on the CPU. The benchmark samples from a 2dimensional distrib </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> compilation, optimization of object-oriented languages and programming systems </p><p> t al., 2011). Outside of DSLs, there are several projects that provide justintime (JIT) compilation for Python, of which Numba (Lam et al., 2015) and PyPy [#b3](Bolz et al., 2009) are two examples.Multistage programming is a wellstudied topic in programming languages a good reference is ref type"bibr" target" </p>
<p> tensorflow eager: a multi-stage, python-embedded dsl for machine learning </p><p> autograph: imperative-style coding with graphbased performance </p><p> r TensorFlow Team, 2018Innes, 2019). Python's flexibility makes it difficult for DSLs embedded in it to use such an approach. Some projects, like AutoGraph [#b20](Moldovan et al., 2019) do operate on Python abstract syntax trees to rewrite imperative code to code that constructs dataflow graphs, but such techniques are out. d to use staging annotations judiciously. This tradeoff can be diminished by using tools like AutoGraph that operate on abstract syntax trees and rewrite Python control flow to dataflow control flow [#b20](Moldovan et al., 2019). Automatic differentiationWe implement a variant of tracingbase. thon functions in function often "does the right thing" staging computations with dynamic control flow can require nontrivial programmer intervention. We hope to decrease this friction via Autograph [#b20](Moldovan et al., 2019).Finally, TensorFlow Eager has informed the evolution of TensorFlow itself the upcoming TensorFlow 2.0 uses our implementation to pr </p>
<p> line: large-scale information network embedding </p><p> deepwalk: online learning of social representations </p><p> ese methods either use an indirect approach that is not designed for networks (e.g., [1]) or lack a clear objective function tailored for network embedding (e.g., [#b42][16]). We anticipate that a new model with a carefully designed objective function that preserves properties of the graph and an efficient optimization technique s. e graph factorization method only applies to undirected graphs while the proposed model is applicable for both undirected and directed graphs.The most recent work related with ours is DeepWalk [#b42][16], which deploys a truncated random walk for social network embedding. Although empirically effective, the DeepWalk does not provide a clear objective that arti. Social networks. We use two social networks Flickr and Youtube2 . The Flickr network is denser than the Youtube network (the same network as used in DeepWalk [#b42][16]). (3) Citation Networks. Two types of citation networks are used an author citation network and a paper citation network. We use the DBLP data set ref type. compare with the matrix factorization techniques for graph factorization.An information network can be represented as an affinity matrix, and is able to represent each vertex with a  DeepWalk [#b42][16]. DeepWalk is an approach recently proposed for social network embedding, which is only applicable for networks with binary edges. For each vertex, truncated r. ty of the embeddings of the language network is set to 200, as used in word embedding [13]. For other networks, the dimension is set as 128 by default, as used in [#b42][16]. Other default settings include the number of negative samples K  5 for LINE and  Quantitat </p>
<p> line: large-scale information network embedding </p><p> the strength of weak ties </p><p> be found in the theories of sociology and linguistics. For example, "the degree of overlap of two people's friendship networks correlates with the strength of ties between them," in a social network [#b32][6] and "You shall know a word by the company it keeps" (Firth, J. R. 195711) in text corpora [5]. Indeed, people who share. he vertices into different groups according to their degrees including (0, 1], [], [[#b32]], [], [], [31, ) </p>
<p> line: large-scale information network embedding </p><p> neural word embedding as implicit matrix factorization </p><p> embedding model SkipGram [12], which learns the word embeddings directly from the original Wikipedia pages and is also implicitly a matrix factorization approach [#b34][8]. The window size is set as 5, the same as used for constructing the language network.We can see that LINE(2nd) outperforms all other methods, including </p>
<p> line: large-scale information network embedding </p><p> distributed large-scale natural graph factorization </p><p> works with millions of nodes. Although a few very recent studies approach the embedding of largescale networks, these methods either use an indirect approach that is not designed for networks (e.g., [#b27][1]) or lack a clear objective function tailored for network embedding (e.g., [16]). We anticipate that a new model with a car. plexity of which is at least quadratic to the number of nodes, making them inefficient to handle largescale networks.Among the most recent literature is a technique called graph factorization [#b27][1]. It finds the lowdimensional embedding of a large graph through matrix factorization, which is optimized using stochastic gradient descent. This is possible b. networks. We do not compare with some classical graph embedding algorithms such as MDS, IsoMap, and Laplacian eigenmap, as they cannot handle networks of this scale. Graph factorization (GF) [#b27][1]. We compare with the matrix factorization techniques for graph factorization.An information network can be represented as an affinity matrix, and is abl </p>
<p> line: large-scale information network embedding </p><p> distributed representations of words and phrases and their compositionality </p><p> ich requires the summation over the entire set of vertices when calculating the conditional probability p2(vi).To address this problem, we adopt the approach of negative sampling proposed in [#b39][13], which samples multiple negative edges according to some noisy distribution for each edge (i, j). More specifically, it specifies the following objective func. tion. The first term models the observed edges, the second term models the negative edges drawn from the noise distribution and K is the number of negative edges. We set Pn(v)  dv 34 as proposed in [#b39][13], where dv is the outdegree of vertex v.For the objective function (3), there exists a trivial solution u ik  , for i1, . . . , V  and k  1, . .. re we only apply LINE (1st2nd) to the scenario of supervised tasks.Parameter Settings.The minibatch size of the stochastic gradient descent is set as 1 for all the methods. Similar to [#b39][13], the learning rate is set with the starting value 0  0.025 and t  0(1tT ), where T is the total number of minibatches or edge samples. For fair compar.  0(1tT ), where T is the total number of minibatches or edge samples. For fair comparisons, the dimensionality of the embeddings of the language network is set to 200, as used in word embedding [#b39][13]. For other networks, the dimension is set as 128 by default, as used in [16]. Other default settings include the number. type"bibr" target"b29"3], [], [], [#b39][], [31, ), and then evaluate the performance of vertices in different groups. Overall, the performance of different models increases </p>
<p> line: large-scale information network embedding </p><p> hogwild: a lock-free approach to parallelizing stochastic gradient descent </p><p> 1, . . . , d. To avoid the trivial solution, we can still utilize the negative sampling approach (7) by just changing u T j to u T j . We adopt the asynchronous stochastic gradient algorithm (ASGD) [#b43][17] for optimizing Eqn. (7). In each step, the ASGD algorithm samples a minibatch of edges and then updates the model parame </p>
<p> line: large-scale information network embedding </p><p> visualizing data using t-sne </p><p>  </p>
<p> line: large-scale information network embedding </p><p> the strength of weak ties </p><p> be found in the theories of sociology and linguistics. For example, "the degree of overlap of two people's friendship networks correlates with the strength of ties between them," in a social network [#b32][6] and "You shall know a word by the company it keeps" (Firth, J. R. 195711) in text corpora [5]. Indeed, people who share. he vertices into different groups according to their degrees including (0, 1], [], [[#b32]], [], [], [31, ) </p>
<p> line: large-scale information network embedding </p><p> reducing the sampling complexity of topic models </p><p> ch interval [ i j wj i j wj) the random value falls into. This approach takes O(E) time to draw a sample which is costly when the number of edges E is large. We use the alias table method [#b35][] to draw a sample according to the weights of the edges, which takes only O(1) time when repeatedly drawing samples from the same discrete distribution.S </p>
<p> line: large-scale information network embedding </p><p> visualizing data using t-sne </p><p>  </p>
<p> line: large-scale information network embedding </p><p> information network or social network?: the structure of the twitter follow graph </p><p> ncerned, which typically contains millions of nodes and billions of edges. For example, the Twitter followeefollower network contains 175 million active users and around twenty billion edges in 2012 [#b40][14]. Most existing graph embedding algorithms do not scale for networks of this size. For example, the time complexity of classical graph embedding algorithms suc </p>
